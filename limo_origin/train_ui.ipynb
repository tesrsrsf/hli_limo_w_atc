{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4a510d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "import warnings\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import ast\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from typing import Dict, Any, Optional\n",
    "import numpy as np\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "#from numpyencoder import NumpyEncoder\n",
    "import datetime\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    roc_curve, auc, precision_recall_curve, average_precision_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from transformers.optimization import get_linear_schedule_with_warmup       # AdamW seems no longer available here\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "project_path = os.path.abspath('')\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n",
    "#import backend_model_info\n",
    "\n",
    "from dataloader import DataManager, DataManagerTest\n",
    "from model_4 import MultiModalConcatLineFocalBMESBinaryClassifier\n",
    "\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, classification_report\n",
    "\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e98e889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "with open('./pylint.txt','r') as f:\n",
    "    error_list = f.read()\n",
    "    error_codes = re.findall(r\"\\((\\w\\d{4})\\)\", error_list)\n",
    "    \n",
    "def analyze_pylint_output(eval_result: str) -> Counter:\n",
    "    analysis = [0]*len(error_codes)\n",
    "    error_pattern = re.compile(r\"\\d:\\d+:\\s(\\w\\d{4}):\\s\")\n",
    "    errors = error_pattern.findall(eval_result)\n",
    "\n",
    "    error_counts = Counter(errors)\n",
    "    \n",
    "    analysis = [error_counts[e] for e in error_codes]\n",
    "\n",
    "    return analysis\n",
    "\n",
    "\n",
    "def analyze_pylint_output_line(eval_result: str, total_lines: int):\n",
    "    error_pattern = re.compile(r\"(\\d+):\\d+:\\s(\\w\\d{4}):\\s\")\n",
    "    errors = error_pattern.findall(eval_result)\n",
    "    \n",
    "    line_error_counts = defaultdict(Counter)\n",
    "\n",
    "    for line, code in errors:\n",
    "        line_error_counts[int(line)][code] += 1\n",
    "    \n",
    "    analysis = [[0]*len(error_codes) for _ in range(total_lines)]\n",
    "    \n",
    "    # 각 줄별 에러 코드 카운트를 분석 결과 리스트에 저장\n",
    "    for line in range(total_lines):\n",
    "        if line in line_error_counts:\n",
    "            analysis[line] = [line_error_counts[line][code] for code in error_codes]\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "def split_code_sentence(code, use_sp=False):\n",
    "        import re\n",
    "        pattern = re.compile(\n",
    "        r'\"\"\"|\\'\\'\\'|\"|\\'|#|==|'\n",
    "        r'\\n|'\n",
    "        r'[^\\S\\n]+|'\n",
    "        r'\\w+|[.,()\\[\\]{};:\\=\\_\\+\\-\\*\\/\\~\\!\\%\\^\\&\\<\\>\\?]')\n",
    "        \n",
    "        tokens = pattern.findall(code)\n",
    "        return tokens\n",
    "\n",
    "def ccfeature_line_to_token_level(code):\n",
    "    code_tokens = split_code_sentence(code)\n",
    "    count = 0\n",
    "    line_num_list = []\n",
    "    for token in code_tokens:\n",
    "        line_num_list.append(count)\n",
    "        if token == '\\n':\n",
    "            count += 1\n",
    "    return line_num_list[:1024]\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, original_dataset, indices):\n",
    "        self.original_dataset = original_dataset\n",
    "        self.indices = [int(idx) for idx in indices]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        real_idx = self.indices[index]\n",
    "        return self.original_dataset[int(real_idx)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "\n",
    "def get_roc_metrics(true_labels, pred_labels):\n",
    "    fpr, tpr, thresholds = roc_curve(true_labels, pred_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    J = tpr - fpr\n",
    "    ix = np.argmax(J)\n",
    "    best_thresh = thresholds[ix]\n",
    "    print('Best Threshold=%f, sensitivity = %.3f, specificity = %.3f, J=%.3f' % (best_thresh, tpr[ix], 1-fpr[ix], J[ix]))\n",
    "    return float(roc_auc)\n",
    "\n",
    "class SupervisedTrainer:\n",
    "    def __init__(self, data, model, en_labels, id2label, args):\n",
    "        self.data = data\n",
    "        self.model = model\n",
    "        self.en_labels = en_labels\n",
    "        self.id2label = id2label\n",
    "\n",
    "        self.seq_len = args.seq_len\n",
    "        self.num_train_epochs = args.num_train_epochs\n",
    "        self.weight_decay = args.weight_decay\n",
    "        self.lr = args.lr\n",
    "        self.warm_up_ratio = args.warm_up_ratio\n",
    "\n",
    "        self.device = torch.device(\n",
    "            'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "        self._create_optimizer_and_scheduler()\n",
    "        \n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_f1_score = 0.0\n",
    "        self.best_model_path = None\n",
    "        self.writer = None\n",
    "        self.loss_function = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "        self.threshold = 0.5\n",
    "\n",
    "    def _create_optimizer_and_scheduler(self):\n",
    "        num_training_steps = len(\n",
    "            self.data.train_dataloader) * self.num_train_epochs\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "\n",
    "        named_parameters = self.model.named_parameters()\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in named_parameters\n",
    "                    if not any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\":\n",
    "                self.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in named_parameters\n",
    "                    if any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\":\n",
    "                0.0,\n",
    "            },\n",
    "        ]\n",
    "        self.optimizer = AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr=self.lr,\n",
    "            betas=(0.9, 0.98),\n",
    "            eps=1e-8,\n",
    "        )\n",
    "        self.scheduler = get_linear_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=int(self.warm_up_ratio * num_training_steps),\n",
    "            num_training_steps=num_training_steps)\n",
    "\n",
    "    def train(self, ckpt_name='linear_en.pt', prediction_method=\"most_common\"):\n",
    "        \n",
    "        for epoch in trange(int(self.num_train_epochs), desc=\"Epoch\"):\n",
    "            self.model.train()\n",
    "            tr_loss = 0\n",
    "            nb_tr_steps = 0\n",
    "            # train\n",
    "            for step, inputs in enumerate(\n",
    "                    tqdm(self.data.train_dataloader, desc=\"Iteration\")):\n",
    "                # send batch data to GPU\n",
    "                for k, v in inputs.items():\n",
    "                    if isinstance(v, torch.Tensor):\n",
    "                        inputs[k] = v.to(self.device)\n",
    "                with torch.set_grad_enabled(True):\n",
    "                    labels = inputs['labels']\n",
    "                    output = self.model(inputs['features'], inputs['labels'], inputs['ccfeatures'])#, inputs['line_indices'])\n",
    "                    logits = output['logits']\n",
    "                    loss = output['loss']\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    \n",
    "                    # print(\"KSY =======================\")\n",
    "                    # for name, p in self.model.named_parameters():\n",
    "                    #     if 'feature_encoder' in name:\n",
    "                    #         print(name)\n",
    "                    #         print(p.grad)\n",
    "                    #         exit()\n",
    "                            \n",
    "                    self.optimizer.step()\n",
    "                    self.scheduler.step()\n",
    "\n",
    "                    tr_loss += loss.item()\n",
    "                    nb_tr_steps += 1\n",
    "            \n",
    "                if step % 50 == 0:\n",
    "                    self.writer.add_scalar('Training Loss', loss.item(), epoch * len(self.data.train_dataloader) + step)\n",
    "            \n",
    "            \n",
    "            avg_train_loss = tr_loss / nb_tr_steps\n",
    "            print(f'epoch {epoch+1}: train_loss {avg_train_loss}')\n",
    "            self.writer.add_scalar('Average Training Loss', avg_train_loss, epoch)\n",
    "\n",
    "            # Validate data at the end of every epoch\n",
    "            val_loss, sent_result = self.valid(prediction_method=prediction_method)\n",
    "            self.writer.add_scalar('Validation Loss', val_loss, epoch)\n",
    "\n",
    "            # save the best model\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "                self.best_model_path = f\"{ckpt_name}\"\n",
    "                self.writer.add_scalar('Best Validation Loss', self.best_val_loss, epoch)\n",
    "                torch.save(self.model.cpu(), self.best_model_path)\n",
    "                self.model.to(self.device)\n",
    "\n",
    "        # then reload the best model in the end\n",
    "        if self.best_model_path:\n",
    "            print(f\"Reloading best model from {self.best_model_path}\")\n",
    "            self.model.load_state_dict(torch.load(self.best_model_path, weights_only=False).state_dict())\n",
    "            self.model.to(self.device)\n",
    "        \n",
    "        self.writer.close()\n",
    "        return\n",
    "    \n",
    "    def valid(self, content_level_eval=False, prediction_method=\"most_common\"):\n",
    "        self.model.eval()\n",
    "        texts = []\n",
    "        true_labels = []\n",
    "        pred_labels = []\n",
    "        total_logits = []\n",
    "        total_probs = []\n",
    "        total_loss = 0.0\n",
    "        total_steps = 0\n",
    "        \n",
    "        for step, inputs in enumerate(\n",
    "                tqdm(self.data.val_dataloader, desc=\"Iteration\")):\n",
    "            for k, v in inputs.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    inputs[k] = v.to(self.device)\n",
    "            with torch.no_grad():\n",
    "                labels_ = inputs['labels']\n",
    "                output = self.model(inputs['features'], inputs['labels'], inputs['ccfeatures'])\n",
    "                preds = output['preds']\n",
    "    \n",
    "                logits_ = output['logits']\n",
    "                \n",
    "                probabilities = F.softmax(logits_, dim=-1)\n",
    "                \n",
    "                logits = logits_.view(-1, logits_.size(-1))\n",
    "                labels = labels_.view(-1)\n",
    "                loss = self.loss_function(logits, labels)\n",
    "                total_loss += loss.item()\n",
    "                total_steps += 1\n",
    "\n",
    "                texts.extend(inputs['text'])\n",
    "                pred_labels.extend(preds.cpu().tolist())\n",
    "                true_labels.extend(labels_.cpu().tolist())\n",
    "                total_probs.extend(probabilities)\n",
    "\n",
    "        avg_val_loss = total_loss / total_steps\n",
    "        print(f\"Validation Loss: {avg_val_loss}\")\n",
    "        \n",
    "        print(\"*\" * 8, \"Sentence Level Evalation\", \"*\" * 8)\n",
    "        #word_result, sent_result = self.sent_level_eval(texts, true_labels, pred_labels, total_probs, prediction_method)\n",
    "        sent_result = self.sent_level_eval(texts, true_labels, pred_labels, total_probs, prediction_method)\n",
    "        \n",
    "        return avg_val_loss, sent_result\n",
    "    \n",
    "    def test(self, test_dataloader, content_level_eval=False, prediction_method=\"most_common\"):\n",
    "        self.model.eval()\n",
    "        texts = []\n",
    "        true_labels = []\n",
    "        pred_labels = []\n",
    "        total_logits = []\n",
    "        total_probs = []\n",
    "        problem_ids = []\n",
    "        user_ids = []\n",
    "        \n",
    "        for step, inputs in enumerate(\n",
    "                tqdm(test_dataloader, desc=\"Iteration\")):\n",
    "            for k, v in inputs.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    inputs[k] = v.to(self.device)\n",
    "            with torch.no_grad():\n",
    "                labels = inputs['labels']\n",
    "                output = self.model(inputs['features'], inputs['labels'], inputs['ccfeatures'])#, inputs['line_indices'])\n",
    "                logits = output['logits']\n",
    "                preds = output['preds']\n",
    "                problem_id = inputs['problem_id']\n",
    "                user_id = inputs['user_id']\n",
    "                \n",
    "                probabilities = F.softmax(logits, dim=-1)\n",
    "\n",
    "                texts.extend(inputs['text'])\n",
    "                pred_labels.extend(preds.cpu().tolist())\n",
    "                true_labels.extend(labels.cpu().tolist())\n",
    "                problem_ids.extend(problem_id)\n",
    "                user_ids.extend(user_id)\n",
    "                total_logits.extend(logits.cpu().tolist())\n",
    "                total_probs.extend(probabilities)\n",
    "        \n",
    "        line_counts = [len(text.split('\\n')) for text in texts]\n",
    "        \n",
    "        if content_level_eval:\n",
    "            # content level evaluation\n",
    "            print(\"*\" * 8, \"Content Level Evalation\", \"*\" * 8)\n",
    "            content_result = self.content_level_eval(texts, true_labels, pred_labels, total_probs, prediction_method)\n",
    "        else:\n",
    "            content_result = None\n",
    "        print(\"*\" * 8, \"Sentence Level Evalation\", \"*\" * 8)\n",
    "        #word_result, sent_result = self.sent_level_eval(texts, true_labels, pred_labels, total_probs, prediction_method)\n",
    "        sent_result = self.sent_level_eval(texts, true_labels, pred_labels, total_probs, prediction_method)\n",
    "            \n",
    "        # return sent_result, content_result, {'text':texts,'pred':pred_labels, 'true':true_labels, 'problem_id':problem_ids, 'user_id': user_ids}\n",
    "        return sent_result, content_result, {'text': texts, 'pred': pred_labels, 'true': true_labels, 'problem_id':problem_ids, 'user_id':user_ids, 'line_count':line_counts}\n",
    "\n",
    "    \n",
    "    def content_level_eval(self, texts, true_labels, pred_labels, pred_probs, prediction_method='most_common'):\n",
    "        if prediction_method =='threshold':\n",
    "            threshold = self.threshold\n",
    "        else:\n",
    "            threshold = None\n",
    "            pred_labels_threshold = pred_labels\n",
    "        \n",
    "        true_content_labels = []\n",
    "        pred_content_labels = []\n",
    "        pred_content_probs = []\n",
    "        \n",
    "        for text, true_label, pred_label, pred_prob in zip(texts, true_labels, pred_labels_threshold, pred_probs):\n",
    "            true_label = np.array(true_label)\n",
    "            pred_label = np.array(pred_label)\n",
    "            pred_prob = np.array(pred_prob.cpu())\n",
    "            \n",
    "            mask = true_label != -1\n",
    "            true_label = true_label[mask].tolist()\n",
    "            pred_label = pred_label[mask].tolist()\n",
    "            \n",
    "            pred_prob = torch.tensor(pred_prob[mask])\n",
    "            true_common_tag = self._get_most_common_tag(true_label)\n",
    "            true_content_labels.append(true_common_tag[0])\n",
    "            \n",
    "            pred_common_tag = self._get_most_common_tag(pred_label)\n",
    "            pred_content_labels.append(pred_common_tag[0])\n",
    "            \n",
    "            cont_prob = pred_prob[:, 4:8].sum(dim=1)\n",
    "            pred_content_prob = torch.mean(cont_prob, dim=0)\n",
    "            pred_content_probs.append(pred_content_prob.item())\n",
    "            \n",
    "        true_content_labels = [self.en_labels[label] for label in true_content_labels]\n",
    "        pred_content_labels = [self.en_labels[label] for label in pred_content_labels]\n",
    "        \n",
    "        result = self._get_precision_recall_acc_f1(true_content_labels, pred_content_labels, pred_content_probs)\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def sent_level_eval(self, texts, true_labels, pred_labels, pred_probs, prediction_method='most_common'):\n",
    "        if prediction_method =='threshold':\n",
    "            threshold = self.threshold\n",
    "        else:\n",
    "            threshold = None\n",
    "            pred_labels_threshold = pred_labels\n",
    "        \n",
    "        # For line-wise labeling\n",
    "        true_sent_labels = []\n",
    "        pred_sent_labels = []\n",
    "        pred_sent_probs = []\n",
    "        for text, true_label, pred_label, pred_prob in zip(texts, true_labels, pred_labels_threshold, pred_probs):\n",
    "            true_label = np.array(true_label)\n",
    "            pred_label = np.array(pred_label)\n",
    "            pred_prob = np.array(pred_prob.cpu())\n",
    "            mask = true_label != -1\n",
    "            true_label = true_label[mask].tolist()\n",
    "            pred_label = pred_label[mask].tolist()\n",
    "            pred_prob = torch.tensor(pred_prob[mask])\n",
    "            sents = text.split('\\n')\n",
    "            for true_label_idx in range(len(true_label)):\n",
    "                if sents[true_label_idx] == '' or sents[true_label_idx].isspace():  # 빈 문장일 경우 처리하지 않음\n",
    "                    continue\n",
    "                true_sent_label = self.id2label[true_label[true_label_idx]]\n",
    "                pred_sent_label = self.id2label[pred_label[true_label_idx]]\n",
    "                \n",
    "                true_sent_labels.append(true_sent_label.split('-')[-1])\n",
    "                pred_sent_prob = pred_prob[true_label_idx, 4:8].sum()\n",
    "                pred_sent_probs.append(pred_sent_prob.item())\n",
    "                pred_sent_labels.append(pred_sent_label.split('-')[-1])\n",
    "            \n",
    "        true_sent_labels = [self.en_labels[label] for label in true_sent_labels]\n",
    "        pred_sent_labels = [self.en_labels[label] for label in pred_sent_labels]\n",
    "        \n",
    "        sent_result = self._get_precision_recall_acc_f1(true_sent_labels, pred_sent_labels, pred_sent_probs)\n",
    "        return sent_result\n",
    "    \n",
    "    \n",
    "    def _get_threshold_tag(self, logits, machine_threshold=0.5):\n",
    "        human_logits = logits[:, :, :4]  # Human Classes\n",
    "        machine_logits = logits[:, :, 4:] # Machine Classes\n",
    "        human_scores = torch.sum(human_logits, dim=-1)  # Shape: [batch_size, seq_len]\n",
    "        machine_scores = torch.sum(machine_logits, dim=-1)        # Shape: [batch_size, seq_len]\n",
    "        pred_labels = torch.where(machine_scores >= machine_threshold, 4, 0)  # 0 for Human, 4 for AI\n",
    "        \n",
    "        return pred_labels.cpu().tolist()\n",
    "    \n",
    "    def _get_most_common_tag(self, tags):\n",
    "        \"\"\"most_common_tag is a tuple: (tag, times)\"\"\"\n",
    "        from collections import Counter\n",
    "        tags = [self.id2label[tag] for tag in tags]\n",
    "        tags = [tag.split('-')[-1] for tag in tags]\n",
    "        tag_counts = Counter(tags)\n",
    "        most_common_tag = tag_counts.most_common(1)[0]\n",
    "        return most_common_tag\n",
    "    \n",
    "    def _get_precision_recall_acc_f1(self, true_labels, pred_labels, pred_probs=None, pos_label: int = 1) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        true_labels: [0/1]\n",
    "        pred_labels: 이미 threshold가 적용된 0/1 예측\n",
    "        pred_probs : 선택. 점수(양성=pos_label의 확률/로짓 등). 있으면 ROC/AUPRC과 임계값 탐색 리포트 추가.\n",
    "        pos_label  : 양성 클래스(기본 1)\n",
    "        \"\"\"\n",
    "        y_true = np.asarray(true_labels).astype(int)\n",
    "        y_pred = np.asarray(pred_labels).astype(int)\n",
    "\n",
    "        # --- 기본 리포트(주어진 라벨 기준) ---\n",
    "        acc  = accuracy_score(y_true, y_pred)\n",
    "        mF1  = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        bF1  = f1_score(y_true, y_pred, average='binary', pos_label=pos_label, zero_division=0)\n",
    "        prec = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "        rec  = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "        cm   = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "\n",
    "        print(\"=== Given labels (as-is) ===\")\n",
    "        print(\"Accuracy: {:.3f}\".format(acc*100))\n",
    "        print(\"Macro F1 Score: {:.3f}\".format(mF1*100))\n",
    "        print(\"Binary F1 Score (pos): {:.3f}\".format(bF1*100))\n",
    "        print(\"Precision/Recall per class:\")\n",
    "        print(\"{:.1f},{:.1f},{:.1f},{:.1f}\".format(prec[0]*100, rec[0]*100, prec[1]*100, rec[1]*100))\n",
    "        print(f\"CM [[TN FP],[FN TP]] = {cm.tolist()}\")\n",
    "\n",
    "        # 결과 dict 시작\n",
    "        result: Dict[str, Any] = {\n",
    "            \"given_labels\": {\n",
    "                \"accuracy\": acc, \"macro_f1\": mF1, \"binary_f1\": bF1,\n",
    "                \"precision\": prec, \"recall\": rec, \"cm\": cm\n",
    "            },\n",
    "            \"roc_auc\": None,\n",
    "            \"auprc\": None,\n",
    "            \"thresholds\": {}\n",
    "        }\n",
    "\n",
    "        # --- 점수 기반 추가 리포트 ---\n",
    "        if pred_probs is not None:\n",
    "            y_score = np.asarray(pred_probs, dtype=float)\n",
    "\n",
    "            # ROC / AUPRC\n",
    "            try:\n",
    "                fpr, tpr, thr_roc = roc_curve(y_true, y_score, pos_label=pos_label)\n",
    "                roc_auc = float(auc(fpr, tpr))\n",
    "            except Exception:\n",
    "                roc_auc = None\n",
    "\n",
    "            try:\n",
    "                auprc = float(average_precision_score(y_true, y_score, pos_label=pos_label))\n",
    "            except Exception:\n",
    "                auprc = None\n",
    "\n",
    "            print(f\"ROC_AUC (fpr-tpr): {roc_auc:.3f}\" if roc_auc is not None else \"ROC_AUC: N/A\")\n",
    "            print(f\"AUPRC: {auprc:.3f}\" if auprc is not None else \"AUPRC: N/A\")\n",
    "\n",
    "            # Helper: 특정 threshold에서 평가\n",
    "            def eval_at(thr: float, tag: str) -> Dict[str, Any]:\n",
    "                y_hat = (y_score > thr).astype(int)\n",
    "                acc_  = accuracy_score(y_true, y_hat)\n",
    "                mF1_  = f1_score(y_true, y_hat, average='macro', zero_division=0)\n",
    "                bF1_  = f1_score(y_true, y_hat, average='binary', pos_label=pos_label, zero_division=0)\n",
    "                pr_   = precision_score(y_true, y_hat, average=None, zero_division=0)\n",
    "                rc_   = recall_score(y_true, y_hat, average=None, zero_division=0)\n",
    "                cm_   = confusion_matrix(y_true, y_hat, labels=[0,1])\n",
    "                print(f\"[{tag}] thr={thr:.3f} | Acc={acc_*100:.1f}  MacroF1={mF1_*100:.1f}  BinF1(pos)={bF1_*100:.1f}\")\n",
    "                print(\" P/R per class -> 0(H): {:.1f}/{:.1f} , 1(AI): {:.1f}/{:.1f}\".format(pr_[0]*100, rc_[0]*100, pr_[1]*100, rc_[1]*100))\n",
    "                print(f\" CM [[TN FP],[FN TP]] = {cm_.tolist()}\")\n",
    "                return {\"thr\": float(thr), \"accuracy\": acc_, \"macro_f1\": mF1_, \"binary_f1\": bF1_, \"precision\": pr_, \"recall\": rc_, \"cm\": cm_}\n",
    "\n",
    "            # Youden J (TPR - FPR) 최대\n",
    "            def best_thr_youden() -> float:\n",
    "                if roc_auc is None or len(thr_roc) == 0:\n",
    "                    return 0.5\n",
    "                J = tpr - fpr\n",
    "                i = int(np.argmax(J))\n",
    "                return float(thr_roc[i])\n",
    "\n",
    "            # 양성 F1 최대(PR 기반)\n",
    "            def best_thr_posF1() -> float:\n",
    "                prec_curve, rec_curve, thr_pr = precision_recall_curve(y_true, y_score, pos_label=pos_label)\n",
    "                if len(thr_pr) == 0:\n",
    "                    return 0.5\n",
    "                f1_curve = (2 * prec_curve * rec_curve) / (prec_curve + rec_curve + 1e-12)\n",
    "                i = int(np.nanargmax(f1_curve[:-1]))  # 마지막 점은 threshold 없음\n",
    "                return float(thr_pr[i])\n",
    "\n",
    "            thr05     = 0.5\n",
    "            thrJ      = best_thr_youden()\n",
    "            thrBestF1 = best_thr_posF1()\n",
    "\n",
    "            print(\"=== Threshold sweeps on scores ===\")\n",
    "            res05  = eval_at(thr05, \"thr=0.5\")\n",
    "            resJ   = eval_at(thrJ, \"thr=YoudenJ\")\n",
    "            resF1  = eval_at(thrBestF1, \"thr=bestPosF1\")\n",
    "\n",
    "            result.update({\n",
    "                \"roc_auc\": roc_auc,\n",
    "                \"auprc\": auprc,\n",
    "                \"thresholds\": {\n",
    "                    \"thr@0.5\": res05,\n",
    "                    \"thr@youden\": resJ,\n",
    "                    \"thr@best_posF1\": resF1\n",
    "                }\n",
    "            })\n",
    "        else:\n",
    "            print(\"ROC_AUC (fpr-tpr): N/A (pred_probs is None)\")\n",
    "            print(\"AUPRC: N/A (pred_probs is None)\")\n",
    "\n",
    "        # CSV 한 줄 요약(기존 포맷과 유사)\n",
    "        pr_line = \"{:.1f},{:.1f},{:.1f},{:.1f}\".format(prec[0]*100, rec[0]*100, prec[1]*100, rec[1]*100)\n",
    "        print(\"{:.1f},{:.1f},{:.1f},{},{:.3f},{}\".format(\n",
    "            acc*100, mF1*100, bF1*100, pr_line, result[\"roc_auc\"] if result[\"roc_auc\"] is not None else float(\"nan\"),\n",
    "            f\"{result['auprc']:.3f}\" if result[\"auprc\"] is not None else \"N/A\"\n",
    "        ))\n",
    "\n",
    "        return result\n",
    "    # def _get_precision_recall_acc_f1(self, true_labels, pred_labels, pred_probs = None):\n",
    "    #     accuracy = accuracy_score(true_labels, pred_labels)\n",
    "    #     macro_f1 = f1_score(true_labels, pred_labels, average='macro')\n",
    "    #     binary_f1 = f1_score(true_labels, pred_labels, average='binary')\n",
    "    #     print(\"Accuracy: {:.3f}\".format(accuracy*100))\n",
    "    #     print(\"Macro F1 Score: {:.3f}\".format(macro_f1*100))\n",
    "    #     print(\"Binary F1 Score: {:.3f}\".format(binary_f1*100))\n",
    "\n",
    "    #     precision = precision_score(true_labels, pred_labels, average=None)\n",
    "    #     recall = recall_score(true_labels, pred_labels, average=None)\n",
    "    #     print(\"Precision/Recall per class: \")\n",
    "    #     precision_recall = ','.join([\"{:.1f},{:.1f}\".format(p*100, r*100) for p, r in zip(precision, recall)])\n",
    "    #     print(precision_recall)\n",
    "    #     roc_auc = get_roc_metrics(true_labels, pred_probs)\n",
    "    #     print(f\"ROC_AUC (fpr-tpr): {roc_auc:.3f}\")\n",
    "        \n",
    "    #     if pred_probs is not None:\n",
    "    #         pred_probs = np.array(pred_probs)\n",
    "    #         ai_probs = pred_probs\n",
    "    #         auprc = average_precision_score(true_labels, ai_probs)\n",
    "    #         print(f\"AUPRC: {auprc:.3f}\")\n",
    "    #     else:\n",
    "    #         auprc = None\n",
    "    #         print(\"AUPRC: N/A (pred_probs in None)\")\n",
    "    #     result = {\"precision\":precision, \"recall\":recall, \"accuracy\":accuracy, \"macro_f1\":macro_f1, \"binary_f1\": binary_f1, \"roc_auc\":roc_auc, \"auprc\": auprc}\n",
    "    #     print(\"{:.1f},{:.1f},{:.1f},{},{:.3f},{:.3f}\".format(accuracy*100, macro_f1*100, binary_f1*100,precision_recall,roc_auc, auprc))\n",
    "    #     return result\n",
    "\n",
    "\n",
    "def construct_bmes_labels(labels):\n",
    "    prefix = ['B-', 'M-', 'E-', 'S-']\n",
    "    id2label = {}\n",
    "    counter = 0\n",
    "\n",
    "    for label, id in labels.items():\n",
    "        for pre in prefix:\n",
    "            id2label[counter] = pre + label\n",
    "            counter += 1\n",
    "    \n",
    "    return id2label\n",
    "\n",
    "def remove_duplicates(prob_dict):\n",
    "    total_p = 0\n",
    "    total = 0\n",
    "    for problem_id, entries in prob_dict.items():\n",
    "        n = 0\n",
    "        unique_texts = set()\n",
    "        unique_entries = []\n",
    "        \n",
    "        for entry in entries:\n",
    "            if entry['text'] not in unique_texts:\n",
    "                unique_entries.append(entry)\n",
    "                unique_texts.add(entry['text'])\n",
    "            else:\n",
    "                n += 1\n",
    "        if n != 0:\n",
    "            total_p += 1\n",
    "        total += n\n",
    "        \n",
    "        prob_dict[problem_id] = unique_entries     \n",
    "\n",
    "# def split_dataset(data_path, dataset):\n",
    "#     with open(data_path+f\"/codenet(python)_{dataset}_features_aigcodeset.jsonl\", 'r') as f:\n",
    "#         full_samples = [json.loads(line) for line in f]\n",
    "    \n",
    "#     seed_everything(42)\n",
    "    \n",
    "#     labels = [sample['label'] for sample in full_samples]\n",
    "    \n",
    "#     train_samples, test_samples = train_test_split(\n",
    "#         full_samples, test_size=0.2, stratify=labels, random_state=42\n",
    "#     )\n",
    "\n",
    "#     # Validation set을 train에서 10%만 샘플링 (stratified 유지)\n",
    "#     train_samples, val_samples = train_test_split(\n",
    "#         train_samples, test_size=0.1, stratify=[s['label'] for s in train_samples], random_state=42\n",
    "#     )\n",
    "        \n",
    "#     print(f\"Train: {len(train_samples)}, Validation: {len(val_samples)}, Test: {len(test_samples)}\")\n",
    "    \n",
    "#     return [train_samples, val_samples, test_samples]\n",
    "    \n",
    "\n",
    "# def split_dataset(data_path, dataset):\n",
    "#     # Train (full set)\n",
    "#     with open(data_path+f\"/codenet(python)_{dataset}_features_all_models.jsonl\", 'r') as f:\n",
    "#         full_train_set = [json.loads(line) for line in f]\n",
    "    \n",
    "#     seed_everything(42)\n",
    "\n",
    "#     for sample in full_train_set:\n",
    "#             if 'line' in dataset:\n",
    "#                 ccfeature_line = analyze_pylint_output_line(sample['eval'], len(sample['text'].split('\\n')))\n",
    "#                 sample['ccfeature'] = ccfeature_line\n",
    "#             else:\n",
    "#                 sample['ccfeature'] = analyze_pylint_output(sample['eval'])\n",
    "\n",
    "#     labels = [sample['label'] for sample in full_train_set]\n",
    "#     train_set, test_set = train_test_split(full_train_set, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "#     train_set, val_set = train_test_split(train_set, test_size=0.1, random_state=42, stratify=[s['label'] for s in train_set])\n",
    "#     print(f\"Train: {len(train_set)}, Validation: {len(val_set)}, Test: {len(test_set)}\")\n",
    "#     # ai = 0\n",
    "#     # filtered_test_set = []\n",
    "#     # for sample in test_set:\n",
    "#     #     if sample['label'] == 'AI' and sample.get('status_in_folder') == \"Wrong\":\n",
    "#     #         filtered_test_set.append(sample)\n",
    "#     #         ai += 1\n",
    "#     #     elif sample['label'] == 'human':\n",
    "#     #         filtered_test_set.append(sample)\n",
    "    \n",
    "#     # print(f\"Train: {len(train_set)}, Validation: {len(val_set)}, Test: {len(filtered_test_set)}\")\n",
    "#     # print(f\"the number of AI code: {ai}\")\n",
    "#     # return [train_set, val_set, filtered_test_set]\n",
    "    \n",
    "#     return [train_set, val_set, test_set]\n",
    "    # # data filtering for test_set\n",
    "    # filtered_test_set = []\n",
    "    # for sample in test_set:\n",
    "    #     if sample['label'] == 'human' and sample.get('status_in_folder') == 'Accepted':\n",
    "    #         filtered_test_set.append(sample)\n",
    "    #     elif sample['label'] == 'AI' and sample.get('LLM') == 'GEMINI':\n",
    "    #         filtered_test_set.append(sample)\n",
    "    \n",
    "        \n",
    "    # print(f\"Train: {len(train_set)}, Validation: {len(val_set)}, Test: {len(filtered_test_set)}\")\n",
    "\n",
    "    # return [train_set, val_set, filtered_test_set] # 여기도 수정!\n",
    "    # ===================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6d686ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def warn_group_overlap(groups_arr, idx_a, idx_b, name_a=\"A\", name_b=\"B\"):\n",
    "    ga = set(groups_arr[idx_a])\n",
    "    gb = set(groups_arr[idx_b])\n",
    "    inter = ga & gb\n",
    "    if inter:\n",
    "        print(f\"[WARN] {name_a} and {name_b} share {len(inter)} problem_ids (leak risk).\")\n",
    "    else:\n",
    "        print(f\"[OK] No problem_id overlap between {name_a} and {name_b}.\")\n",
    "\n",
    "def split_dataset(data_path, dataset, seed=42, test_size=0.2, val_size=0.1):\n",
    "    # 1) Load full set\n",
    "    with open(os.path.join(data_path, f\"codenet(python)_{dataset}_features.jsonl\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        #full_train_set = [json.loads(line) for line in f]\n",
    "\n",
    "        full_train_set = []\n",
    "        for line in f:\n",
    "            dumped_line = json.loads(line)\n",
    "            dumped_line[\"user_id\"] = \"\"\n",
    "            if dumped_line[\"LLM\"] == \"Human\":\n",
    "                dumped_line[\"label_int\"] = 0\n",
    "            else:\n",
    "                dumped_line[\"label_int\"] = 1\n",
    "\n",
    "            full_train_set.append(dumped_line)\n",
    "\n",
    "\n",
    "\n",
    "    # full_train_set = [x for x in full_train_set if x.get(\"LLM\") != \"GPT3.5\" and x.get(\"LLM\") != \"GEMINI\"]\n",
    "    seed_everything(seed)\n",
    "\n",
    "    # 2) Build features (pylint 기반)\n",
    "    for i, sample in enumerate(full_train_set):\n",
    "        # problem_id가 없을 수도 있으니 안전하게 기본값\n",
    "        if sample.get(\"problem_id\") is None:\n",
    "            sample[\"problem_id\"] = f\"__none__#{i}\"\n",
    "\n",
    "        if 'line' in dataset:\n",
    "            n_lines = len(sample.get('text', '').split('\\n'))\n",
    "            ccfeature_line = analyze_pylint_output_line(sample.get('eval', ''), n_lines)\n",
    "            sample['ccfeature'] = ccfeature_line\n",
    "        else:\n",
    "            sample['ccfeature'] = analyze_pylint_output(sample.get('eval', ''))\n",
    "\n",
    "    # 3) Arrays for splitting\n",
    "    labels = np.array([sample['label'] for sample in full_train_set])\n",
    "    groups = np.array([sample['problem_id'] for sample in full_train_set])\n",
    "\n",
    "    # 4) Group-aware Train/Test split\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=seed)\n",
    "    train_full_idx, test_idx = next(\n",
    "        gss.split(\n",
    "            np.zeros(len(full_train_set)),\n",
    "            labels,\n",
    "            groups=groups\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 5) Group-aware Train/Val split (within train_full)\n",
    "    gss_val = GroupShuffleSplit(n_splits=1, test_size=val_size, random_state=seed)\n",
    "    train_idx, val_idx = next(\n",
    "        gss_val.split(\n",
    "            np.zeros(len(train_full_idx)),\n",
    "            labels[train_full_idx],\n",
    "            groups=groups[train_full_idx]\n",
    "        )\n",
    "    )\n",
    "    # 인덱스를 원본 기준으로 변환\n",
    "    train_idx = train_full_idx[train_idx]\n",
    "    val_idx   = train_full_idx[val_idx]\n",
    "\n",
    "    # 6) 누수(그룹 겹침) 점검\n",
    "    warn_group_overlap(groups, train_idx, val_idx, \"Train\", \"Val\")\n",
    "    warn_group_overlap(groups, train_idx, test_idx, \"Train\", \"Test\")\n",
    "    warn_group_overlap(groups, val_idx,   test_idx, \"Val\",   \"Test\")\n",
    "\n",
    "    # 7) 실제 세트 구성\n",
    "    train_set = [full_train_set[i] for i in train_idx]\n",
    "    val_set   = [full_train_set[i] for i in val_idx]\n",
    "    test_set  = [full_train_set[i] for i in test_idx]\n",
    "\n",
    "    # 8) 라벨 분포 확인(옵션이지만 유용)\n",
    "    def distrib(name, arr):\n",
    "        c = Counter([s['label'] for s in arr])\n",
    "        total = len(arr)\n",
    "        print(f\"{name}: {total}  | human={c.get('human',0)} ({c.get('human',0)/total:.2%}), AI={c.get('AI',0)} ({c.get('AI',0)/total:.2%})\")\n",
    "\n",
    "    print(f\"Train: {len(train_set)}, Validation: {len(val_set)}, Test: {len(test_set)}\")\n",
    "    distrib(\"Train\", train_set)\n",
    "    distrib(\"Val\",   val_set)\n",
    "    distrib(\"Test\",  test_set)\n",
    "    \n",
    "    \n",
    "    # ai = 0\n",
    "    # filtered_test_set = []\n",
    "    # for sample in test_set:\n",
    "    #     if sample['LLM'] == 'GPT3.5':\n",
    "    #         filtered_test_set.append(sample)\n",
    "    #         ai += 1\n",
    "    # print(f\"Train: {len(train_set)}, Validation: {len(val_set)}, Test: {len(filtered_test_set)}\")\n",
    "    \n",
    "    \n",
    "    # test_save_path = \"./codenet(python)_python_document_level_merged_file_test_0820.jsonl\"\n",
    "    # with open(test_save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    #     for sample in test_set:\n",
    "    #         f.write(json.dumps(sample, ensure_ascii=False) + \"\\n\")\n",
    "    # print(f\"Test set saved to {test_save_path}\")\n",
    "    # exit\n",
    "    return [train_set, val_set, test_set]\n",
    "\n",
    "# import json\n",
    "# import random\n",
    "# from collections import defaultdict\n",
    "\n",
    "# def split_dataset(data_path, dataset):\n",
    "#     # 데이터 로딩\n",
    "#     with open(data_path + f\"/codenet(python)_{dataset}_features.jsonl\", 'r') as f:\n",
    "#         total_samples = [json.loads(line) for line in f]\n",
    "\n",
    "#     # seed 고정\n",
    "#     seed_everything(42)\n",
    "\n",
    "#     # 문제 ID 기준 그룹화 + ccfeature 추가\n",
    "#     prob_dict = defaultdict(list)\n",
    "#     for i in total_samples:\n",
    "#         if 'line' in dataset:\n",
    "#             ccfeature_line = analyze_pylint_output_line(i['eval'], len(i['text'].split('\\n')))\n",
    "#             i['ccfeature'] = ccfeature_line\n",
    "#         else:\n",
    "#             i['ccfeature'] = analyze_pylint_output(i['eval'])\n",
    "#         prob_dict[i['problem_id']].append(i)\n",
    "\n",
    "#     prob_list = list(prob_dict.keys())\n",
    "    \n",
    "#     # revised인 경우 전체 반환\n",
    "#     if 'revised' in dataset:\n",
    "#         df_test = []\n",
    "#         for p in prob_list:\n",
    "#             df_test.extend(prob_dict[p])\n",
    "#         return {0: (df_test, df_test, df_test)}\n",
    "\n",
    "#     # fold split: 문제 ID 단위로 겹치지 않게 나눔\n",
    "#     random.shuffle(prob_list)\n",
    "#     fold_size = len(prob_list) // 3\n",
    "#     folds = [prob_list[i * fold_size: (i + 1) * fold_size] for i in range(3)]\n",
    "\n",
    "#     df_ = {}\n",
    "#     for fold in range(3):\n",
    "#         print(f\"\\n[Fold {fold}]\")\n",
    "#         test_ids = folds[fold]\n",
    "#         val_ids = folds[(fold + 1) % 3]\n",
    "#         train_ids = [pid for i in range(3) if i != fold and i != (fold + 1) % 3 for pid in folds[i]]\n",
    "\n",
    "#         df_train = [s for pid in train_ids for s in prob_dict[pid]]\n",
    "#         df_valid = [s for pid in val_ids for s in prob_dict[pid]]\n",
    "#         df_test  = [s for pid in test_ids for s in prob_dict[pid]]\n",
    "\n",
    "#         print(f\"Train: {len(df_train)} / Valid: {len(df_valid)} / Test: {len(df_test)}\")\n",
    "#         df_[fold] = (df_train, df_valid, df_test)\n",
    "\n",
    "#     return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1501f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model', type=str, default='Transformer')\n",
    "    parser.add_argument('--gpu', type=str, default='0')\n",
    "    parser.add_argument('--train_mode', type=str, default='classify')\n",
    "    parser.add_argument('--batch_size', type=int, default=32)\n",
    "    parser.add_argument('--seq_len', type=int, default=1024)\n",
    "    parser.add_argument('--dataset', type=str, default=\"\")\n",
    "    parser.add_argument('--method', type=str, default=\"focalbmesbinary_embedconcat_transformer256\")\n",
    "    \n",
    "    parser.add_argument('--train_ratio', type=float, default=0.9)\n",
    "    parser.add_argument('--split_dataset', action='store_true')\n",
    "    parser.add_argument('--data_path', type=str, default='')\n",
    "    parser.add_argument('--train_path', type=str, default='')\n",
    "    parser.add_argument('--valid_path', type=str, default='')\n",
    "    parser.add_argument('--test_path', type=str, default='')\n",
    "\n",
    "    parser.add_argument('--num_train_epochs', type=int, default=20)\n",
    "    parser.add_argument('--weight_decay', type=float, default=0.1)\n",
    "    parser.add_argument('--lr', type=float, default=5e-5)\n",
    "    parser.add_argument('--warm_up_ratio', type=float, default=0.1)\n",
    "    parser.add_argument('--seed', type=int, default=42, required=True)\n",
    "    parser.add_argument('--do_test', action='store_true')\n",
    "    parser.add_argument('--test_content', action='store_true')\n",
    "    \n",
    "    parser.add_argument('--ckpt_name', type=str, default='')\n",
    "    parser.add_argument('--alpha', type=float, default=0.5)\n",
    "    parser.add_argument('--testbed', type=str, required=True)\n",
    "    \n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bba197f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log INFO: split dataset...\n",
      "[OK] No problem_id overlap between Train and Val.\n",
      "[OK] No problem_id overlap between Train and Test.\n",
      "[OK] No problem_id overlap between Val and Test.\n",
      "Train: 1992, Validation: 231, Test: 564\n",
      "Train: 1992  | human=0 (0.00%), AI=1992 (100.00%)\n",
      "Val: 231  | human=0 (0.00%), AI=231 (100.00%)\n",
      "Test: 564  | human=0 (0.00%), AI=564 (100.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [00:00<00:00, 4235.24it/s]\n",
      "100%|██████████| 231/231 [00:00<00:00, 21684.96it/s]\n",
      "100%|██████████| 564/564 [00:00<00:00, 21888.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log INFO: do train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:33<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: train_loss 0.04996196831029559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.3829176872968674\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 67.122\n",
      "Macro F1 Score: 40.163\n",
      "Binary F1 Score (pos): 0.000\n",
      "Precision/Recall per class:\n",
      "67.1,100.0,0.0,0.0\n",
      "CM [[TN FP],[FN TP]] = [[3148, 0], [1542, 0]]\n",
      "ROC_AUC (fpr-tpr): 0.492\n",
      "AUPRC: 0.311\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=67.1  MacroF1=40.2  BinF1(pos)=0.0\n",
      " P/R per class -> 0(H): 67.1/100.0 , 1(AI): 0.0/0.0\n",
      " CM [[TN FP],[FN TP]] = [[3148, 0], [1542, 0]]\n",
      "[thr=YoudenJ] thr=0.200 | Acc=52.0  MacroF1=50.5  BinF1(pos)=41.8\n",
      " P/R per class -> 0(H): 69.0/51.8 , 1(AI): 34.8/52.4\n",
      " CM [[TN FP],[FN TP]] = [[1631, 1517], [734, 808]]\n",
      "[thr=bestPosF1] thr=0.174 | Acc=35.5  MacroF1=29.5  BinF1(pos)=50.0\n",
      " P/R per class -> 0(H): 84.2/4.7 , 1(AI): 33.5/98.2\n",
      " CM [[TN FP],[FN TP]] = [[149, 2999], [28, 1514]]\n",
      "67.1,40.2,0.0,67.1,100.0,0.0,0.0,0.492,0.311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:33<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: train_loss 0.036352718396792334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:05<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.246462494134903\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 67.122\n",
      "Macro F1 Score: 40.163\n",
      "Binary F1 Score (pos): 0.000\n",
      "Precision/Recall per class:\n",
      "67.1,100.0,0.0,0.0\n",
      "CM [[TN FP],[FN TP]] = [[3148, 0], [1542, 0]]\n",
      "ROC_AUC (fpr-tpr): 0.707\n",
      "AUPRC: 0.523\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=67.1  MacroF1=40.2  BinF1(pos)=0.0\n",
      " P/R per class -> 0(H): 67.1/100.0 , 1(AI): 0.0/0.0\n",
      " CM [[TN FP],[FN TP]] = [[3148, 0], [1542, 0]]\n",
      "[thr=YoudenJ] thr=0.171 | Acc=57.3  MacroF1=57.3  BinF1(pos)=56.3\n",
      " P/R per class -> 0(H): 84.8/44.3 , 1(AI): 42.4/83.7\n",
      " CM [[TN FP],[FN TP]] = [[1396, 1752], [251, 1291]]\n",
      "[thr=bestPosF1] thr=0.171 | Acc=57.3  MacroF1=57.3  BinF1(pos)=56.3\n",
      " P/R per class -> 0(H): 84.8/44.3 , 1(AI): 42.4/83.7\n",
      " CM [[TN FP],[FN TP]] = [[1396, 1752], [251, 1291]]\n",
      "67.1,40.2,0.0,67.1,100.0,0.0,0.0,0.707,0.523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:32<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: train_loss 0.03397092716916213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:05<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.032549187541008\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 74.520\n",
      "Macro F1 Score: 65.733\n",
      "Binary F1 Score (pos): 48.380\n",
      "Precision/Recall per class:\n",
      "74.9,93.2,72.4,36.3\n",
      "CM [[TN FP],[FN TP]] = [[2935, 213], [982, 560]]\n",
      "ROC_AUC (fpr-tpr): 0.790\n",
      "AUPRC: 0.643\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=73.8  MacroF1=63.2  BinF1(pos)=43.5\n",
      " P/R per class -> 0(H): 73.7/94.9 , 1(AI): 74.6/30.7\n",
      " CM [[TN FP],[FN TP]] = [[2987, 161], [1068, 474]]\n",
      "[thr=YoudenJ] thr=0.281 | Acc=73.0  MacroF1=70.5  BinF1(pos)=61.9\n",
      " P/R per class -> 0(H): 82.3/76.1 , 1(AI): 57.8/66.7\n",
      " CM [[TN FP],[FN TP]] = [[2396, 752], [514, 1028]]\n",
      "[thr=bestPosF1] thr=0.279 | Acc=72.9  MacroF1=70.4  BinF1(pos)=61.9\n",
      " P/R per class -> 0(H): 82.4/75.8 , 1(AI): 57.5/67.0\n",
      " CM [[TN FP],[FN TP]] = [[2385, 763], [509, 1033]]\n",
      "74.5,65.7,48.4,74.9,93.2,72.4,36.3,0.790,0.643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:33<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: train_loss 0.031550832004064604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:05<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.953242652118206\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 75.330\n",
      "Macro F1 Score: 65.373\n",
      "Binary F1 Score (pos): 46.805\n",
      "Precision/Recall per class:\n",
      "74.5,96.1,80.4,33.0\n",
      "CM [[TN FP],[FN TP]] = [[3024, 124], [1033, 509]]\n",
      "ROC_AUC (fpr-tpr): 0.796\n",
      "AUPRC: 0.659\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=73.8  MacroF1=62.6  BinF1(pos)=42.1\n",
      " P/R per class -> 0(H): 73.4/95.8 , 1(AI): 77.3/28.9\n",
      " CM [[TN FP],[FN TP]] = [[3017, 131], [1096, 446]]\n",
      "[thr=YoudenJ] thr=0.209 | Acc=71.9  MacroF1=69.7  BinF1(pos)=61.5\n",
      " P/R per class -> 0(H): 82.6/73.7 , 1(AI): 56.0/68.4\n",
      " CM [[TN FP],[FN TP]] = [[2319, 829], [488, 1054]]\n",
      "[thr=bestPosF1] thr=0.165 | Acc=68.2  MacroF1=67.3  BinF1(pos)=61.9\n",
      " P/R per class -> 0(H): 85.8/63.0 , 1(AI): 51.0/78.8\n",
      " CM [[TN FP],[FN TP]] = [[1982, 1166], [327, 1215]]\n",
      "75.3,65.4,46.8,74.5,96.1,80.4,33.0,0.796,0.659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:32<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: train_loss 0.03004901051994354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.8525397256016731\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 76.652\n",
      "Macro F1 Score: 68.509\n",
      "Binary F1 Score (pos): 52.495\n",
      "Precision/Recall per class:\n",
      "76.1,95.0,79.3,39.2\n",
      "CM [[TN FP],[FN TP]] = [[2990, 158], [937, 605]]\n",
      "ROC_AUC (fpr-tpr): 0.819\n",
      "AUPRC: 0.687\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=74.9  MacroF1=65.7  BinF1(pos)=47.9\n",
      " P/R per class -> 0(H): 74.8/94.5 , 1(AI): 75.7/35.1\n",
      " CM [[TN FP],[FN TP]] = [[2974, 174], [1001, 541]]\n",
      "[thr=YoudenJ] thr=0.248 | Acc=73.6  MacroF1=71.8  BinF1(pos)=64.7\n",
      " P/R per class -> 0(H): 85.0/73.6 , 1(AI): 57.7/73.5\n",
      " CM [[TN FP],[FN TP]] = [[2316, 832], [408, 1134]]\n",
      "[thr=bestPosF1] thr=0.248 | Acc=73.6  MacroF1=71.8  BinF1(pos)=64.7\n",
      " P/R per class -> 0(H): 85.0/73.6 , 1(AI): 57.7/73.5\n",
      " CM [[TN FP],[FN TP]] = [[2316, 832], [408, 1134]]\n",
      "76.7,68.5,52.5,76.1,95.0,79.3,39.2,0.819,0.687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:32<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: train_loss 0.029299531545903947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:05<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.8280503004789352\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 76.013\n",
      "Macro F1 Score: 66.608\n",
      "Binary F1 Score (pos): 48.887\n",
      "Precision/Recall per class:\n",
      "75.1,96.2,81.6,34.9\n",
      "CM [[TN FP],[FN TP]] = [[3027, 121], [1004, 538]]\n",
      "ROC_AUC (fpr-tpr): 0.831\n",
      "AUPRC: 0.706\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=75.4  MacroF1=65.3  BinF1(pos)=46.6\n",
      " P/R per class -> 0(H): 74.5/96.3 , 1(AI): 81.3/32.7\n",
      " CM [[TN FP],[FN TP]] = [[3032, 116], [1038, 504]]\n",
      "[thr=YoudenJ] thr=0.192 | Acc=74.6  MacroF1=72.8  BinF1(pos)=65.9\n",
      " P/R per class -> 0(H): 85.8/74.6 , 1(AI): 59.0/74.7\n",
      " CM [[TN FP],[FN TP]] = [[2347, 801], [390, 1152]]\n",
      "[thr=bestPosF1] thr=0.192 | Acc=74.6  MacroF1=72.8  BinF1(pos)=65.9\n",
      " P/R per class -> 0(H): 85.8/74.6 , 1(AI): 59.0/74.7\n",
      " CM [[TN FP],[FN TP]] = [[2347, 801], [390, 1152]]\n",
      "76.0,66.6,48.9,75.1,96.2,81.6,34.9,0.831,0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:32<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: train_loss 0.028878397234375516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:05<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.8255745619535446\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 75.842\n",
      "Macro F1 Score: 66.004\n",
      "Binary F1 Score (pos): 47.716\n",
      "Precision/Recall per class:\n",
      "74.8,96.6,82.7,33.5\n",
      "CM [[TN FP],[FN TP]] = [[3040, 108], [1025, 517]]\n",
      "ROC_AUC (fpr-tpr): 0.832\n",
      "AUPRC: 0.712\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=74.9  MacroF1=63.8  BinF1(pos)=43.7\n",
      " P/R per class -> 0(H): 73.8/97.1 , 1(AI): 83.5/29.6\n",
      " CM [[TN FP],[FN TP]] = [[3058, 90], [1086, 456]]\n",
      "[thr=YoudenJ] thr=0.159 | Acc=74.3  MacroF1=72.6  BinF1(pos)=65.6\n",
      " P/R per class -> 0(H): 85.6/74.2 , 1(AI): 58.6/74.5\n",
      " CM [[TN FP],[FN TP]] = [[2337, 811], [393, 1149]]\n",
      "[thr=bestPosF1] thr=0.159 | Acc=74.3  MacroF1=72.6  BinF1(pos)=65.6\n",
      " P/R per class -> 0(H): 85.6/74.2 , 1(AI): 58.6/74.5\n",
      " CM [[TN FP],[FN TP]] = [[2337, 811], [393, 1149]]\n",
      "75.8,66.0,47.7,74.8,96.6,82.7,33.5,0.832,0.712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:32<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8: train_loss 0.028617681905863775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:05<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7775556221604347\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 76.866\n",
      "Macro F1 Score: 68.075\n",
      "Binary F1 Score (pos): 51.323\n",
      "Precision/Recall per class:\n",
      "75.8,96.3,83.3,37.1\n",
      "CM [[TN FP],[FN TP]] = [[3033, 115], [970, 572]]\n",
      "ROC_AUC (fpr-tpr): 0.845\n",
      "AUPRC: 0.732\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=75.9  MacroF1=66.2  BinF1(pos)=48.0\n",
      " P/R per class -> 0(H): 74.9/96.6 , 1(AI): 83.0/33.8\n",
      " CM [[TN FP],[FN TP]] = [[3041, 107], [1021, 521]]\n",
      "[thr=YoudenJ] thr=0.192 | Acc=76.2  MacroF1=74.3  BinF1(pos)=67.3\n",
      " P/R per class -> 0(H): 86.1/76.9 , 1(AI): 61.3/74.6\n",
      " CM [[TN FP],[FN TP]] = [[2422, 726], [391, 1151]]\n",
      "[thr=bestPosF1] thr=0.197 | Acc=76.4  MacroF1=74.5  BinF1(pos)=67.3\n",
      " P/R per class -> 0(H): 85.9/77.7 , 1(AI): 61.9/73.9\n",
      " CM [[TN FP],[FN TP]] = [[2446, 702], [403, 1139]]\n",
      "76.9,68.1,51.3,75.8,96.3,83.3,37.1,0.845,0.732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:33<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9: train_loss 0.028052987678656504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:05<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7292047441005707\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 79.168\n",
      "Macro F1 Score: 74.325\n",
      "Binary F1 Score (pos): 63.174\n",
      "Precision/Recall per class:\n",
      "80.3,91.3,75.4,54.3\n",
      "CM [[TN FP],[FN TP]] = [[2875, 273], [704, 838]]\n",
      "ROC_AUC (fpr-tpr): 0.853\n",
      "AUPRC: 0.746\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=78.8  MacroF1=73.4  BinF1(pos)=61.5\n",
      " P/R per class -> 0(H): 79.5/92.1 , 1(AI): 76.2/51.6\n",
      " CM [[TN FP],[FN TP]] = [[2899, 249], [746, 796]]\n",
      "[thr=YoudenJ] thr=0.343 | Acc=78.4  MacroF1=75.9  BinF1(pos)=68.2\n",
      " P/R per class -> 0(H): 85.0/82.4 , 1(AI): 66.1/70.3\n",
      " CM [[TN FP],[FN TP]] = [[2593, 555], [458, 1084]]\n",
      "[thr=bestPosF1] thr=0.343 | Acc=78.4  MacroF1=75.9  BinF1(pos)=68.2\n",
      " P/R per class -> 0(H): 85.0/82.4 , 1(AI): 66.1/70.3\n",
      " CM [[TN FP],[FN TP]] = [[2593, 555], [458, 1084]]\n",
      "79.2,74.3,63.2,80.3,91.3,75.4,54.3,0.853,0.746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:33<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10: train_loss 0.027808418733969567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:05<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7218530997633934\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 78.145\n",
      "Macro F1 Score: 71.943\n",
      "Binary F1 Score (pos): 58.753\n",
      "Precision/Recall per class:\n",
      "78.3,93.2,77.4,47.3\n",
      "CM [[TN FP],[FN TP]] = [[2935, 213], [812, 730]]\n",
      "ROC_AUC (fpr-tpr): 0.851\n",
      "AUPRC: 0.745\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=78.1  MacroF1=71.8  BinF1(pos)=58.5\n",
      " P/R per class -> 0(H): 78.2/93.5 , 1(AI): 77.9/46.8\n",
      " CM [[TN FP],[FN TP]] = [[2944, 204], [821, 721]]\n",
      "[thr=YoudenJ] thr=0.291 | Acc=77.3  MacroF1=75.2  BinF1(pos)=68.0\n",
      " P/R per class -> 0(H): 85.9/79.3 , 1(AI): 63.4/73.3\n",
      " CM [[TN FP],[FN TP]] = [[2495, 653], [411, 1131]]\n",
      "[thr=bestPosF1] thr=0.291 | Acc=77.3  MacroF1=75.2  BinF1(pos)=68.0\n",
      " P/R per class -> 0(H): 85.9/79.3 , 1(AI): 63.4/73.3\n",
      " CM [[TN FP],[FN TP]] = [[2495, 653], [411, 1131]]\n",
      "78.1,71.9,58.8,78.3,93.2,77.4,47.3,0.851,0.745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:31<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11: train_loss 0.02756033536224138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:05<00:00,  1.41it/s]\n",
      "Epoch:  55%|█████▌    | 11/20 [07:12<05:50, 38.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7234265506267548\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 77.569\n",
      "Macro F1 Score: 70.302\n",
      "Binary F1 Score (pos): 55.612\n",
      "Precision/Recall per class:\n",
      "77.1,94.6,79.6,42.7\n",
      "CM [[TN FP],[FN TP]] = [[2979, 169], [883, 659]]\n",
      "ROC_AUC (fpr-tpr): 0.857\n",
      "AUPRC: 0.754\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=77.8  MacroF1=70.4  BinF1(pos)=55.5\n",
      " P/R per class -> 0(H): 77.1/95.4 , 1(AI): 81.6/42.1\n",
      " CM [[TN FP],[FN TP]] = [[3002, 146], [893, 649]]\n",
      "[thr=YoudenJ] thr=0.211 | Acc=76.4  MacroF1=74.8  BinF1(pos)=68.5\n",
      " P/R per class -> 0(H): 87.6/75.5 , 1(AI): 61.0/78.1\n",
      " CM [[TN FP],[FN TP]] = [[2378, 770], [337, 1205]]\n",
      "[thr=bestPosF1] thr=0.255 | Acc=78.3  MacroF1=76.0  BinF1(pos)=68.5\n",
      " P/R per class -> 0(H): 85.5/81.5 , 1(AI): 65.5/71.8\n",
      " CM [[TN FP],[FN TP]] = [[2566, 582], [435, 1107]]\n",
      "77.6,70.3,55.6,77.1,94.6,79.6,42.7,0.857,0.754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:32<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12: train_loss 0.027326575849973965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:05<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7016537934541702\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 78.891\n",
      "Macro F1 Score: 72.880\n",
      "Binary F1 Score (pos): 60.113\n",
      "Precision/Recall per class:\n",
      "78.8,93.8,79.4,48.4\n",
      "CM [[TN FP],[FN TP]] = [[2954, 194], [796, 746]]\n",
      "ROC_AUC (fpr-tpr): 0.858\n",
      "AUPRC: 0.757\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=78.7  MacroF1=72.4  BinF1(pos)=59.2\n",
      " P/R per class -> 0(H): 78.4/94.2 , 1(AI): 79.8/47.0\n",
      " CM [[TN FP],[FN TP]] = [[2965, 183], [817, 725]]\n",
      "[thr=YoudenJ] thr=0.248 | Acc=76.2  MacroF1=74.6  BinF1(pos)=68.2\n",
      " P/R per class -> 0(H): 87.3/75.6 , 1(AI): 60.9/77.6\n",
      " CM [[TN FP],[FN TP]] = [[2380, 768], [346, 1196]]\n",
      "[thr=bestPosF1] thr=0.314 | Acc=79.0  MacroF1=76.4  BinF1(pos)=68.5\n",
      " P/R per class -> 0(H): 84.9/83.6 , 1(AI): 67.5/69.6\n",
      " CM [[TN FP],[FN TP]] = [[2631, 517], [469, 1073]]\n",
      "78.9,72.9,60.1,78.8,93.8,79.4,48.4,0.858,0.757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:33<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13: train_loss 0.027245092457012524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:05<00:00,  1.40it/s]\n",
      "Epoch:  65%|██████▌   | 13/20 [08:30<04:34, 39.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7034503370523453\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 78.081\n",
      "Macro F1 Score: 71.172\n",
      "Binary F1 Score (pos): 57.059\n",
      "Precision/Recall per class:\n",
      "77.6,94.6,80.2,44.3\n",
      "CM [[TN FP],[FN TP]] = [[2979, 169], [859, 683]]\n",
      "ROC_AUC (fpr-tpr): 0.864\n",
      "AUPRC: 0.763\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=78.5  MacroF1=71.5  BinF1(pos)=57.3\n",
      " P/R per class -> 0(H): 77.6/95.4 , 1(AI): 82.5/43.9\n",
      " CM [[TN FP],[FN TP]] = [[3004, 144], [865, 677]]\n",
      "[thr=YoudenJ] thr=0.187 | Acc=75.9  MacroF1=74.6  BinF1(pos)=68.8\n",
      " P/R per class -> 0(H): 88.7/73.4 , 1(AI): 59.8/80.9\n",
      " CM [[TN FP],[FN TP]] = [[2310, 838], [294, 1248]]\n",
      "[thr=bestPosF1] thr=0.260 | Acc=79.1  MacroF1=76.7  BinF1(pos)=69.2\n",
      " P/R per class -> 0(H): 85.5/82.8 , 1(AI): 67.1/71.4\n",
      " CM [[TN FP],[FN TP]] = [[2607, 541], [441, 1101]]\n",
      "78.1,71.2,57.1,77.6,94.6,80.2,44.3,0.864,0.763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:33<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14: train_loss 0.027111405477164282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:05<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6848049014806747\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 79.595\n",
      "Macro F1 Score: 74.336\n",
      "Binary F1 Score (pos): 62.719\n",
      "Precision/Recall per class:\n",
      "79.9,93.0,78.5,52.2\n",
      "CM [[TN FP],[FN TP]] = [[2928, 220], [737, 805]]\n",
      "ROC_AUC (fpr-tpr): 0.863\n",
      "AUPRC: 0.763\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=79.5  MacroF1=74.0  BinF1(pos)=61.9\n",
      " P/R per class -> 0(H): 79.5/93.7 , 1(AI): 79.7/50.6\n",
      " CM [[TN FP],[FN TP]] = [[2949, 199], [761, 781]]\n",
      "[thr=YoudenJ] thr=0.237 | Acc=76.2  MacroF1=74.8  BinF1(pos)=68.8\n",
      " P/R per class -> 0(H): 88.3/74.5 , 1(AI): 60.5/79.8\n",
      " CM [[TN FP],[FN TP]] = [[2346, 802], [312, 1230]]\n",
      "[thr=bestPosF1] thr=0.238 | Acc=76.3  MacroF1=74.9  BinF1(pos)=68.8\n",
      " P/R per class -> 0(H): 88.2/74.7 , 1(AI): 60.7/79.6\n",
      " CM [[TN FP],[FN TP]] = [[2352, 796], [315, 1227]]\n",
      "79.6,74.3,62.7,79.9,93.0,78.5,52.2,0.863,0.763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:34<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15: train_loss 0.027114815241287626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:05<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6831010282039642\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 78.955\n",
      "Macro F1 Score: 73.389\n",
      "Binary F1 Score (pos): 61.218\n",
      "Precision/Recall per class:\n",
      "79.3,92.9,77.7,50.5\n",
      "CM [[TN FP],[FN TP]] = [[2924, 224], [763, 779]]\n",
      "ROC_AUC (fpr-tpr): 0.865\n",
      "AUPRC: 0.765\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=79.3  MacroF1=73.4  BinF1(pos)=60.8\n",
      " P/R per class -> 0(H): 79.0/94.2 , 1(AI): 80.4/48.9\n",
      " CM [[TN FP],[FN TP]] = [[2964, 184], [788, 754]]\n",
      "[thr=YoudenJ] thr=0.211 | Acc=75.9  MacroF1=74.6  BinF1(pos)=69.0\n",
      " P/R per class -> 0(H): 88.9/73.2 , 1(AI): 59.8/81.4\n",
      " CM [[TN FP],[FN TP]] = [[2305, 843], [287, 1255]]\n",
      "[thr=bestPosF1] thr=0.261 | Acc=78.1  MacroF1=76.1  BinF1(pos)=69.1\n",
      " P/R per class -> 0(H): 86.5/79.8 , 1(AI): 64.4/74.6\n",
      " CM [[TN FP],[FN TP]] = [[2511, 637], [391, 1151]]\n",
      "79.0,73.4,61.2,79.3,92.9,77.7,50.5,0.865,0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:32<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16: train_loss 0.026888944918201083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:05<00:00,  1.38it/s]\n",
      "Epoch:  80%|████████  | 16/20 [10:30<02:37, 39.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6855407729744911\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 78.443\n",
      "Macro F1 Score: 72.006\n",
      "Binary F1 Score (pos): 58.583\n",
      "Precision/Recall per class:\n",
      "78.2,94.2,79.5,46.4\n",
      "CM [[TN FP],[FN TP]] = [[2964, 184], [827, 715]]\n",
      "ROC_AUC (fpr-tpr): 0.866\n",
      "AUPRC: 0.768\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=78.8  MacroF1=72.1  BinF1(pos)=58.5\n",
      " P/R per class -> 0(H): 78.1/95.1 , 1(AI): 82.1/45.4\n",
      " CM [[TN FP],[FN TP]] = [[2995, 153], [842, 700]]\n",
      "[thr=YoudenJ] thr=0.215 | Acc=77.0  MacroF1=75.5  BinF1(pos)=69.3\n",
      " P/R per class -> 0(H): 88.1/76.0 , 1(AI): 61.7/79.1\n",
      " CM [[TN FP],[FN TP]] = [[2392, 756], [323, 1219]]\n",
      "[thr=bestPosF1] thr=0.247 | Acc=78.4  MacroF1=76.4  BinF1(pos)=69.4\n",
      " P/R per class -> 0(H): 86.6/80.2 , 1(AI): 64.9/74.7\n",
      " CM [[TN FP],[FN TP]] = [[2524, 624], [390, 1152]]\n",
      "78.4,72.0,58.6,78.2,94.2,79.5,46.4,0.866,0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:32<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17: train_loss 0.02688767287939314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6771578267216682\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 79.488\n",
      "Macro F1 Score: 74.018\n",
      "Binary F1 Score (pos): 62.096\n",
      "Precision/Recall per class:\n",
      "79.6,93.4,79.1,51.1\n",
      "CM [[TN FP],[FN TP]] = [[2940, 208], [754, 788]]\n",
      "ROC_AUC (fpr-tpr): 0.868\n",
      "AUPRC: 0.770\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=79.5  MacroF1=73.7  BinF1(pos)=61.3\n",
      " P/R per class -> 0(H): 79.2/94.3 , 1(AI): 80.8/49.4\n",
      " CM [[TN FP],[FN TP]] = [[2967, 181], [781, 761]]\n",
      "[thr=YoudenJ] thr=0.222 | Acc=76.8  MacroF1=75.4  BinF1(pos)=69.6\n",
      " P/R per class -> 0(H): 88.8/74.9 , 1(AI): 61.1/80.7\n",
      " CM [[TN FP],[FN TP]] = [[2357, 791], [298, 1244]]\n",
      "[thr=bestPosF1] thr=0.222 | Acc=76.8  MacroF1=75.4  BinF1(pos)=69.6\n",
      " P/R per class -> 0(H): 88.8/74.9 , 1(AI): 61.1/80.7\n",
      " CM [[TN FP],[FN TP]] = [[2357, 791], [298, 1244]]\n",
      "79.5,74.0,62.1,79.6,93.4,79.1,51.1,0.868,0.770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:31<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18: train_loss 0.02679358600150971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:05<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6744687110185623\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 79.296\n",
      "Macro F1 Score: 73.716\n",
      "Binary F1 Score (pos): 61.605\n",
      "Precision/Recall per class:\n",
      "79.4,93.4,78.9,50.5\n",
      "CM [[TN FP],[FN TP]] = [[2940, 208], [763, 779]]\n",
      "ROC_AUC (fpr-tpr): 0.869\n",
      "AUPRC: 0.771\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=79.7  MacroF1=73.9  BinF1(pos)=61.6\n",
      " P/R per class -> 0(H): 79.3/94.4 , 1(AI): 81.4/49.5\n",
      " CM [[TN FP],[FN TP]] = [[2973, 175], [778, 764]]\n",
      "[thr=YoudenJ] thr=0.222 | Acc=76.7  MacroF1=75.3  BinF1(pos)=69.5\n",
      " P/R per class -> 0(H): 88.8/74.7 , 1(AI): 61.0/80.8\n",
      " CM [[TN FP],[FN TP]] = [[2350, 798], [296, 1246]]\n",
      "[thr=bestPosF1] thr=0.249 | Acc=77.8  MacroF1=76.0  BinF1(pos)=69.5\n",
      " P/R per class -> 0(H): 87.4/78.2 , 1(AI): 63.4/77.0\n",
      " CM [[TN FP],[FN TP]] = [[2461, 687], [354, 1188]]\n",
      "79.3,73.7,61.6,79.4,93.4,78.9,50.5,0.869,0.771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:31<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19: train_loss 0.026752432246529866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:05<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6726795211434364\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 79.616\n",
      "Macro F1 Score: 74.231\n",
      "Binary F1 Score (pos): 62.451\n",
      "Precision/Recall per class:\n",
      "79.7,93.4,79.2,51.6\n",
      "CM [[TN FP],[FN TP]] = [[2939, 209], [747, 795]]\n",
      "ROC_AUC (fpr-tpr): 0.869\n",
      "AUPRC: 0.772\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=79.9  MacroF1=74.2  BinF1(pos)=62.2\n",
      " P/R per class -> 0(H): 79.5/94.3 , 1(AI): 81.1/50.5\n",
      " CM [[TN FP],[FN TP]] = [[2967, 181], [764, 778]]\n",
      "[thr=YoudenJ] thr=0.226 | Acc=76.8  MacroF1=75.4  BinF1(pos)=69.5\n",
      " P/R per class -> 0(H): 88.7/75.0 , 1(AI): 61.2/80.4\n",
      " CM [[TN FP],[FN TP]] = [[2361, 787], [302, 1240]]\n",
      "[thr=bestPosF1] thr=0.258 | Acc=78.1  MacroF1=76.3  BinF1(pos)=69.6\n",
      " P/R per class -> 0(H): 87.1/79.2 , 1(AI): 64.1/76.1\n",
      " CM [[TN FP],[FN TP]] = [[2492, 656], [369, 1173]]\n",
      "79.6,74.2,62.5,79.7,93.4,79.2,51.6,0.869,0.772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:32<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20: train_loss 0.026741520782548284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:05<00:00,  1.41it/s]\n",
      "Epoch: 100%|██████████| 20/20 [13:03<00:00, 39.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6735561937093735\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 79.190\n",
      "Macro F1 Score: 73.548\n",
      "Binary F1 Score (pos): 61.331\n",
      "Precision/Recall per class:\n",
      "79.3,93.4,78.8,50.2\n",
      "CM [[TN FP],[FN TP]] = [[2940, 208], [768, 774]]\n",
      "ROC_AUC (fpr-tpr): 0.869\n",
      "AUPRC: 0.772\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=79.7  MacroF1=73.9  BinF1(pos)=61.6\n",
      " P/R per class -> 0(H): 79.2/94.6 , 1(AI): 81.7/49.4\n",
      " CM [[TN FP],[FN TP]] = [[2977, 171], [780, 762]]\n",
      "[thr=YoudenJ] thr=0.225 | Acc=76.9  MacroF1=75.5  BinF1(pos)=69.6\n",
      " P/R per class -> 0(H): 88.6/75.3 , 1(AI): 61.4/80.2\n",
      " CM [[TN FP],[FN TP]] = [[2371, 777], [305, 1237]]\n",
      "[thr=bestPosF1] thr=0.258 | Acc=78.3  MacroF1=76.4  BinF1(pos)=69.6\n",
      " P/R per class -> 0(H): 87.0/79.6 , 1(AI): 64.5/75.6\n",
      " CM [[TN FP],[FN TP]] = [[2506, 642], [376, 1166]]\n",
      "79.2,73.5,61.3,79.3,93.4,78.8,50.2,0.869,0.772\n",
      "Reloading best model from ckpt/gemini_hybrid_line_best_f1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 18/18 [00:16<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 77.471\n",
      "Macro F1 Score: 71.051\n",
      "Binary F1 Score (pos): 57.418\n",
      "Precision/Recall per class:\n",
      "75.8,95.9,85.0,43.4\n",
      "CM [[TN FP],[FN TP]] = [[7934, 342], [2528, 1935]]\n",
      "ROC_AUC (fpr-tpr): 0.848\n",
      "AUPRC: 0.765\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=76.6  MacroF1=69.8  BinF1(pos)=55.6\n",
      " P/R per class -> 0(H): 75.2/95.4 , 1(AI): 83.0/41.8\n",
      " CM [[TN FP],[FN TP]] = [[7894, 382], [2599, 1864]]\n",
      "[thr=YoudenJ] thr=0.244 | Acc=76.3  MacroF1=74.9  BinF1(pos)=69.1\n",
      " P/R per class -> 0(H): 85.3/76.7 , 1(AI): 63.6/75.6\n",
      " CM [[TN FP],[FN TP]] = [[6348, 1928], [1090, 3373]]\n",
      "[thr=bestPosF1] thr=0.244 | Acc=76.3  MacroF1=74.9  BinF1(pos)=69.1\n",
      " P/R per class -> 0(H): 85.3/76.7 , 1(AI): 63.6/75.6\n",
      " CM [[TN FP],[FN TP]] = [[6348, 1928], [1090, 3373]]\n",
      "77.5,71.1,57.4,75.8,95.9,85.0,43.4,0.848,0.765\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    sys.argv = [\n",
    "        \"train.py\",\n",
    "        \"--dataset\", \"gemini_hybrid_line\",\n",
    "        \"--data_path\", \"./data\",\n",
    "        \"--seed\", \"42\",\n",
    "        \"--testbed\", \"toplevel\",\n",
    "        \"--ckpt_name\", \"gemini_hybrid_line\"\n",
    "    ]\n",
    "\n",
    "    args = parse_args()\n",
    "    \n",
    "    print(\"Log INFO: split dataset...\")\n",
    "    df_ = split_dataset(data_path=args.data_path, seed=args.seed, dataset=args.dataset)  # [train, val, test]\n",
    "\n",
    "    en_labels = {\n",
    "        'human': 0,\n",
    "        'AI': 1\n",
    "    }\n",
    "    \n",
    "    id2label = construct_bmes_labels(en_labels)\n",
    "    label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "    prediction_method = 'most_common'\n",
    "\n",
    "    experiment_results = []\n",
    "\n",
    "    if 'revised' in args.dataset:\n",
    "        datas = DataManagerTest(datas=df_, batch_size=args.batch_size, max_len=args.seq_len, human_label='human', id2label=id2label)\n",
    "    else:\n",
    "        datas = DataManager(datas=df_, batch_size=args.batch_size, max_len=args.seq_len, human_label='human', id2label=id2label)\n",
    "\n",
    "    # classifier 선택\n",
    "    if args.method == 'focalbmesbinary_embedconcat_transformer256':\n",
    "        if args.testbed == 'toplevel':\n",
    "            if 'gemini' in args.dataset or 'gpt4' in args.dataset:\n",
    "                classifier = MultiModalConcatLineFocalBMESBinaryClassifier(id2labels=id2label, seq_len=args.seq_len, alpha=args.alpha)\n",
    "\n",
    "    ckpt_name = f'ckpt/{args.ckpt_name}_best_f1.pt'\n",
    "\n",
    "    trainer = SupervisedTrainer(datas, classifier, en_labels, id2label, args)\n",
    "    trainer.writer = SummaryWriter(log_dir=f\"runs/python_{args.ckpt_name}\")\n",
    "\n",
    "    experiment_result = {}\n",
    "\n",
    "    if args.do_test:\n",
    "        print(\"Log INFO: do test...\")\n",
    "        saved_model = torch.load(ckpt_name)\n",
    "        trainer.model.load_state_dict(saved_model.state_dict())\n",
    "        if 'hybrid' in args.dataset or 'revised' in args.dataset:\n",
    "            test_sent_result, _, test_raw_results = trainer.test(datas.test_dataloader, content_level_eval=False, prediction_method=prediction_method)\n",
    "            experiment_result['test_result'] = {'line': test_sent_result, 'raw': test_raw_results}\n",
    "        else:\n",
    "            test_sent_result, test_content_result, test_raw_results = trainer.test(datas.test_dataloader, content_level_eval=True, prediction_method=prediction_method)\n",
    "            experiment_result['test_result'] = {'line': test_sent_result, 'document': test_content_result, 'raw': test_raw_results}\n",
    "    else:\n",
    "        print(\"Log INFO: do train...\")\n",
    "        trainer.train(ckpt_name=ckpt_name, prediction_method=prediction_method)\n",
    "\n",
    "        if 'hybrid' in args.dataset or 'revised' in args.dataset:\n",
    "            test_sent_result, _, test_raw_results = trainer.test(datas.test_dataloader, content_level_eval=False, prediction_method=prediction_method)\n",
    "            experiment_result['test_result'] = {'line': test_sent_result, 'raw': test_raw_results}\n",
    "        else:\n",
    "            test_sent_result, test_content_result, test_raw_results = trainer.test(datas.test_dataloader, content_level_eval=True, prediction_method=prediction_method)\n",
    "            experiment_result['test_result'] = {'line': test_sent_result, 'document': test_content_result, 'raw': test_raw_results}\n",
    "\n",
    "    experiment_results.append(experiment_result)\n",
    "\n",
    "    with open(f'result/experiment_results_{args.ckpt_name}.json', 'w') as file:\n",
    "        json.dump(experiment_results, file, ensure_ascii=False, cls=NpEncoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
