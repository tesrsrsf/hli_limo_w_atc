{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4a510d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "import warnings\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import ast\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from typing import Dict, Any, Optional\n",
    "import numpy as np\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "import datetime\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    roc_curve, auc, precision_recall_curve, average_precision_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from transformers.optimization import get_linear_schedule_with_warmup       # AdamW seems no longer available here\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "project_path = os.path.abspath('')\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n",
    "\n",
    "from dataloader import DataManager, DataManagerTest\n",
    "from model_4 import MultiModalConcatLineFocalBMESBinaryClassifier\n",
    "\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, classification_report\n",
    "\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from dataloader import AtcSidecar\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e98e889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "with open('./pylint.txt','r') as f:\n",
    "    error_list = f.read()\n",
    "    error_codes = re.findall(r\"\\((\\w\\d{4})\\)\", error_list)\n",
    "    \n",
    "def analyze_pylint_output(eval_result: str) -> Counter:\n",
    "    analysis = [0]*len(error_codes)\n",
    "    error_pattern = re.compile(r\"\\d:\\d+:\\s(\\w\\d{4}):\\s\")\n",
    "    errors = error_pattern.findall(eval_result)\n",
    "\n",
    "    error_counts = Counter(errors)\n",
    "    \n",
    "    analysis = [error_counts[e] for e in error_codes]\n",
    "\n",
    "    return analysis\n",
    "\n",
    "\n",
    "def analyze_pylint_output_line(eval_result: str, total_lines: int):\n",
    "    error_pattern = re.compile(r\"(\\d+):\\d+:\\s(\\w\\d{4}):\\s\")\n",
    "    errors = error_pattern.findall(eval_result)\n",
    "    \n",
    "    line_error_counts = defaultdict(Counter)\n",
    "\n",
    "    for line, code in errors:\n",
    "        line_error_counts[int(line)][code] += 1\n",
    "    \n",
    "    analysis = [[0]*len(error_codes) for _ in range(total_lines)]\n",
    "    \n",
    "    # 각 줄별 에러 코드 카운트를 분석 결과 리스트에 저장\n",
    "    for line in range(total_lines):\n",
    "        if line in line_error_counts:\n",
    "            analysis[line] = [line_error_counts[line][code] for code in error_codes]\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "def split_code_sentence(code, use_sp=False):\n",
    "        import re\n",
    "        pattern = re.compile(\n",
    "        r'\"\"\"|\\'\\'\\'|\"|\\'|#|==|'\n",
    "        r'\\n|'\n",
    "        r'[^\\S\\n]+|'\n",
    "        r'\\w+|[.,()\\[\\]{};:\\=\\_\\+\\-\\*\\/\\~\\!\\%\\^\\&\\<\\>\\?]')\n",
    "        \n",
    "        tokens = pattern.findall(code)\n",
    "        return tokens\n",
    "\n",
    "def ccfeature_line_to_token_level(code):\n",
    "    code_tokens = split_code_sentence(code)\n",
    "    count = 0\n",
    "    line_num_list = []\n",
    "    for token in code_tokens:\n",
    "        line_num_list.append(count)\n",
    "        if token == '\\n':\n",
    "            count += 1\n",
    "    return line_num_list[:1024]\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, original_dataset, indices):\n",
    "        self.original_dataset = original_dataset\n",
    "        self.indices = [int(idx) for idx in indices]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        real_idx = self.indices[index]\n",
    "        return self.original_dataset[int(real_idx)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "\n",
    "def get_roc_metrics(true_labels, pred_labels):\n",
    "    fpr, tpr, thresholds = roc_curve(true_labels, pred_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    J = tpr - fpr\n",
    "    ix = np.argmax(J)\n",
    "    best_thresh = thresholds[ix]\n",
    "    print('Best Threshold=%f, sensitivity = %.3f, specificity = %.3f, J=%.3f' % (best_thresh, tpr[ix], 1-fpr[ix], J[ix]))\n",
    "    return float(roc_auc)\n",
    "\n",
    "class SupervisedTrainer:\n",
    "    def __init__(self, data, model, en_labels, id2label, args):\n",
    "        self.data = data\n",
    "        self.model = model\n",
    "        self.en_labels = en_labels\n",
    "        self.id2label = id2label\n",
    "\n",
    "        self.seq_len = args.seq_len\n",
    "        self.num_train_epochs = args.num_train_epochs\n",
    "        self.weight_decay = args.weight_decay\n",
    "        self.lr = args.lr\n",
    "        self.warm_up_ratio = args.warm_up_ratio\n",
    "\n",
    "        self.device = torch.device(\n",
    "            'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "        self._create_optimizer_and_scheduler()\n",
    "        \n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_f1_score = 0.0\n",
    "        self.best_model_path = None\n",
    "        self.writer = None\n",
    "        self.loss_function = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "        self.threshold = 0.5\n",
    "\n",
    "    def _create_optimizer_and_scheduler(self):\n",
    "        num_training_steps = len(\n",
    "            self.data.train_dataloader) * self.num_train_epochs\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "\n",
    "        named_parameters = self.model.named_parameters()\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in named_parameters\n",
    "                    if not any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\":\n",
    "                self.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in named_parameters\n",
    "                    if any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\":\n",
    "                0.0,\n",
    "            },\n",
    "        ]\n",
    "        self.optimizer = AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr=self.lr,\n",
    "            betas=(0.9, 0.98),\n",
    "            eps=1e-8,\n",
    "        )\n",
    "        self.scheduler = get_linear_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=int(self.warm_up_ratio * num_training_steps),\n",
    "            num_training_steps=num_training_steps)\n",
    "\n",
    "    def train(self, ckpt_name='linear_en.pt', prediction_method=\"most_common\"):\n",
    "        \n",
    "        for epoch in trange(int(self.num_train_epochs), desc=\"Epoch\"):\n",
    "            self.model.train()\n",
    "            tr_loss = 0\n",
    "            nb_tr_steps = 0\n",
    "            # train\n",
    "            for step, inputs in enumerate(\n",
    "                    tqdm(self.data.train_dataloader, desc=\"Iteration\")):\n",
    "                # send batch data to GPU\n",
    "                for k, v in inputs.items():\n",
    "                    if isinstance(v, torch.Tensor):\n",
    "                        inputs[k] = v.to(self.device)\n",
    "                with torch.set_grad_enabled(True):\n",
    "                    labels = inputs['labels']\n",
    "                    output = self.model(inputs['features'], inputs['labels'], inputs['ccfeatures'], inputs['atfeatures'])#, inputs['line_indices'])\n",
    "                    logits = output['logits']\n",
    "                    loss = output['loss']\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    \n",
    "                    # print(\"KSY =======================\")\n",
    "                    # for name, p in self.model.named_parameters():\n",
    "                    #     if 'feature_encoder' in name:\n",
    "                    #         print(name)\n",
    "                    #         print(p.grad)\n",
    "                    #         exit()\n",
    "                            \n",
    "                    self.optimizer.step()\n",
    "                    self.scheduler.step()\n",
    "\n",
    "                    tr_loss += loss.item()\n",
    "                    nb_tr_steps += 1\n",
    "            \n",
    "                if step % 50 == 0:\n",
    "                    self.writer.add_scalar('Training Loss', loss.item(), epoch * len(self.data.train_dataloader) + step)\n",
    "            \n",
    "            \n",
    "            avg_train_loss = tr_loss / nb_tr_steps\n",
    "            print(f'epoch {epoch+1}: train_loss {avg_train_loss}')\n",
    "            self.writer.add_scalar('Average Training Loss', avg_train_loss, epoch)\n",
    "\n",
    "            # Validate data at the end of every epoch\n",
    "            val_loss, sent_result = self.valid(prediction_method=prediction_method)\n",
    "            self.writer.add_scalar('Validation Loss', val_loss, epoch)\n",
    "\n",
    "            # save the best model\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "                self.best_model_path = f\"{ckpt_name}\"\n",
    "                self.writer.add_scalar('Best Validation Loss', self.best_val_loss, epoch)\n",
    "                torch.save(self.model.cpu(), self.best_model_path)\n",
    "                self.model.to(self.device)\n",
    "\n",
    "        # then reload the best model in the end\n",
    "        if self.best_model_path:\n",
    "            print(f\"Reloading best model from {self.best_model_path}\")\n",
    "            self.model.load_state_dict(torch.load(self.best_model_path, weights_only=False).state_dict())\n",
    "            self.model.to(self.device)\n",
    "        \n",
    "        self.writer.close()\n",
    "        return\n",
    "    \n",
    "    def valid(self, content_level_eval=False, prediction_method=\"most_common\"):\n",
    "        self.model.eval()\n",
    "        texts = []\n",
    "        true_labels = []\n",
    "        pred_labels = []\n",
    "        total_logits = []\n",
    "        total_probs = []\n",
    "        total_loss = 0.0\n",
    "        total_steps = 0\n",
    "        \n",
    "        for step, inputs in enumerate(\n",
    "                tqdm(self.data.val_dataloader, desc=\"Iteration\")):\n",
    "            for k, v in inputs.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    inputs[k] = v.to(self.device)\n",
    "            with torch.no_grad():\n",
    "                labels_ = inputs['labels']\n",
    "                output = self.model(inputs['features'], inputs['labels'], inputs['ccfeatures'], inputs['atfeatures'])\n",
    "                preds = output['preds']\n",
    "    \n",
    "                logits_ = output['logits']\n",
    "                \n",
    "                probabilities = F.softmax(logits_, dim=-1)\n",
    "                \n",
    "                logits = logits_.view(-1, logits_.size(-1))\n",
    "                labels = labels_.view(-1)\n",
    "                loss = self.loss_function(logits, labels)\n",
    "                total_loss += loss.item()\n",
    "                total_steps += 1\n",
    "\n",
    "                texts.extend(inputs['text'])\n",
    "                pred_labels.extend(preds.cpu().tolist())\n",
    "                true_labels.extend(labels_.cpu().tolist())\n",
    "                total_probs.extend(probabilities)\n",
    "\n",
    "        avg_val_loss = total_loss / total_steps\n",
    "        print(f\"Validation Loss: {avg_val_loss}\")\n",
    "        \n",
    "        print(\"*\" * 8, \"Sentence Level Evalation\", \"*\" * 8)\n",
    "        #word_result, sent_result = self.sent_level_eval(texts, true_labels, pred_labels, total_probs, prediction_method)\n",
    "        sent_result = self.sent_level_eval(texts, true_labels, pred_labels, total_probs, prediction_method)\n",
    "        \n",
    "        return avg_val_loss, sent_result\n",
    "    \n",
    "    def test(self, test_dataloader, content_level_eval=False, prediction_method=\"most_common\"):\n",
    "        self.model.eval()\n",
    "        texts = []\n",
    "        true_labels = []\n",
    "        pred_labels = []\n",
    "        total_logits = []\n",
    "        total_probs = []\n",
    "        problem_ids = []\n",
    "        user_ids = []\n",
    "        \n",
    "        for step, inputs in enumerate(\n",
    "                tqdm(test_dataloader, desc=\"Iteration\")):\n",
    "            for k, v in inputs.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    inputs[k] = v.to(self.device)\n",
    "            with torch.no_grad():\n",
    "                labels = inputs['labels']\n",
    "                output = self.model(inputs['features'], inputs['labels'], inputs['ccfeatures'], inputs['atfeatures'])#, inputs['line_indices'])\n",
    "                logits = output['logits']\n",
    "                preds = output['preds']\n",
    "                problem_id = inputs['problem_id']\n",
    "                user_id = inputs['user_id']\n",
    "                \n",
    "                probabilities = F.softmax(logits, dim=-1)\n",
    "\n",
    "                texts.extend(inputs['text'])\n",
    "                pred_labels.extend(preds.cpu().tolist())\n",
    "                true_labels.extend(labels.cpu().tolist())\n",
    "                problem_ids.extend(problem_id)\n",
    "                user_ids.extend(user_id)\n",
    "                total_logits.extend(logits.cpu().tolist())\n",
    "                total_probs.extend(probabilities)\n",
    "        \n",
    "        line_counts = [len(text.split('\\n')) for text in texts]\n",
    "        \n",
    "        if content_level_eval:\n",
    "            # content level evaluation\n",
    "            print(\"*\" * 8, \"Content Level Evalation\", \"*\" * 8)\n",
    "            content_result = self.content_level_eval(texts, true_labels, pred_labels, total_probs, prediction_method)\n",
    "        else:\n",
    "            content_result = None\n",
    "        print(\"*\" * 8, \"Sentence Level Evalation\", \"*\" * 8)\n",
    "        #word_result, sent_result = self.sent_level_eval(texts, true_labels, pred_labels, total_probs, prediction_method)\n",
    "        sent_result = self.sent_level_eval(texts, true_labels, pred_labels, total_probs, prediction_method)\n",
    "            \n",
    "        # return sent_result, content_result, {'text':texts,'pred':pred_labels, 'true':true_labels, 'problem_id':problem_ids, 'user_id': user_ids}\n",
    "        return sent_result, content_result, {'text': texts, 'pred': pred_labels, 'true': true_labels, 'problem_id':problem_ids, 'user_id':user_ids, 'line_count':line_counts}\n",
    "\n",
    "    \n",
    "    def content_level_eval(self, texts, true_labels, pred_labels, pred_probs, prediction_method='most_common'):\n",
    "        if prediction_method =='threshold':\n",
    "            threshold = self.threshold\n",
    "        else:\n",
    "            threshold = None\n",
    "            pred_labels_threshold = pred_labels\n",
    "        \n",
    "        true_content_labels = []\n",
    "        pred_content_labels = []\n",
    "        pred_content_probs = []\n",
    "        \n",
    "        for text, true_label, pred_label, pred_prob in zip(texts, true_labels, pred_labels_threshold, pred_probs):\n",
    "            true_label = np.array(true_label)\n",
    "            pred_label = np.array(pred_label)\n",
    "            pred_prob = np.array(pred_prob.cpu())\n",
    "            \n",
    "            mask = true_label != -1\n",
    "            true_label = true_label[mask].tolist()\n",
    "            pred_label = pred_label[mask].tolist()\n",
    "            \n",
    "            pred_prob = torch.tensor(pred_prob[mask])\n",
    "            true_common_tag = self._get_most_common_tag(true_label)\n",
    "            true_content_labels.append(true_common_tag[0])\n",
    "            \n",
    "            pred_common_tag = self._get_most_common_tag(pred_label)\n",
    "            pred_content_labels.append(pred_common_tag[0])\n",
    "            \n",
    "            cont_prob = pred_prob[:, 4:8].sum(dim=1)\n",
    "            pred_content_prob = torch.mean(cont_prob, dim=0)\n",
    "            pred_content_probs.append(pred_content_prob.item())\n",
    "            \n",
    "        true_content_labels = [self.en_labels[label] for label in true_content_labels]\n",
    "        pred_content_labels = [self.en_labels[label] for label in pred_content_labels]\n",
    "        \n",
    "        result = self._get_precision_recall_acc_f1(true_content_labels, pred_content_labels, pred_content_probs)\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def sent_level_eval(self, texts, true_labels, pred_labels, pred_probs, prediction_method='most_common'):\n",
    "        if prediction_method =='threshold':\n",
    "            threshold = self.threshold\n",
    "        else:\n",
    "            threshold = None\n",
    "            pred_labels_threshold = pred_labels\n",
    "        \n",
    "        # For line-wise labeling\n",
    "        true_sent_labels = []\n",
    "        pred_sent_labels = []\n",
    "        pred_sent_probs = []\n",
    "        for text, true_label, pred_label, pred_prob in zip(texts, true_labels, pred_labels_threshold, pred_probs):\n",
    "            true_label = np.array(true_label)\n",
    "            pred_label = np.array(pred_label)\n",
    "            pred_prob = np.array(pred_prob.cpu())\n",
    "            mask = true_label != -1\n",
    "            true_label = true_label[mask].tolist()\n",
    "            pred_label = pred_label[mask].tolist()\n",
    "            pred_prob = torch.tensor(pred_prob[mask])\n",
    "            sents = text.split('\\n')\n",
    "            for true_label_idx in range(len(true_label)):\n",
    "                if sents[true_label_idx] == '' or sents[true_label_idx].isspace():  # 빈 문장일 경우 처리하지 않음\n",
    "                    continue\n",
    "                true_sent_label = self.id2label[true_label[true_label_idx]]\n",
    "                pred_sent_label = self.id2label[pred_label[true_label_idx]]\n",
    "                \n",
    "                true_sent_labels.append(true_sent_label.split('-')[-1])\n",
    "                pred_sent_prob = pred_prob[true_label_idx, 4:8].sum()\n",
    "                pred_sent_probs.append(pred_sent_prob.item())\n",
    "                pred_sent_labels.append(pred_sent_label.split('-')[-1])\n",
    "            \n",
    "        true_sent_labels = [self.en_labels[label] for label in true_sent_labels]\n",
    "        pred_sent_labels = [self.en_labels[label] for label in pred_sent_labels]\n",
    "        \n",
    "        sent_result = self._get_precision_recall_acc_f1(true_sent_labels, pred_sent_labels, pred_sent_probs)\n",
    "        return sent_result\n",
    "    \n",
    "    \n",
    "    def _get_threshold_tag(self, logits, machine_threshold=0.5):\n",
    "        human_logits = logits[:, :, :4]  # Human Classes\n",
    "        machine_logits = logits[:, :, 4:] # Machine Classes\n",
    "        human_scores = torch.sum(human_logits, dim=-1)  # Shape: [batch_size, seq_len]\n",
    "        machine_scores = torch.sum(machine_logits, dim=-1)        # Shape: [batch_size, seq_len]\n",
    "        pred_labels = torch.where(machine_scores >= machine_threshold, 4, 0)  # 0 for Human, 4 for AI\n",
    "        \n",
    "        return pred_labels.cpu().tolist()\n",
    "    \n",
    "    def _get_most_common_tag(self, tags):\n",
    "        \"\"\"most_common_tag is a tuple: (tag, times)\"\"\"\n",
    "        from collections import Counter\n",
    "        tags = [self.id2label[tag] for tag in tags]\n",
    "        tags = [tag.split('-')[-1] for tag in tags]\n",
    "        tag_counts = Counter(tags)\n",
    "        most_common_tag = tag_counts.most_common(1)[0]\n",
    "        return most_common_tag\n",
    "    \n",
    "    def _get_precision_recall_acc_f1(self, true_labels, pred_labels, pred_probs=None, pos_label: int = 1) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        true_labels: [0/1]\n",
    "        pred_labels: 이미 threshold가 적용된 0/1 예측\n",
    "        pred_probs : 선택. 점수(양성=pos_label의 확률/로짓 등). 있으면 ROC/AUPRC과 임계값 탐색 리포트 추가.\n",
    "        pos_label  : 양성 클래스(기본 1)\n",
    "        \"\"\"\n",
    "        y_true = np.asarray(true_labels).astype(int)\n",
    "        y_pred = np.asarray(pred_labels).astype(int)\n",
    "\n",
    "        # --- 기본 리포트(주어진 라벨 기준) ---\n",
    "        acc  = accuracy_score(y_true, y_pred)\n",
    "        mF1  = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        bF1  = f1_score(y_true, y_pred, average='binary', pos_label=pos_label, zero_division=0)\n",
    "        prec = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "        rec  = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "        cm   = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "\n",
    "        print(\"=== Given labels (as-is) ===\")\n",
    "        print(\"Accuracy: {:.3f}\".format(acc*100))\n",
    "        print(\"Macro F1 Score: {:.3f}\".format(mF1*100))\n",
    "        print(\"Binary F1 Score (pos): {:.3f}\".format(bF1*100))\n",
    "        print(\"Precision/Recall per class:\")\n",
    "        print(\"{:.1f},{:.1f},{:.1f},{:.1f}\".format(prec[0]*100, rec[0]*100, prec[1]*100, rec[1]*100))\n",
    "        print(f\"CM [[TN FP],[FN TP]] = {cm.tolist()}\")\n",
    "\n",
    "        # 결과 dict 시작\n",
    "        result: Dict[str, Any] = {\n",
    "            \"given_labels\": {\n",
    "                \"accuracy\": acc, \"macro_f1\": mF1, \"binary_f1\": bF1,\n",
    "                \"precision\": prec, \"recall\": rec, \"cm\": cm\n",
    "            },\n",
    "            \"roc_auc\": None,\n",
    "            \"auprc\": None,\n",
    "            \"thresholds\": {}\n",
    "        }\n",
    "\n",
    "        # --- 점수 기반 추가 리포트 ---\n",
    "        if pred_probs is not None:\n",
    "            y_score = np.asarray(pred_probs, dtype=float)\n",
    "\n",
    "            # ROC / AUPRC\n",
    "            try:\n",
    "                fpr, tpr, thr_roc = roc_curve(y_true, y_score, pos_label=pos_label)\n",
    "                roc_auc = float(auc(fpr, tpr))\n",
    "            except Exception:\n",
    "                roc_auc = None\n",
    "\n",
    "            try:\n",
    "                auprc = float(average_precision_score(y_true, y_score, pos_label=pos_label))\n",
    "            except Exception:\n",
    "                auprc = None\n",
    "\n",
    "            print(f\"ROC_AUC (fpr-tpr): {roc_auc:.3f}\" if roc_auc is not None else \"ROC_AUC: N/A\")\n",
    "            print(f\"AUPRC: {auprc:.3f}\" if auprc is not None else \"AUPRC: N/A\")\n",
    "\n",
    "            # Helper: 특정 threshold에서 평가\n",
    "            def eval_at(thr: float, tag: str) -> Dict[str, Any]:\n",
    "                y_hat = (y_score > thr).astype(int)\n",
    "                acc_  = accuracy_score(y_true, y_hat)\n",
    "                mF1_  = f1_score(y_true, y_hat, average='macro', zero_division=0)\n",
    "                bF1_  = f1_score(y_true, y_hat, average='binary', pos_label=pos_label, zero_division=0)\n",
    "                pr_   = precision_score(y_true, y_hat, average=None, zero_division=0)\n",
    "                rc_   = recall_score(y_true, y_hat, average=None, zero_division=0)\n",
    "                cm_   = confusion_matrix(y_true, y_hat, labels=[0,1])\n",
    "                print(f\"[{tag}] thr={thr:.3f} | Acc={acc_*100:.1f}  MacroF1={mF1_*100:.1f}  BinF1(pos)={bF1_*100:.1f}\")\n",
    "                print(\" P/R per class -> 0(H): {:.1f}/{:.1f} , 1(AI): {:.1f}/{:.1f}\".format(pr_[0]*100, rc_[0]*100, pr_[1]*100, rc_[1]*100))\n",
    "                print(f\" CM [[TN FP],[FN TP]] = {cm_.tolist()}\")\n",
    "                return {\"thr\": float(thr), \"accuracy\": acc_, \"macro_f1\": mF1_, \"binary_f1\": bF1_, \"precision\": pr_, \"recall\": rc_, \"cm\": cm_}\n",
    "\n",
    "            # Youden J (TPR - FPR) 최대\n",
    "            def best_thr_youden() -> float:\n",
    "                if roc_auc is None or len(thr_roc) == 0:\n",
    "                    return 0.5\n",
    "                J = tpr - fpr\n",
    "                i = int(np.argmax(J))\n",
    "                return float(thr_roc[i])\n",
    "\n",
    "            # 양성 F1 최대(PR 기반)\n",
    "            def best_thr_posF1() -> float:\n",
    "                prec_curve, rec_curve, thr_pr = precision_recall_curve(y_true, y_score, pos_label=pos_label)\n",
    "                if len(thr_pr) == 0:\n",
    "                    return 0.5\n",
    "                f1_curve = (2 * prec_curve * rec_curve) / (prec_curve + rec_curve + 1e-12)\n",
    "                i = int(np.nanargmax(f1_curve[:-1]))  # 마지막 점은 threshold 없음\n",
    "                return float(thr_pr[i])\n",
    "\n",
    "            thr05     = 0.5\n",
    "            thrJ      = best_thr_youden()\n",
    "            thrBestF1 = best_thr_posF1()\n",
    "\n",
    "            print(\"=== Threshold sweeps on scores ===\")\n",
    "            res05  = eval_at(thr05, \"thr=0.5\")\n",
    "            resJ   = eval_at(thrJ, \"thr=YoudenJ\")\n",
    "            resF1  = eval_at(thrBestF1, \"thr=bestPosF1\")\n",
    "\n",
    "            result.update({\n",
    "                \"roc_auc\": roc_auc,\n",
    "                \"auprc\": auprc,\n",
    "                \"thresholds\": {\n",
    "                    \"thr@0.5\": res05,\n",
    "                    \"thr@youden\": resJ,\n",
    "                    \"thr@best_posF1\": resF1\n",
    "                }\n",
    "            })\n",
    "        else:\n",
    "            print(\"ROC_AUC (fpr-tpr): N/A (pred_probs is None)\")\n",
    "            print(\"AUPRC: N/A (pred_probs is None)\")\n",
    "\n",
    "        # CSV 한 줄 요약(기존 포맷과 유사)\n",
    "        pr_line = \"{:.1f},{:.1f},{:.1f},{:.1f}\".format(prec[0]*100, rec[0]*100, prec[1]*100, rec[1]*100)\n",
    "        print(\"{:.1f},{:.1f},{:.1f},{},{:.3f},{}\".format(\n",
    "            acc*100, mF1*100, bF1*100, pr_line, result[\"roc_auc\"] if result[\"roc_auc\"] is not None else float(\"nan\"),\n",
    "            f\"{result['auprc']:.3f}\" if result[\"auprc\"] is not None else \"N/A\"\n",
    "        ))\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "def construct_bmes_labels(labels):\n",
    "    prefix = ['B-', 'M-', 'E-', 'S-']\n",
    "    id2label = {}\n",
    "    counter = 0\n",
    "\n",
    "    for label, id in labels.items():\n",
    "        for pre in prefix:\n",
    "            id2label[counter] = pre + label\n",
    "            counter += 1\n",
    "    \n",
    "    return id2label\n",
    "\n",
    "def remove_duplicates(prob_dict):\n",
    "    total_p = 0\n",
    "    total = 0\n",
    "    for problem_id, entries in prob_dict.items():\n",
    "        n = 0\n",
    "        unique_texts = set()\n",
    "        unique_entries = []\n",
    "        \n",
    "        for entry in entries:\n",
    "            if entry['text'] not in unique_texts:\n",
    "                unique_entries.append(entry)\n",
    "                unique_texts.add(entry['text'])\n",
    "            else:\n",
    "                n += 1\n",
    "        if n != 0:\n",
    "            total_p += 1\n",
    "        total += n\n",
    "        \n",
    "        prob_dict[problem_id] = unique_entries     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6d686ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def warn_group_overlap(groups_arr, idx_a, idx_b, name_a=\"A\", name_b=\"B\"):\n",
    "    ga = set(groups_arr[idx_a])\n",
    "    gb = set(groups_arr[idx_b])\n",
    "    inter = ga & gb\n",
    "    if inter:\n",
    "        print(f\"[WARN] {name_a} and {name_b} share {len(inter)} problem_ids (leak risk).\")\n",
    "    else:\n",
    "        print(f\"[OK] No problem_id overlap between {name_a} and {name_b}.\")\n",
    "\n",
    "def split_dataset(data_path, dataset, seed=42, test_size=0.2, val_size=0.1):\n",
    "    # 1) Load full set\n",
    "    with open(os.path.join(data_path, f\"{dataset}_features.jsonl\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        #full_train_set = [json.loads(line) for line in f]\n",
    "\n",
    "        full_train_set = []\n",
    "        for line in f:\n",
    "            dumped_line = json.loads(line)\n",
    "            dumped_line[\"user_id\"] = \"\"\n",
    "            if dumped_line[\"LLM\"] == \"Human\":\n",
    "                dumped_line[\"label_int\"] = 0\n",
    "            else:\n",
    "                dumped_line[\"label_int\"] = 1\n",
    "\n",
    "            full_train_set.append(dumped_line)\n",
    "\n",
    "\n",
    "\n",
    "    # full_train_set = [x for x in full_train_set if x.get(\"LLM\") != \"GPT3.5\" and x.get(\"LLM\") != \"GEMINI\"]\n",
    "    seed_everything(seed)\n",
    "\n",
    "    # 2) Build features (pylint 기반)\n",
    "    for i, sample in enumerate(full_train_set):\n",
    "        # problem_id가 없을 수도 있으니 안전하게 기본값\n",
    "        if sample.get(\"problem_id\") is None:\n",
    "            sample[\"problem_id\"] = f\"__none__#{i}\"\n",
    "\n",
    "        if 'line' in dataset:\n",
    "            n_lines = len(sample.get('text', '').split('\\n'))\n",
    "            ccfeature_line = analyze_pylint_output_line(sample.get('eval', ''), n_lines)\n",
    "            sample['ccfeature'] = ccfeature_line\n",
    "        else:\n",
    "            sample['ccfeature'] = analyze_pylint_output(sample.get('eval', ''))\n",
    "\n",
    "    # 3) Arrays for splitting\n",
    "    labels = np.array([sample['label'] for sample in full_train_set])\n",
    "    groups = np.array([sample['problem_id'] for sample in full_train_set])\n",
    "\n",
    "    # 4) Group-aware Train/Test split\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=seed)\n",
    "    train_full_idx, test_idx = next(\n",
    "        gss.split(\n",
    "            np.zeros(len(full_train_set)),\n",
    "            labels,\n",
    "            groups=groups\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 5) Group-aware Train/Val split (within train_full)\n",
    "    gss_val = GroupShuffleSplit(n_splits=1, test_size=val_size, random_state=seed)\n",
    "    train_idx, val_idx = next(\n",
    "        gss_val.split(\n",
    "            np.zeros(len(train_full_idx)),\n",
    "            labels[train_full_idx],\n",
    "            groups=groups[train_full_idx]\n",
    "        )\n",
    "    )\n",
    "    # 인덱스를 원본 기준으로 변환\n",
    "    train_idx = train_full_idx[train_idx]\n",
    "    val_idx   = train_full_idx[val_idx]\n",
    "\n",
    "    # 6) 누수(그룹 겹침) 점검\n",
    "    warn_group_overlap(groups, train_idx, val_idx, \"Train\", \"Val\")\n",
    "    warn_group_overlap(groups, train_idx, test_idx, \"Train\", \"Test\")\n",
    "    warn_group_overlap(groups, val_idx,   test_idx, \"Val\",   \"Test\")\n",
    "\n",
    "    # 7) 실제 세트 구성\n",
    "    train_set = [full_train_set[i] for i in train_idx]\n",
    "    val_set   = [full_train_set[i] for i in val_idx]\n",
    "    test_set  = [full_train_set[i] for i in test_idx]\n",
    "\n",
    "    # 8) 라벨 분포 확인(옵션이지만 유용)\n",
    "    def distrib(name, arr):\n",
    "        c = Counter([s['label'] for s in arr])\n",
    "        total = len(arr)\n",
    "        print(f\"{name}: {total}  | human={c.get('human',0)} ({c.get('human',0)/total:.2%}), AI={c.get('AI',0)} ({c.get('AI',0)/total:.2%})\")\n",
    "\n",
    "    print(f\"Train: {len(train_set)}, Validation: {len(val_set)}, Test: {len(test_set)}\")\n",
    "    distrib(\"Train\", train_set)\n",
    "    distrib(\"Val\",   val_set)\n",
    "    distrib(\"Test\",  test_set)\n",
    "    \n",
    "    return [train_set, val_set, test_set]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1501f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model', type=str, default='Transformer')\n",
    "    parser.add_argument('--gpu', type=str, default='0')\n",
    "    parser.add_argument('--train_mode', type=str, default='classify')\n",
    "    parser.add_argument('--batch_size', type=int, default=32)\n",
    "    parser.add_argument('--seq_len', type=int, default=1024)\n",
    "    parser.add_argument('--dataset', type=str, default=\"\")\n",
    "    parser.add_argument('--method', type=str, default=\"focalbmesbinary_embedconcat_transformer256\")\n",
    "    \n",
    "    parser.add_argument('--train_ratio', type=float, default=0.9)\n",
    "    parser.add_argument('--split_dataset', action='store_true')\n",
    "    parser.add_argument('--data_path', type=str, default='')\n",
    "    parser.add_argument('--train_path', type=str, default='')\n",
    "    parser.add_argument('--valid_path', type=str, default='')\n",
    "    parser.add_argument('--test_path', type=str, default='')\n",
    "\n",
    "    parser.add_argument('--num_train_epochs', type=int, default=20)\n",
    "    parser.add_argument('--weight_decay', type=float, default=0.1)\n",
    "    parser.add_argument('--lr', type=float, default=5e-5)\n",
    "    parser.add_argument('--warm_up_ratio', type=float, default=0.1)\n",
    "    parser.add_argument('--seed', type=int, default=42, required=True)\n",
    "    parser.add_argument('--do_test', action='store_true')\n",
    "    parser.add_argument('--test_content', action='store_true')\n",
    "    \n",
    "    parser.add_argument('--ckpt_name', type=str, default='')\n",
    "    parser.add_argument('--alpha', type=float, default=0.5)\n",
    "    parser.add_argument('--testbed', type=str, required=True)\n",
    "\n",
    "    parser.add_argument('--at_feature_path', type=str, default='')\n",
    "    \n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bba197f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log INFO: split dataset...\n",
      "[OK] No problem_id overlap between Train and Val.\n",
      "[OK] No problem_id overlap between Train and Test.\n",
      "[OK] No problem_id overlap between Val and Test.\n",
      "Train: 1992, Validation: 231, Test: 564\n",
      "Train: 1992  | human=0 (0.00%), AI=1992 (100.00%)\n",
      "Val: 231  | human=0 (0.00%), AI=231 (100.00%)\n",
      "Test: 564  | human=0 (0.00%), AI=564 (100.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [00:01<00:00, 1273.30it/s]\n",
      "100%|██████████| 231/231 [00:00<00:00, 1459.26it/s]\n",
      "100%|██████████| 564/564 [00:00<00:00, 1691.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log INFO: do train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:42<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: train_loss 0.04510200750969705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.297755867242813\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 67.122\n",
      "Macro F1 Score: 40.163\n",
      "Binary F1 Score (pos): 0.000\n",
      "Precision/Recall per class:\n",
      "67.1,100.0,0.0,0.0\n",
      "CM [[TN FP],[FN TP]] = [[3148, 0], [1542, 0]]\n",
      "ROC_AUC (fpr-tpr): 0.591\n",
      "AUPRC: 0.364\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=67.1  MacroF1=40.2  BinF1(pos)=0.0\n",
      " P/R per class -> 0(H): 67.1/100.0 , 1(AI): 0.0/0.0\n",
      " CM [[TN FP],[FN TP]] = [[3148, 0], [1542, 0]]\n",
      "[thr=YoudenJ] thr=0.199 | Acc=50.7  MacroF1=50.6  BinF1(pos)=53.4\n",
      " P/R per class -> 0(H): 82.9/33.5 , 1(AI): 38.8/85.9\n",
      " CM [[TN FP],[FN TP]] = [[1055, 2093], [217, 1325]]\n",
      "[thr=bestPosF1] thr=0.192 | Acc=48.1  MacroF1=47.3  BinF1(pos)=54.0\n",
      " P/R per class -> 0(H): 87.7/26.5 , 1(AI): 38.1/92.4\n",
      " CM [[TN FP],[FN TP]] = [[833, 2315], [117, 1425]]\n",
      "67.1,40.2,0.0,67.1,100.0,0.0,0.0,0.591,0.364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:41<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: train_loss 0.03494816521803538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.1264781206846237\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 67.122\n",
      "Macro F1 Score: 40.163\n",
      "Binary F1 Score (pos): 0.000\n",
      "Precision/Recall per class:\n",
      "67.1,100.0,0.0,0.0\n",
      "CM [[TN FP],[FN TP]] = [[3148, 0], [1542, 0]]\n",
      "ROC_AUC (fpr-tpr): 0.728\n",
      "AUPRC: 0.580\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=67.1  MacroF1=40.2  BinF1(pos)=0.0\n",
      " P/R per class -> 0(H): 67.1/100.0 , 1(AI): 0.0/0.0\n",
      " CM [[TN FP],[FN TP]] = [[3148, 0], [1542, 0]]\n",
      "[thr=YoudenJ] thr=0.241 | Acc=70.7  MacroF1=65.9  BinF1(pos)=53.0\n",
      " P/R per class -> 0(H): 76.8/80.7 , 1(AI): 56.0/50.3\n",
      " CM [[TN FP],[FN TP]] = [[2539, 609], [766, 776]]\n",
      "[thr=bestPosF1] thr=0.144 | Acc=54.6  MacroF1=54.4  BinF1(pos)=56.7\n",
      " P/R per class -> 0(H): 89.0/36.9 , 1(AI): 41.3/90.7\n",
      " CM [[TN FP],[FN TP]] = [[1161, 1987], [144, 1398]]\n",
      "67.1,40.2,0.0,67.1,100.0,0.0,0.0,0.728,0.580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:41<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: train_loss 0.03230320753914023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.9870371744036674\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 74.456\n",
      "Macro F1 Score: 67.233\n",
      "Binary F1 Score (pos): 51.849\n",
      "Precision/Recall per class:\n",
      "76.0,90.4,68.2,41.8\n",
      "CM [[TN FP],[FN TP]] = [[2847, 301], [897, 645]]\n",
      "ROC_AUC (fpr-tpr): 0.777\n",
      "AUPRC: 0.639\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=74.5  MacroF1=66.8  BinF1(pos)=50.7\n",
      " P/R per class -> 0(H): 75.7/91.4 , 1(AI): 69.5/39.9\n",
      " CM [[TN FP],[FN TP]] = [[2878, 270], [926, 616]]\n",
      "[thr=YoudenJ] thr=0.380 | Acc=72.0  MacroF1=69.0  BinF1(pos)=59.5\n",
      " P/R per class -> 0(H): 80.7/76.5 , 1(AI): 56.7/62.6\n",
      " CM [[TN FP],[FN TP]] = [[2409, 739], [576, 966]]\n",
      "[thr=bestPosF1] thr=0.305 | Acc=66.1  MacroF1=65.4  BinF1(pos)=60.4\n",
      " P/R per class -> 0(H): 85.1/60.0 , 1(AI): 49.1/78.6\n",
      " CM [[TN FP],[FN TP]] = [[1890, 1258], [330, 1212]]\n",
      "74.5,67.2,51.8,76.0,90.4,68.2,41.8,0.777,0.639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:41<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: train_loss 0.030864491112648496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:05<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.9323926940560341\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 72.367\n",
      "Macro F1 Score: 56.995\n",
      "Binary F1 Score (pos): 31.283\n",
      "Precision/Recall per class:\n",
      "71.3,98.4,85.8,19.1\n",
      "CM [[TN FP],[FN TP]] = [[3099, 49], [1247, 295]]\n",
      "ROC_AUC (fpr-tpr): 0.792\n",
      "AUPRC: 0.651\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=72.2  MacroF1=56.7  BinF1(pos)=30.7\n",
      " P/R per class -> 0(H): 71.2/98.4 , 1(AI): 85.0/18.7\n",
      " CM [[TN FP],[FN TP]] = [[3097, 51], [1253, 289]]\n",
      "[thr=YoudenJ] thr=0.168 | Acc=70.0  MacroF1=68.6  BinF1(pos)=62.0\n",
      " P/R per class -> 0(H): 84.4/67.9 , 1(AI): 53.2/74.4\n",
      " CM [[TN FP],[FN TP]] = [[2138, 1010], [395, 1147]]\n",
      "[thr=bestPosF1] thr=0.168 | Acc=70.0  MacroF1=68.6  BinF1(pos)=62.0\n",
      " P/R per class -> 0(H): 84.4/67.9 , 1(AI): 53.2/74.4\n",
      " CM [[TN FP],[FN TP]] = [[2138, 1010], [395, 1147]]\n",
      "72.4,57.0,31.3,71.3,98.4,85.8,19.1,0.792,0.651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:41<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: train_loss 0.0297537792828821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:05<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.805026113986969\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 77.058\n",
      "Macro F1 Score: 70.630\n",
      "Binary F1 Score (pos): 56.891\n",
      "Precision/Recall per class:\n",
      "77.7,92.2,74.4,46.0\n",
      "CM [[TN FP],[FN TP]] = [[2904, 244], [832, 710]]\n",
      "ROC_AUC (fpr-tpr): 0.831\n",
      "AUPRC: 0.704\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=76.2  MacroF1=69.0  BinF1(pos)=54.0\n",
      " P/R per class -> 0(H): 76.7/92.6 , 1(AI): 73.8/42.6\n",
      " CM [[TN FP],[FN TP]] = [[2915, 233], [885, 657]]\n",
      "[thr=YoudenJ] thr=0.226 | Acc=71.6  MacroF1=70.7  BinF1(pos)=65.5\n",
      " P/R per class -> 0(H): 88.3/66.5 , 1(AI): 54.5/82.0\n",
      " CM [[TN FP],[FN TP]] = [[2094, 1054], [278, 1264]]\n",
      "[thr=bestPosF1] thr=0.226 | Acc=71.6  MacroF1=70.7  BinF1(pos)=65.5\n",
      " P/R per class -> 0(H): 88.3/66.5 , 1(AI): 54.5/82.0\n",
      " CM [[TN FP],[FN TP]] = [[2094, 1054], [278, 1264]]\n",
      "77.1,70.6,56.9,77.7,92.2,74.4,46.0,0.831,0.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:41<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: train_loss 0.028960735404065678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7710463479161263\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 78.252\n",
      "Macro F1 Score: 71.302\n",
      "Binary F1 Score (pos): 57.179\n",
      "Precision/Recall per class:\n",
      "77.6,94.9,81.1,44.2\n",
      "CM [[TN FP],[FN TP]] = [[2989, 159], [861, 681]]\n",
      "ROC_AUC (fpr-tpr): 0.846\n",
      "AUPRC: 0.721\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=76.7  MacroF1=68.9  BinF1(pos)=53.3\n",
      " P/R per class -> 0(H): 76.4/94.4 , 1(AI): 78.1/40.5\n",
      " CM [[TN FP],[FN TP]] = [[2973, 175], [918, 624]]\n",
      "[thr=YoudenJ] thr=0.225 | Acc=74.6  MacroF1=73.3  BinF1(pos)=67.3\n",
      " P/R per class -> 0(H): 87.8/72.2 , 1(AI): 58.3/79.6\n",
      " CM [[TN FP],[FN TP]] = [[2272, 876], [315, 1227]]\n",
      "[thr=bestPosF1] thr=0.225 | Acc=74.6  MacroF1=73.3  BinF1(pos)=67.3\n",
      " P/R per class -> 0(H): 87.8/72.2 , 1(AI): 58.3/79.6\n",
      " CM [[TN FP],[FN TP]] = [[2272, 876], [315, 1227]]\n",
      "78.3,71.3,57.2,77.6,94.9,81.1,44.2,0.846,0.721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:41<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: train_loss 0.02834845201245376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7506780102849007\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 76.482\n",
      "Macro F1 Score: 68.129\n",
      "Binary F1 Score (pos): 51.813\n",
      "Precision/Recall per class:\n",
      "75.9,95.1,79.4,38.5\n",
      "CM [[TN FP],[FN TP]] = [[2994, 154], [949, 593]]\n",
      "ROC_AUC (fpr-tpr): 0.848\n",
      "AUPRC: 0.722\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=76.1  MacroF1=66.9  BinF1(pos)=49.4\n",
      " P/R per class -> 0(H): 75.2/96.0 , 1(AI): 81.2/35.5\n",
      " CM [[TN FP],[FN TP]] = [[3021, 127], [994, 548]]\n",
      "[thr=YoudenJ] thr=0.210 | Acc=76.2  MacroF1=74.5  BinF1(pos)=68.1\n",
      " P/R per class -> 0(H): 87.2/75.5 , 1(AI): 60.8/77.4\n",
      " CM [[TN FP],[FN TP]] = [[2378, 770], [348, 1194]]\n",
      "[thr=bestPosF1] thr=0.229 | Acc=77.2  MacroF1=75.2  BinF1(pos)=68.2\n",
      " P/R per class -> 0(H): 86.2/78.5 , 1(AI): 62.9/74.4\n",
      " CM [[TN FP],[FN TP]] = [[2471, 677], [394, 1148]]\n",
      "76.5,68.1,51.8,75.9,95.1,79.4,38.5,0.848,0.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:41<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8: train_loss 0.027922430474843298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7299973741173744\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 77.761\n",
      "Macro F1 Score: 69.881\n",
      "Binary F1 Score (pos): 54.474\n",
      "Precision/Recall per class:\n",
      "76.7,96.0,83.3,40.5\n",
      "CM [[TN FP],[FN TP]] = [[3023, 125], [918, 624]]\n",
      "ROC_AUC (fpr-tpr): 0.861\n",
      "AUPRC: 0.748\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=77.1  MacroF1=68.8  BinF1(pos)=52.6\n",
      " P/R per class -> 0(H): 76.1/96.1 , 1(AI): 82.7/38.5\n",
      " CM [[TN FP],[FN TP]] = [[3024, 124], [948, 594]]\n",
      "[thr=YoudenJ] thr=0.188 | Acc=76.6  MacroF1=75.2  BinF1(pos)=69.2\n",
      " P/R per class -> 0(H): 88.5/74.9 , 1(AI): 61.0/80.0\n",
      " CM [[TN FP],[FN TP]] = [[2359, 789], [308, 1234]]\n",
      "[thr=bestPosF1] thr=0.196 | Acc=77.1  MacroF1=75.5  BinF1(pos)=69.3\n",
      " P/R per class -> 0(H): 87.8/76.6 , 1(AI): 62.1/78.3\n",
      " CM [[TN FP],[FN TP]] = [[2410, 738], [334, 1208]]\n",
      "77.8,69.9,54.5,76.7,96.0,83.3,40.5,0.861,0.748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:41<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9: train_loss 0.027750346809625626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:05<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7107026129961014\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 77.910\n",
      "Macro F1 Score: 70.021\n",
      "Binary F1 Score (pos): 54.641\n",
      "Precision/Recall per class:\n",
      "76.7,96.3,84.1,40.5\n",
      "CM [[TN FP],[FN TP]] = [[3030, 118], [918, 624]]\n",
      "ROC_AUC (fpr-tpr): 0.863\n",
      "AUPRC: 0.751\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=77.7  MacroF1=70.0  BinF1(pos)=54.9\n",
      " P/R per class -> 0(H): 76.9/95.5 , 1(AI): 81.9/41.3\n",
      " CM [[TN FP],[FN TP]] = [[3007, 141], [905, 637]]\n",
      "[thr=YoudenJ] thr=0.228 | Acc=78.1  MacroF1=76.3  BinF1(pos)=69.7\n",
      " P/R per class -> 0(H): 87.4/78.7 , 1(AI): 63.9/76.8\n",
      " CM [[TN FP],[FN TP]] = [[2478, 670], [358, 1184]]\n",
      "[thr=bestPosF1] thr=0.228 | Acc=78.1  MacroF1=76.3  BinF1(pos)=69.7\n",
      " P/R per class -> 0(H): 87.4/78.7 , 1(AI): 63.9/76.8\n",
      " CM [[TN FP],[FN TP]] = [[2478, 670], [358, 1184]]\n",
      "77.9,70.0,54.6,76.7,96.3,84.1,40.5,0.863,0.751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:41<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10: train_loss 0.0273684419928089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6951789259910583\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 77.783\n",
      "Macro F1 Score: 70.181\n",
      "Binary F1 Score (pos): 55.125\n",
      "Precision/Recall per class:\n",
      "76.9,95.6,82.1,41.5\n",
      "CM [[TN FP],[FN TP]] = [[3008, 140], [902, 640]]\n",
      "ROC_AUC (fpr-tpr): 0.871\n",
      "AUPRC: 0.759\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=78.1  MacroF1=70.8  BinF1(pos)=56.2\n",
      " P/R per class -> 0(H): 77.3/95.4 , 1(AI): 82.0/42.8\n",
      " CM [[TN FP],[FN TP]] = [[3003, 145], [882, 660]]\n",
      "[thr=YoudenJ] thr=0.201 | Acc=78.1  MacroF1=76.5  BinF1(pos)=70.5\n",
      " P/R per class -> 0(H): 88.5/77.4 , 1(AI): 63.3/79.4\n",
      " CM [[TN FP],[FN TP]] = [[2438, 710], [317, 1225]]\n",
      "[thr=bestPosF1] thr=0.203 | Acc=78.3  MacroF1=76.6  BinF1(pos)=70.5\n",
      " P/R per class -> 0(H): 88.3/78.0 , 1(AI): 63.7/78.9\n",
      " CM [[TN FP],[FN TP]] = [[2454, 694], [325, 1217]]\n",
      "77.8,70.2,55.1,76.9,95.6,82.1,41.5,0.871,0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:42<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11: train_loss 0.027183570204273103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6899524629116058\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 79.787\n",
      "Macro F1 Score: 73.937\n",
      "Binary F1 Score (pos): 61.588\n",
      "Precision/Recall per class:\n",
      "79.2,94.7,82.1,49.3\n",
      "CM [[TN FP],[FN TP]] = [[2982, 166], [782, 760]]\n",
      "ROC_AUC (fpr-tpr): 0.870\n",
      "AUPRC: 0.756\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=78.2  MacroF1=71.3  BinF1(pos)=57.2\n",
      " P/R per class -> 0(H): 77.6/94.9 , 1(AI): 80.9/44.2\n",
      " CM [[TN FP],[FN TP]] = [[2987, 161], [860, 682]]\n",
      "[thr=YoudenJ] thr=0.179 | Acc=76.0  MacroF1=74.9  BinF1(pos)=69.7\n",
      " P/R per class -> 0(H): 90.2/72.2 , 1(AI): 59.6/83.9\n",
      " CM [[TN FP],[FN TP]] = [[2272, 876], [248, 1294]]\n",
      "[thr=bestPosF1] thr=0.229 | Acc=78.8  MacroF1=76.7  BinF1(pos)=69.9\n",
      " P/R per class -> 0(H): 86.8/80.6 , 1(AI): 65.5/75.0\n",
      " CM [[TN FP],[FN TP]] = [[2538, 610], [386, 1156]]\n",
      "79.8,73.9,61.6,79.2,94.7,82.1,49.3,0.870,0.756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:41<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12: train_loss 0.02702988013033829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.688295803964138\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 78.550\n",
      "Macro F1 Score: 71.489\n",
      "Binary F1 Score (pos): 57.301\n",
      "Precision/Recall per class:\n",
      "77.6,95.6,82.9,43.8\n",
      "CM [[TN FP],[FN TP]] = [[3009, 139], [867, 675]]\n",
      "ROC_AUC (fpr-tpr): 0.875\n",
      "AUPRC: 0.766\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=78.1  MacroF1=70.7  BinF1(pos)=56.0\n",
      " P/R per class -> 0(H): 77.2/95.6 , 1(AI): 82.6/42.4\n",
      " CM [[TN FP],[FN TP]] = [[3010, 138], [888, 654]]\n",
      "[thr=YoudenJ] thr=0.180 | Acc=78.0  MacroF1=76.5  BinF1(pos)=70.8\n",
      " P/R per class -> 0(H): 89.2/76.4 , 1(AI): 62.7/81.2\n",
      " CM [[TN FP],[FN TP]] = [[2404, 744], [290, 1252]]\n",
      "[thr=bestPosF1] thr=0.202 | Acc=79.2  MacroF1=77.4  BinF1(pos)=71.0\n",
      " P/R per class -> 0(H): 87.8/80.1 , 1(AI): 65.6/77.3\n",
      " CM [[TN FP],[FN TP]] = [[2522, 626], [350, 1192]]\n",
      "78.6,71.5,57.3,77.6,95.6,82.9,43.8,0.875,0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:41<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13: train_loss 0.02684739637114699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:05<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6541578136384487\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 81.258\n",
      "Macro F1 Score: 77.046\n",
      "Binary F1 Score (pos): 67.214\n",
      "Precision/Recall per class:\n",
      "81.9,92.4,79.1,58.4\n",
      "CM [[TN FP],[FN TP]] = [[2910, 238], [641, 901]]\n",
      "ROC_AUC (fpr-tpr): 0.875\n",
      "AUPRC: 0.772\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=79.6  MacroF1=74.4  BinF1(pos)=62.8\n",
      " P/R per class -> 0(H): 79.9/92.9 , 1(AI): 78.4/52.3\n",
      " CM [[TN FP],[FN TP]] = [[2926, 222], [735, 807]]\n",
      "[thr=YoudenJ] thr=0.247 | Acc=77.7  MacroF1=76.3  BinF1(pos)=70.4\n",
      " P/R per class -> 0(H): 88.9/76.4 , 1(AI): 62.5/80.5\n",
      " CM [[TN FP],[FN TP]] = [[2404, 744], [300, 1242]]\n",
      "[thr=bestPosF1] thr=0.290 | Acc=79.5  MacroF1=77.5  BinF1(pos)=70.7\n",
      " P/R per class -> 0(H): 87.0/81.7 , 1(AI): 66.8/75.1\n",
      " CM [[TN FP],[FN TP]] = [[2572, 576], [384, 1158]]\n",
      "81.3,77.0,67.2,81.9,92.4,79.1,58.4,0.875,0.772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:41<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14: train_loss 0.026738903145231897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.32it/s]\n",
      "Epoch:  70%|███████   | 14/20 [11:16<04:49, 48.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6553976535797119\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 81.493\n",
      "Macro F1 Score: 77.389\n",
      "Binary F1 Score (pos): 67.756\n",
      "Precision/Recall per class:\n",
      "82.2,92.4,79.3,59.1\n",
      "CM [[TN FP],[FN TP]] = [[2910, 238], [630, 912]]\n",
      "ROC_AUC (fpr-tpr): 0.877\n",
      "AUPRC: 0.779\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=79.7  MacroF1=74.6  BinF1(pos)=63.1\n",
      " P/R per class -> 0(H): 80.1/93.0 , 1(AI): 78.6/52.7\n",
      " CM [[TN FP],[FN TP]] = [[2927, 221], [729, 813]]\n",
      "[thr=YoudenJ] thr=0.244 | Acc=77.8  MacroF1=76.4  BinF1(pos)=70.6\n",
      " P/R per class -> 0(H): 89.1/76.2 , 1(AI): 62.5/81.0\n",
      " CM [[TN FP],[FN TP]] = [[2399, 749], [293, 1249]]\n",
      "[thr=bestPosF1] thr=0.284 | Acc=79.1  MacroF1=77.3  BinF1(pos)=70.7\n",
      " P/R per class -> 0(H): 87.6/80.3 , 1(AI): 65.6/76.7\n",
      " CM [[TN FP],[FN TP]] = [[2528, 620], [359, 1183]]\n",
      "81.5,77.4,67.8,82.2,92.4,79.3,59.1,0.877,0.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:41<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15: train_loss 0.026570613185564678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6499367095530033\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 80.576\n",
      "Macro F1 Score: 75.780\n",
      "Binary F1 Score (pos): 65.002\n",
      "Precision/Recall per class:\n",
      "80.8,93.2,79.7,54.9\n",
      "CM [[TN FP],[FN TP]] = [[2933, 215], [696, 846]]\n",
      "ROC_AUC (fpr-tpr): 0.879\n",
      "AUPRC: 0.779\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=79.6  MacroF1=74.1  BinF1(pos)=62.2\n",
      " P/R per class -> 0(H): 79.6/93.6 , 1(AI): 79.6/51.0\n",
      " CM [[TN FP],[FN TP]] = [[2946, 202], [755, 787]]\n",
      "[thr=YoudenJ] thr=0.271 | Acc=79.8  MacroF1=77.8  BinF1(pos)=71.1\n",
      " P/R per class -> 0(H): 87.2/81.9 , 1(AI): 67.1/75.6\n",
      " CM [[TN FP],[FN TP]] = [[2578, 570], [377, 1165]]\n",
      "[thr=bestPosF1] thr=0.284 | Acc=80.1  MacroF1=78.0  BinF1(pos)=71.1\n",
      " P/R per class -> 0(H): 86.9/82.9 , 1(AI): 68.1/74.4\n",
      " CM [[TN FP],[FN TP]] = [[2611, 537], [395, 1147]]\n",
      "80.6,75.8,65.0,80.8,93.2,79.7,54.9,0.879,0.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:41<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16: train_loss 0.02643624350192055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.32it/s]\n",
      "Epoch:  80%|████████  | 16/20 [12:52<03:12, 48.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6550727039575577\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 80.405\n",
      "Macro F1 Score: 75.474\n",
      "Binary F1 Score (pos): 64.476\n",
      "Precision/Recall per class:\n",
      "80.6,93.3,79.8,54.1\n",
      "CM [[TN FP],[FN TP]] = [[2937, 211], [708, 834]]\n",
      "ROC_AUC (fpr-tpr): 0.881\n",
      "AUPRC: 0.781\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=79.4  MacroF1=73.5  BinF1(pos)=61.1\n",
      " P/R per class -> 0(H): 79.1/94.2 , 1(AI): 80.6/49.2\n",
      " CM [[TN FP],[FN TP]] = [[2966, 182], [784, 758]]\n",
      "[thr=YoudenJ] thr=0.271 | Acc=80.6  MacroF1=78.5  BinF1(pos)=71.7\n",
      " P/R per class -> 0(H): 87.0/83.6 , 1(AI): 69.0/74.5\n",
      " CM [[TN FP],[FN TP]] = [[2632, 516], [393, 1149]]\n",
      "[thr=bestPosF1] thr=0.274 | Acc=80.7  MacroF1=78.5  BinF1(pos)=71.7\n",
      " P/R per class -> 0(H): 86.9/83.9 , 1(AI): 69.3/74.3\n",
      " CM [[TN FP],[FN TP]] = [[2640, 508], [397, 1145]]\n",
      "80.4,75.5,64.5,80.6,93.3,79.8,54.1,0.881,0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:41<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17: train_loss 0.026435450754231878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6495837643742561\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 80.021\n",
      "Macro F1 Score: 74.848\n",
      "Binary F1 Score (pos): 63.441\n",
      "Precision/Recall per class:\n",
      "80.1,93.4,79.6,52.7\n",
      "CM [[TN FP],[FN TP]] = [[2940, 208], [729, 813]]\n",
      "ROC_AUC (fpr-tpr): 0.881\n",
      "AUPRC: 0.784\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=79.7  MacroF1=74.0  BinF1(pos)=61.8\n",
      " P/R per class -> 0(H): 79.4/94.4 , 1(AI): 81.3/49.9\n",
      " CM [[TN FP],[FN TP]] = [[2971, 177], [773, 769]]\n",
      "[thr=YoudenJ] thr=0.266 | Acc=80.4  MacroF1=78.4  BinF1(pos)=71.7\n",
      " P/R per class -> 0(H): 87.3/82.9 , 1(AI): 68.4/75.4\n",
      " CM [[TN FP],[FN TP]] = [[2611, 537], [380, 1162]]\n",
      "[thr=bestPosF1] thr=0.266 | Acc=80.4  MacroF1=78.4  BinF1(pos)=71.7\n",
      " P/R per class -> 0(H): 87.3/82.9 , 1(AI): 68.4/75.4\n",
      " CM [[TN FP],[FN TP]] = [[2611, 537], [380, 1162]]\n",
      "80.0,74.8,63.4,80.1,93.4,79.6,52.7,0.881,0.784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:41<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18: train_loss 0.02645324170589447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.32it/s]\n",
      "Epoch:  90%|█████████ | 18/20 [14:29<01:36, 48.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.654197208583355\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 80.362\n",
      "Macro F1 Score: 75.409\n",
      "Binary F1 Score (pos): 64.371\n",
      "Precision/Recall per class:\n",
      "80.5,93.3,79.8,54.0\n",
      "CM [[TN FP],[FN TP]] = [[2937, 211], [710, 832]]\n",
      "ROC_AUC (fpr-tpr): 0.881\n",
      "AUPRC: 0.782\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=79.4  MacroF1=73.4  BinF1(pos)=60.8\n",
      " P/R per class -> 0(H): 79.0/94.5 , 1(AI): 81.2/48.6\n",
      " CM [[TN FP],[FN TP]] = [[2974, 174], [792, 750]]\n",
      "[thr=YoudenJ] thr=0.198 | Acc=77.9  MacroF1=76.6  BinF1(pos)=71.1\n",
      " P/R per class -> 0(H): 89.9/75.6 , 1(AI): 62.4/82.6\n",
      " CM [[TN FP],[FN TP]] = [[2381, 767], [268, 1274]]\n",
      "[thr=bestPosF1] thr=0.274 | Acc=80.8  MacroF1=78.6  BinF1(pos)=71.6\n",
      " P/R per class -> 0(H): 86.7/84.4 , 1(AI): 69.8/73.6\n",
      " CM [[TN FP],[FN TP]] = [[2656, 492], [407, 1135]]\n",
      "80.4,75.4,64.4,80.5,93.3,79.8,54.0,0.881,0.782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:41<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19: train_loss 0.026372583671694712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.28it/s]\n",
      "Epoch:  95%|█████████▌| 19/20 [15:17<00:48, 48.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.650653462857008\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 80.256\n",
      "Macro F1 Score: 75.234\n",
      "Binary F1 Score (pos): 64.081\n",
      "Precision/Recall per class:\n",
      "80.4,93.3,79.7,53.6\n",
      "CM [[TN FP],[FN TP]] = [[2938, 210], [716, 826]]\n",
      "ROC_AUC (fpr-tpr): 0.882\n",
      "AUPRC: 0.784\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=79.6  MacroF1=73.8  BinF1(pos)=61.4\n",
      " P/R per class -> 0(H): 79.2/94.5 , 1(AI): 81.4/49.4\n",
      " CM [[TN FP],[FN TP]] = [[2974, 174], [781, 761]]\n",
      "[thr=YoudenJ] thr=0.197 | Acc=78.0  MacroF1=76.7  BinF1(pos)=71.2\n",
      " P/R per class -> 0(H): 90.0/75.6 , 1(AI): 62.4/82.8\n",
      " CM [[TN FP],[FN TP]] = [[2379, 769], [265, 1277]]\n",
      "[thr=bestPosF1] thr=0.276 | Acc=80.9  MacroF1=78.7  BinF1(pos)=71.8\n",
      " P/R per class -> 0(H): 86.8/84.4 , 1(AI): 69.8/73.8\n",
      " CM [[TN FP],[FN TP]] = [[2656, 492], [404, 1138]]\n",
      "80.3,75.2,64.1,80.4,93.3,79.7,53.6,0.882,0.784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:42<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20: train_loss 0.02623027107781834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.33it/s]\n",
      "Epoch: 100%|██████████| 20/20 [16:05<00:00, 48.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6499966308474541\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 80.426\n",
      "Macro F1 Score: 75.506\n",
      "Binary F1 Score (pos): 64.529\n",
      "Precision/Recall per class:\n",
      "80.6,93.3,79.8,54.2\n",
      "CM [[TN FP],[FN TP]] = [[2937, 211], [707, 835]]\n",
      "ROC_AUC (fpr-tpr): 0.882\n",
      "AUPRC: 0.783\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=79.6  MacroF1=73.8  BinF1(pos)=61.5\n",
      " P/R per class -> 0(H): 79.3/94.3 , 1(AI): 81.0/49.6\n",
      " CM [[TN FP],[FN TP]] = [[2969, 179], [777, 765]]\n",
      "[thr=YoudenJ] thr=0.197 | Acc=78.0  MacroF1=76.8  BinF1(pos)=71.4\n",
      " P/R per class -> 0(H): 90.2/75.4 , 1(AI): 62.4/83.3\n",
      " CM [[TN FP],[FN TP]] = [[2375, 773], [258, 1284]]\n",
      "[thr=bestPosF1] thr=0.273 | Acc=80.8  MacroF1=78.6  BinF1(pos)=71.8\n",
      " P/R per class -> 0(H): 86.9/84.1 , 1(AI): 69.5/74.2\n",
      " CM [[TN FP],[FN TP]] = [[2646, 502], [398, 1144]]\n",
      "80.4,75.5,64.5,80.6,93.3,79.8,54.2,0.882,0.783\n",
      "Reloading best model from ckpt/codenet(python)_gemini_hybrid_line_best_f1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 18/18 [00:16<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 77.863\n",
      "Macro F1 Score: 71.230\n",
      "Binary F1 Score (pos): 57.415\n",
      "Precision/Recall per class:\n",
      "75.8,96.9,88.1,42.6\n",
      "CM [[TN FP],[FN TP]] = [[8018, 258], [2562, 1901]]\n",
      "ROC_AUC (fpr-tpr): 0.861\n",
      "AUPRC: 0.776\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=76.6  MacroF1=69.6  BinF1(pos)=55.0\n",
      " P/R per class -> 0(H): 75.0/96.0 , 1(AI): 84.5/40.8\n",
      " CM [[TN FP],[FN TP]] = [[7942, 334], [2642, 1821]]\n",
      "[thr=YoudenJ] thr=0.221 | Acc=76.5  MacroF1=75.4  BinF1(pos)=70.2\n",
      " P/R per class -> 0(H): 87.0/75.0 , 1(AI): 63.1/79.2\n",
      " CM [[TN FP],[FN TP]] = [[6205, 2071], [928, 3535]]\n",
      "[thr=bestPosF1] thr=0.221 | Acc=76.5  MacroF1=75.4  BinF1(pos)=70.2\n",
      " P/R per class -> 0(H): 87.0/75.0 , 1(AI): 63.1/79.2\n",
      " CM [[TN FP],[FN TP]] = [[6205, 2071], [928, 3535]]\n",
      "77.9,71.2,57.4,75.8,96.9,88.1,42.6,0.861,0.776\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    sys.argv = [\n",
    "        \"train.py\",\n",
    "        \"--dataset\", \"codenet(python)_gemini_hybrid_line\",\n",
    "        \"--data_path\", \"./data\",\n",
    "        \"--seed\", \"42\",\n",
    "        \"--testbed\", \"toplevel\",\n",
    "        \"--ckpt_name\", \"codenet(python)_gemini_hybrid_line\",\n",
    "    ]\n",
    "\n",
    "    args = parse_args()\n",
    "    \n",
    "    print(\"Log INFO: split dataset...\")\n",
    "    df_ = split_dataset(data_path=args.data_path, seed=args.seed, dataset=args.dataset)  # [train, val, test]\n",
    "\n",
    "    en_labels = {\n",
    "        'human': 0,\n",
    "        'AI': 1\n",
    "    }\n",
    "    \n",
    "    id2label = construct_bmes_labels(en_labels)\n",
    "    label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "    prediction_method = 'most_common'\n",
    "\n",
    "    experiment_results = []\n",
    "\n",
    "    if 'revised' in args.dataset:\n",
    "        at_sidecar = AtcSidecar('./limo_atf/great_data/index.json')\n",
    "        datas = DataManagerTest(datas=df_, batch_size=args.batch_size, max_len=args.seq_len, human_label='human', id2label=id2label, at_feature_lookup=at_sidecar)\n",
    "    else:\n",
    "        at_sidecar = AtcSidecar('./limo_atf/great_data/index.json')\n",
    "        datas = DataManager(datas=df_, batch_size=args.batch_size, max_len=args.seq_len, human_label='human', id2label=id2label, at_feature_lookup=at_sidecar)\n",
    "\n",
    "    # classifier 선택\n",
    "    if args.method == 'focalbmesbinary_embedconcat_transformer256':\n",
    "        if args.testbed == 'toplevel':\n",
    "            if 'gemini' in args.dataset or 'gpt4' in args.dataset:\n",
    "                classifier = MultiModalConcatLineFocalBMESBinaryClassifier(id2labels=id2label, seq_len=args.seq_len, alpha=args.alpha)\n",
    "\n",
    "    ckpt_name = f'ckpt/{args.ckpt_name}_best_f1.pt'\n",
    "\n",
    "    trainer = SupervisedTrainer(datas, classifier, en_labels, id2label, args)\n",
    "    trainer.writer = SummaryWriter(log_dir=f\"runs/python_{args.ckpt_name}\")\n",
    "\n",
    "    experiment_result = {}\n",
    "\n",
    "    if args.do_test:\n",
    "        print(\"Log INFO: do test...\")\n",
    "        saved_model = torch.load(ckpt_name)\n",
    "        trainer.model.load_state_dict(saved_model.state_dict())\n",
    "        if 'hybrid' in args.dataset or 'revised' in args.dataset:\n",
    "            test_sent_result, _, test_raw_results = trainer.test(datas.test_dataloader, content_level_eval=False, prediction_method=prediction_method)\n",
    "            experiment_result['test_result'] = {'line': test_sent_result, 'raw': test_raw_results}\n",
    "        else:\n",
    "            test_sent_result, test_content_result, test_raw_results = trainer.test(datas.test_dataloader, content_level_eval=True, prediction_method=prediction_method)\n",
    "            experiment_result['test_result'] = {'line': test_sent_result, 'document': test_content_result, 'raw': test_raw_results}\n",
    "    else:\n",
    "        print(\"Log INFO: do train...\")\n",
    "        trainer.train(ckpt_name=ckpt_name, prediction_method=prediction_method)\n",
    "\n",
    "        if 'hybrid' in args.dataset or 'revised' in args.dataset:\n",
    "            test_sent_result, _, test_raw_results = trainer.test(datas.test_dataloader, content_level_eval=False, prediction_method=prediction_method)\n",
    "            experiment_result['test_result'] = {'line': test_sent_result, 'raw': test_raw_results}\n",
    "        else:\n",
    "            test_sent_result, test_content_result, test_raw_results = trainer.test(datas.test_dataloader, content_level_eval=True, prediction_method=prediction_method)\n",
    "            experiment_result['test_result'] = {'line': test_sent_result, 'document': test_content_result, 'raw': test_raw_results}\n",
    "\n",
    "    experiment_results.append(experiment_result)\n",
    "\n",
    "    with open(f'result/experiment_results_{args.ckpt_name}.json', 'w') as file:\n",
    "        json.dump(experiment_results, file, ensure_ascii=False, cls=NpEncoder)\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
