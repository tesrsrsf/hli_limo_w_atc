{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4a510d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "import warnings\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import ast\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from typing import Dict, Any, Optional\n",
    "import numpy as np\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "import datetime\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    roc_curve, auc, precision_recall_curve, average_precision_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from transformers.optimization import get_linear_schedule_with_warmup       # AdamW seems no longer available here\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "project_path = os.path.abspath('')\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n",
    "\n",
    "from dataloader_256atf import DataManager, DataManagerTest\n",
    "from model_4_256atf import MultiModalConcatLineFocalBMESBinaryClassifier\n",
    "\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, classification_report\n",
    "\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from dataloader_256atf import AtcSidecar\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e98e889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "with open('./pylint.txt','r') as f:\n",
    "    error_list = f.read()\n",
    "    error_codes = re.findall(r\"\\((\\w\\d{4})\\)\", error_list)\n",
    "    \n",
    "def analyze_pylint_output(eval_result: str) -> Counter:\n",
    "    analysis = [0]*len(error_codes)\n",
    "    error_pattern = re.compile(r\"\\d:\\d+:\\s(\\w\\d{4}):\\s\")\n",
    "    errors = error_pattern.findall(eval_result)\n",
    "\n",
    "    error_counts = Counter(errors)\n",
    "    \n",
    "    analysis = [error_counts[e] for e in error_codes]\n",
    "\n",
    "    return analysis\n",
    "\n",
    "\n",
    "def analyze_pylint_output_line(eval_result: str, total_lines: int):\n",
    "    error_pattern = re.compile(r\"(\\d+):\\d+:\\s(\\w\\d{4}):\\s\")\n",
    "    errors = error_pattern.findall(eval_result)\n",
    "    \n",
    "    line_error_counts = defaultdict(Counter)\n",
    "\n",
    "    for line, code in errors:\n",
    "        line_error_counts[int(line)][code] += 1\n",
    "    \n",
    "    analysis = [[0]*len(error_codes) for _ in range(total_lines)]\n",
    "    \n",
    "    # 각 줄별 에러 코드 카운트를 분석 결과 리스트에 저장\n",
    "    for line in range(total_lines):\n",
    "        if line in line_error_counts:\n",
    "            analysis[line] = [line_error_counts[line][code] for code in error_codes]\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "def split_code_sentence(code, use_sp=False):\n",
    "        import re\n",
    "        pattern = re.compile(\n",
    "        r'\"\"\"|\\'\\'\\'|\"|\\'|#|==|'\n",
    "        r'\\n|'\n",
    "        r'[^\\S\\n]+|'\n",
    "        r'\\w+|[.,()\\[\\]{};:\\=\\_\\+\\-\\*\\/\\~\\!\\%\\^\\&\\<\\>\\?]')\n",
    "        \n",
    "        tokens = pattern.findall(code)\n",
    "        return tokens\n",
    "\n",
    "def ccfeature_line_to_token_level(code):\n",
    "    code_tokens = split_code_sentence(code)\n",
    "    count = 0\n",
    "    line_num_list = []\n",
    "    for token in code_tokens:\n",
    "        line_num_list.append(count)\n",
    "        if token == '\\n':\n",
    "            count += 1\n",
    "    return line_num_list[:1024]\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, original_dataset, indices):\n",
    "        self.original_dataset = original_dataset\n",
    "        self.indices = [int(idx) for idx in indices]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        real_idx = self.indices[index]\n",
    "        return self.original_dataset[int(real_idx)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "\n",
    "def get_roc_metrics(true_labels, pred_labels):\n",
    "    fpr, tpr, thresholds = roc_curve(true_labels, pred_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    J = tpr - fpr\n",
    "    ix = np.argmax(J)\n",
    "    best_thresh = thresholds[ix]\n",
    "    print('Best Threshold=%f, sensitivity = %.3f, specificity = %.3f, J=%.3f' % (best_thresh, tpr[ix], 1-fpr[ix], J[ix]))\n",
    "    return float(roc_auc)\n",
    "\n",
    "class SupervisedTrainer:\n",
    "    def __init__(self, data, model, en_labels, id2label, args):\n",
    "        self.data = data\n",
    "        self.model = model\n",
    "        self.en_labels = en_labels\n",
    "        self.id2label = id2label\n",
    "\n",
    "        self.seq_len = args.seq_len\n",
    "        self.num_train_epochs = args.num_train_epochs\n",
    "        self.weight_decay = args.weight_decay\n",
    "        self.lr = args.lr\n",
    "        self.warm_up_ratio = args.warm_up_ratio\n",
    "\n",
    "        self.device = torch.device(\n",
    "            'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "        self._create_optimizer_and_scheduler()\n",
    "        \n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_f1_score = 0.0\n",
    "        self.best_model_path = None\n",
    "        self.writer = None\n",
    "        self.loss_function = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "        self.threshold = 0.5\n",
    "\n",
    "    def _create_optimizer_and_scheduler(self):\n",
    "        num_training_steps = len(\n",
    "            self.data.train_dataloader) * self.num_train_epochs\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "\n",
    "        named_parameters = self.model.named_parameters()\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in named_parameters\n",
    "                    if not any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\":\n",
    "                self.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in named_parameters\n",
    "                    if any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\":\n",
    "                0.0,\n",
    "            },\n",
    "        ]\n",
    "        self.optimizer = AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr=self.lr,\n",
    "            betas=(0.9, 0.98),\n",
    "            eps=1e-8,\n",
    "        )\n",
    "        self.scheduler = get_linear_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=int(self.warm_up_ratio * num_training_steps),\n",
    "            num_training_steps=num_training_steps)\n",
    "\n",
    "    def train(self, ckpt_name='linear_en.pt', prediction_method=\"most_common\"):\n",
    "        \n",
    "        for epoch in trange(int(self.num_train_epochs), desc=\"Epoch\"):\n",
    "            self.model.train()\n",
    "            tr_loss = 0\n",
    "            nb_tr_steps = 0\n",
    "            # train\n",
    "            for step, inputs in enumerate(\n",
    "                    tqdm(self.data.train_dataloader, desc=\"Iteration\")):\n",
    "                # send batch data to GPU\n",
    "                for k, v in inputs.items():\n",
    "                    if isinstance(v, torch.Tensor):\n",
    "                        inputs[k] = v.to(self.device)\n",
    "                with torch.set_grad_enabled(True):\n",
    "                    labels = inputs['labels']\n",
    "                    output = self.model(inputs['features'], inputs['labels'], inputs['ccfeatures'], inputs['atfeatures'])#, inputs['line_indices'])\n",
    "                    logits = output['logits']\n",
    "                    loss = output['loss']\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    \n",
    "                    # print(\"KSY =======================\")\n",
    "                    # for name, p in self.model.named_parameters():\n",
    "                    #     if 'feature_encoder' in name:\n",
    "                    #         print(name)\n",
    "                    #         print(p.grad)\n",
    "                    #         exit()\n",
    "                            \n",
    "                    self.optimizer.step()\n",
    "                    self.scheduler.step()\n",
    "\n",
    "                    tr_loss += loss.item()\n",
    "                    nb_tr_steps += 1\n",
    "            \n",
    "                if step % 50 == 0:\n",
    "                    self.writer.add_scalar('Training Loss', loss.item(), epoch * len(self.data.train_dataloader) + step)\n",
    "            \n",
    "            \n",
    "            avg_train_loss = tr_loss / nb_tr_steps\n",
    "            print(f'epoch {epoch+1}: train_loss {avg_train_loss}')\n",
    "            self.writer.add_scalar('Average Training Loss', avg_train_loss, epoch)\n",
    "\n",
    "            # Validate data at the end of every epoch\n",
    "            val_loss, sent_result = self.valid(prediction_method=prediction_method)\n",
    "            self.writer.add_scalar('Validation Loss', val_loss, epoch)\n",
    "\n",
    "            # save the best model\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "                self.best_model_path = f\"{ckpt_name}\"\n",
    "                self.writer.add_scalar('Best Validation Loss', self.best_val_loss, epoch)\n",
    "                torch.save(self.model.cpu(), self.best_model_path)\n",
    "                self.model.to(self.device)\n",
    "\n",
    "        # then reload the best model in the end\n",
    "        if self.best_model_path:\n",
    "            print(f\"Reloading best model from {self.best_model_path}\")\n",
    "            self.model.load_state_dict(torch.load(self.best_model_path, weights_only=False).state_dict())\n",
    "            self.model.to(self.device)\n",
    "        \n",
    "        self.writer.close()\n",
    "        return\n",
    "    \n",
    "    def valid(self, content_level_eval=False, prediction_method=\"most_common\"):\n",
    "        self.model.eval()\n",
    "        texts = []\n",
    "        true_labels = []\n",
    "        pred_labels = []\n",
    "        total_logits = []\n",
    "        total_probs = []\n",
    "        total_loss = 0.0\n",
    "        total_steps = 0\n",
    "        \n",
    "        for step, inputs in enumerate(\n",
    "                tqdm(self.data.val_dataloader, desc=\"Iteration\")):\n",
    "            for k, v in inputs.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    inputs[k] = v.to(self.device)\n",
    "            with torch.no_grad():\n",
    "                labels_ = inputs['labels']\n",
    "                output = self.model(inputs['features'], inputs['labels'], inputs['ccfeatures'], inputs['atfeatures'])\n",
    "                preds = output['preds']\n",
    "    \n",
    "                logits_ = output['logits']\n",
    "                \n",
    "                probabilities = F.softmax(logits_, dim=-1)\n",
    "                \n",
    "                logits = logits_.view(-1, logits_.size(-1))\n",
    "                labels = labels_.view(-1)\n",
    "                loss = self.loss_function(logits, labels)\n",
    "                total_loss += loss.item()\n",
    "                total_steps += 1\n",
    "\n",
    "                texts.extend(inputs['text'])\n",
    "                pred_labels.extend(preds.cpu().tolist())\n",
    "                true_labels.extend(labels_.cpu().tolist())\n",
    "                total_probs.extend(probabilities)\n",
    "\n",
    "        avg_val_loss = total_loss / total_steps\n",
    "        print(f\"Validation Loss: {avg_val_loss}\")\n",
    "        \n",
    "        print(\"*\" * 8, \"Sentence Level Evalation\", \"*\" * 8)\n",
    "        #word_result, sent_result = self.sent_level_eval(texts, true_labels, pred_labels, total_probs, prediction_method)\n",
    "        sent_result = self.sent_level_eval(texts, true_labels, pred_labels, total_probs, prediction_method)\n",
    "        \n",
    "        return avg_val_loss, sent_result\n",
    "    \n",
    "    def test(self, test_dataloader, content_level_eval=False, prediction_method=\"most_common\"):\n",
    "        self.model.eval()\n",
    "        texts = []\n",
    "        true_labels = []\n",
    "        pred_labels = []\n",
    "        total_logits = []\n",
    "        total_probs = []\n",
    "        problem_ids = []\n",
    "        user_ids = []\n",
    "        \n",
    "        for step, inputs in enumerate(\n",
    "                tqdm(test_dataloader, desc=\"Iteration\")):\n",
    "            for k, v in inputs.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    inputs[k] = v.to(self.device)\n",
    "            with torch.no_grad():\n",
    "                labels = inputs['labels']\n",
    "                output = self.model(inputs['features'], inputs['labels'], inputs['ccfeatures'], inputs['atfeatures'])#, inputs['line_indices'])\n",
    "                logits = output['logits']\n",
    "                preds = output['preds']\n",
    "                problem_id = inputs['problem_id']\n",
    "                user_id = inputs['user_id']\n",
    "                \n",
    "                probabilities = F.softmax(logits, dim=-1)\n",
    "\n",
    "                texts.extend(inputs['text'])\n",
    "                pred_labels.extend(preds.cpu().tolist())\n",
    "                true_labels.extend(labels.cpu().tolist())\n",
    "                problem_ids.extend(problem_id)\n",
    "                user_ids.extend(user_id)\n",
    "                total_logits.extend(logits.cpu().tolist())\n",
    "                total_probs.extend(probabilities)\n",
    "        \n",
    "        line_counts = [len(text.split('\\n')) for text in texts]\n",
    "        \n",
    "        if content_level_eval:\n",
    "            # content level evaluation\n",
    "            print(\"*\" * 8, \"Content Level Evalation\", \"*\" * 8)\n",
    "            content_result = self.content_level_eval(texts, true_labels, pred_labels, total_probs, prediction_method)\n",
    "        else:\n",
    "            content_result = None\n",
    "        print(\"*\" * 8, \"Sentence Level Evalation\", \"*\" * 8)\n",
    "        #word_result, sent_result = self.sent_level_eval(texts, true_labels, pred_labels, total_probs, prediction_method)\n",
    "        sent_result = self.sent_level_eval(texts, true_labels, pred_labels, total_probs, prediction_method)\n",
    "            \n",
    "        # return sent_result, content_result, {'text':texts,'pred':pred_labels, 'true':true_labels, 'problem_id':problem_ids, 'user_id': user_ids}\n",
    "        return sent_result, content_result, {'text': texts, 'pred': pred_labels, 'true': true_labels, 'problem_id':problem_ids, 'user_id':user_ids, 'line_count':line_counts}\n",
    "\n",
    "    \n",
    "    def content_level_eval(self, texts, true_labels, pred_labels, pred_probs, prediction_method='most_common'):\n",
    "        if prediction_method =='threshold':\n",
    "            threshold = self.threshold\n",
    "        else:\n",
    "            threshold = None\n",
    "            pred_labels_threshold = pred_labels\n",
    "        \n",
    "        true_content_labels = []\n",
    "        pred_content_labels = []\n",
    "        pred_content_probs = []\n",
    "        \n",
    "        for text, true_label, pred_label, pred_prob in zip(texts, true_labels, pred_labels_threshold, pred_probs):\n",
    "            true_label = np.array(true_label)\n",
    "            pred_label = np.array(pred_label)\n",
    "            pred_prob = np.array(pred_prob.cpu())\n",
    "            \n",
    "            mask = true_label != -1\n",
    "            true_label = true_label[mask].tolist()\n",
    "            pred_label = pred_label[mask].tolist()\n",
    "            \n",
    "            pred_prob = torch.tensor(pred_prob[mask])\n",
    "            true_common_tag = self._get_most_common_tag(true_label)\n",
    "            true_content_labels.append(true_common_tag[0])\n",
    "            \n",
    "            pred_common_tag = self._get_most_common_tag(pred_label)\n",
    "            pred_content_labels.append(pred_common_tag[0])\n",
    "            \n",
    "            cont_prob = pred_prob[:, 4:8].sum(dim=1)\n",
    "            pred_content_prob = torch.mean(cont_prob, dim=0)\n",
    "            pred_content_probs.append(pred_content_prob.item())\n",
    "            \n",
    "        true_content_labels = [self.en_labels[label] for label in true_content_labels]\n",
    "        pred_content_labels = [self.en_labels[label] for label in pred_content_labels]\n",
    "        \n",
    "        result = self._get_precision_recall_acc_f1(true_content_labels, pred_content_labels, pred_content_probs)\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def sent_level_eval(self, texts, true_labels, pred_labels, pred_probs, prediction_method='most_common'):\n",
    "        if prediction_method =='threshold':\n",
    "            threshold = self.threshold\n",
    "        else:\n",
    "            threshold = None\n",
    "            pred_labels_threshold = pred_labels\n",
    "        \n",
    "        # For line-wise labeling\n",
    "        true_sent_labels = []\n",
    "        pred_sent_labels = []\n",
    "        pred_sent_probs = []\n",
    "        for text, true_label, pred_label, pred_prob in zip(texts, true_labels, pred_labels_threshold, pred_probs):\n",
    "            true_label = np.array(true_label)\n",
    "            pred_label = np.array(pred_label)\n",
    "            pred_prob = np.array(pred_prob.cpu())\n",
    "            mask = true_label != -1\n",
    "            true_label = true_label[mask].tolist()\n",
    "            pred_label = pred_label[mask].tolist()\n",
    "            pred_prob = torch.tensor(pred_prob[mask])\n",
    "            sents = text.split('\\n')\n",
    "            for true_label_idx in range(len(true_label)):\n",
    "                if sents[true_label_idx] == '' or sents[true_label_idx].isspace():  # 빈 문장일 경우 처리하지 않음\n",
    "                    continue\n",
    "                true_sent_label = self.id2label[true_label[true_label_idx]]\n",
    "                pred_sent_label = self.id2label[pred_label[true_label_idx]]\n",
    "                \n",
    "                true_sent_labels.append(true_sent_label.split('-')[-1])\n",
    "                pred_sent_prob = pred_prob[true_label_idx, 4:8].sum()\n",
    "                pred_sent_probs.append(pred_sent_prob.item())\n",
    "                pred_sent_labels.append(pred_sent_label.split('-')[-1])\n",
    "            \n",
    "        true_sent_labels = [self.en_labels[label] for label in true_sent_labels]\n",
    "        pred_sent_labels = [self.en_labels[label] for label in pred_sent_labels]\n",
    "        \n",
    "        sent_result = self._get_precision_recall_acc_f1(true_sent_labels, pred_sent_labels, pred_sent_probs)\n",
    "        return sent_result\n",
    "    \n",
    "    \n",
    "    def _get_threshold_tag(self, logits, machine_threshold=0.5):\n",
    "        human_logits = logits[:, :, :4]  # Human Classes\n",
    "        machine_logits = logits[:, :, 4:] # Machine Classes\n",
    "        human_scores = torch.sum(human_logits, dim=-1)  # Shape: [batch_size, seq_len]\n",
    "        machine_scores = torch.sum(machine_logits, dim=-1)        # Shape: [batch_size, seq_len]\n",
    "        pred_labels = torch.where(machine_scores >= machine_threshold, 4, 0)  # 0 for Human, 4 for AI\n",
    "        \n",
    "        return pred_labels.cpu().tolist()\n",
    "    \n",
    "    def _get_most_common_tag(self, tags):\n",
    "        \"\"\"most_common_tag is a tuple: (tag, times)\"\"\"\n",
    "        from collections import Counter\n",
    "        tags = [self.id2label[tag] for tag in tags]\n",
    "        tags = [tag.split('-')[-1] for tag in tags]\n",
    "        tag_counts = Counter(tags)\n",
    "        most_common_tag = tag_counts.most_common(1)[0]\n",
    "        return most_common_tag\n",
    "    \n",
    "    def _get_precision_recall_acc_f1(self, true_labels, pred_labels, pred_probs=None, pos_label: int = 1) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        true_labels: [0/1]\n",
    "        pred_labels: 이미 threshold가 적용된 0/1 예측\n",
    "        pred_probs : 선택. 점수(양성=pos_label의 확률/로짓 등). 있으면 ROC/AUPRC과 임계값 탐색 리포트 추가.\n",
    "        pos_label  : 양성 클래스(기본 1)\n",
    "        \"\"\"\n",
    "        y_true = np.asarray(true_labels).astype(int)\n",
    "        y_pred = np.asarray(pred_labels).astype(int)\n",
    "\n",
    "        # --- 기본 리포트(주어진 라벨 기준) ---\n",
    "        acc  = accuracy_score(y_true, y_pred)\n",
    "        mF1  = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        bF1  = f1_score(y_true, y_pred, average='binary', pos_label=pos_label, zero_division=0)\n",
    "        prec = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "        rec  = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "        cm   = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "\n",
    "        print(\"=== Given labels (as-is) ===\")\n",
    "        print(\"Accuracy: {:.3f}\".format(acc*100))\n",
    "        print(\"Macro F1 Score: {:.3f}\".format(mF1*100))\n",
    "        print(\"Binary F1 Score (pos): {:.3f}\".format(bF1*100))\n",
    "        print(\"Precision/Recall per class:\")\n",
    "        print(\"{:.1f},{:.1f},{:.1f},{:.1f}\".format(prec[0]*100, rec[0]*100, prec[1]*100, rec[1]*100))\n",
    "        print(f\"CM [[TN FP],[FN TP]] = {cm.tolist()}\")\n",
    "\n",
    "        # 결과 dict 시작\n",
    "        result: Dict[str, Any] = {\n",
    "            \"given_labels\": {\n",
    "                \"accuracy\": acc, \"macro_f1\": mF1, \"binary_f1\": bF1,\n",
    "                \"precision\": prec, \"recall\": rec, \"cm\": cm\n",
    "            },\n",
    "            \"roc_auc\": None,\n",
    "            \"auprc\": None,\n",
    "            \"thresholds\": {}\n",
    "        }\n",
    "\n",
    "        # --- 점수 기반 추가 리포트 ---\n",
    "        if pred_probs is not None:\n",
    "            y_score = np.asarray(pred_probs, dtype=float)\n",
    "\n",
    "            # ROC / AUPRC\n",
    "            try:\n",
    "                fpr, tpr, thr_roc = roc_curve(y_true, y_score, pos_label=pos_label)\n",
    "                roc_auc = float(auc(fpr, tpr))\n",
    "            except Exception:\n",
    "                roc_auc = None\n",
    "\n",
    "            try:\n",
    "                auprc = float(average_precision_score(y_true, y_score, pos_label=pos_label))\n",
    "            except Exception:\n",
    "                auprc = None\n",
    "\n",
    "            print(f\"ROC_AUC (fpr-tpr): {roc_auc:.3f}\" if roc_auc is not None else \"ROC_AUC: N/A\")\n",
    "            print(f\"AUPRC: {auprc:.3f}\" if auprc is not None else \"AUPRC: N/A\")\n",
    "\n",
    "            # Helper: 특정 threshold에서 평가\n",
    "            def eval_at(thr: float, tag: str) -> Dict[str, Any]:\n",
    "                y_hat = (y_score > thr).astype(int)\n",
    "                acc_  = accuracy_score(y_true, y_hat)\n",
    "                mF1_  = f1_score(y_true, y_hat, average='macro', zero_division=0)\n",
    "                bF1_  = f1_score(y_true, y_hat, average='binary', pos_label=pos_label, zero_division=0)\n",
    "                pr_   = precision_score(y_true, y_hat, average=None, zero_division=0)\n",
    "                rc_   = recall_score(y_true, y_hat, average=None, zero_division=0)\n",
    "                cm_   = confusion_matrix(y_true, y_hat, labels=[0,1])\n",
    "                print(f\"[{tag}] thr={thr:.3f} | Acc={acc_*100:.1f}  MacroF1={mF1_*100:.1f}  BinF1(pos)={bF1_*100:.1f}\")\n",
    "                print(\" P/R per class -> 0(H): {:.1f}/{:.1f} , 1(AI): {:.1f}/{:.1f}\".format(pr_[0]*100, rc_[0]*100, pr_[1]*100, rc_[1]*100))\n",
    "                print(f\" CM [[TN FP],[FN TP]] = {cm_.tolist()}\")\n",
    "                return {\"thr\": float(thr), \"accuracy\": acc_, \"macro_f1\": mF1_, \"binary_f1\": bF1_, \"precision\": pr_, \"recall\": rc_, \"cm\": cm_}\n",
    "\n",
    "            # Youden J (TPR - FPR) 최대\n",
    "            def best_thr_youden() -> float:\n",
    "                if roc_auc is None or len(thr_roc) == 0:\n",
    "                    return 0.5\n",
    "                J = tpr - fpr\n",
    "                i = int(np.argmax(J))\n",
    "                return float(thr_roc[i])\n",
    "\n",
    "            # 양성 F1 최대(PR 기반)\n",
    "            def best_thr_posF1() -> float:\n",
    "                prec_curve, rec_curve, thr_pr = precision_recall_curve(y_true, y_score, pos_label=pos_label)\n",
    "                if len(thr_pr) == 0:\n",
    "                    return 0.5\n",
    "                f1_curve = (2 * prec_curve * rec_curve) / (prec_curve + rec_curve + 1e-12)\n",
    "                i = int(np.nanargmax(f1_curve[:-1]))  # 마지막 점은 threshold 없음\n",
    "                return float(thr_pr[i])\n",
    "\n",
    "            thr05     = 0.5\n",
    "            thrJ      = best_thr_youden()\n",
    "            thrBestF1 = best_thr_posF1()\n",
    "\n",
    "            print(\"=== Threshold sweeps on scores ===\")\n",
    "            res05  = eval_at(thr05, \"thr=0.5\")\n",
    "            resJ   = eval_at(thrJ, \"thr=YoudenJ\")\n",
    "            resF1  = eval_at(thrBestF1, \"thr=bestPosF1\")\n",
    "\n",
    "            result.update({\n",
    "                \"roc_auc\": roc_auc,\n",
    "                \"auprc\": auprc,\n",
    "                \"thresholds\": {\n",
    "                    \"thr@0.5\": res05,\n",
    "                    \"thr@youden\": resJ,\n",
    "                    \"thr@best_posF1\": resF1\n",
    "                }\n",
    "            })\n",
    "        else:\n",
    "            print(\"ROC_AUC (fpr-tpr): N/A (pred_probs is None)\")\n",
    "            print(\"AUPRC: N/A (pred_probs is None)\")\n",
    "\n",
    "        # CSV 한 줄 요약(기존 포맷과 유사)\n",
    "        pr_line = \"{:.1f},{:.1f},{:.1f},{:.1f}\".format(prec[0]*100, rec[0]*100, prec[1]*100, rec[1]*100)\n",
    "        print(\"{:.1f},{:.1f},{:.1f},{},{:.3f},{}\".format(\n",
    "            acc*100, mF1*100, bF1*100, pr_line, result[\"roc_auc\"] if result[\"roc_auc\"] is not None else float(\"nan\"),\n",
    "            f\"{result['auprc']:.3f}\" if result[\"auprc\"] is not None else \"N/A\"\n",
    "        ))\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "def construct_bmes_labels(labels):\n",
    "    prefix = ['B-', 'M-', 'E-', 'S-']\n",
    "    id2label = {}\n",
    "    counter = 0\n",
    "\n",
    "    for label, id in labels.items():\n",
    "        for pre in prefix:\n",
    "            id2label[counter] = pre + label\n",
    "            counter += 1\n",
    "    \n",
    "    return id2label\n",
    "\n",
    "def remove_duplicates(prob_dict):\n",
    "    total_p = 0\n",
    "    total = 0\n",
    "    for problem_id, entries in prob_dict.items():\n",
    "        n = 0\n",
    "        unique_texts = set()\n",
    "        unique_entries = []\n",
    "        \n",
    "        for entry in entries:\n",
    "            if entry['text'] not in unique_texts:\n",
    "                unique_entries.append(entry)\n",
    "                unique_texts.add(entry['text'])\n",
    "            else:\n",
    "                n += 1\n",
    "        if n != 0:\n",
    "            total_p += 1\n",
    "        total += n\n",
    "        \n",
    "        prob_dict[problem_id] = unique_entries     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6d686ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def warn_group_overlap(groups_arr, idx_a, idx_b, name_a=\"A\", name_b=\"B\"):\n",
    "    ga = set(groups_arr[idx_a])\n",
    "    gb = set(groups_arr[idx_b])\n",
    "    inter = ga & gb\n",
    "    if inter:\n",
    "        print(f\"[WARN] {name_a} and {name_b} share {len(inter)} problem_ids (leak risk).\")\n",
    "    else:\n",
    "        print(f\"[OK] No problem_id overlap between {name_a} and {name_b}.\")\n",
    "\n",
    "def split_dataset(data_path, dataset, seed=42, test_size=0.2, val_size=0.1):\n",
    "    # 1) Load full set\n",
    "    with open(os.path.join(data_path, f\"{dataset}_features.jsonl\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        #full_train_set = [json.loads(line) for line in f]\n",
    "\n",
    "        full_train_set = []\n",
    "        for line in f:\n",
    "            dumped_line = json.loads(line)\n",
    "            dumped_line[\"user_id\"] = \"\"\n",
    "            if dumped_line[\"LLM\"] == \"Human\":\n",
    "                dumped_line[\"label_int\"] = 0\n",
    "            else:\n",
    "                dumped_line[\"label_int\"] = 1\n",
    "\n",
    "            full_train_set.append(dumped_line)\n",
    "\n",
    "\n",
    "\n",
    "    # full_train_set = [x for x in full_train_set if x.get(\"LLM\") != \"GPT3.5\" and x.get(\"LLM\") != \"GEMINI\"]\n",
    "    seed_everything(seed)\n",
    "\n",
    "    # 2) Build features (pylint 기반)\n",
    "    for i, sample in enumerate(full_train_set):\n",
    "        # problem_id가 없을 수도 있으니 안전하게 기본값\n",
    "        if sample.get(\"problem_id\") is None:\n",
    "            sample[\"problem_id\"] = f\"__none__#{i}\"\n",
    "\n",
    "        if 'line' in dataset:\n",
    "            n_lines = len(sample.get('text', '').split('\\n'))\n",
    "            ccfeature_line = analyze_pylint_output_line(sample.get('eval', ''), n_lines)\n",
    "            sample['ccfeature'] = ccfeature_line\n",
    "        else:\n",
    "            sample['ccfeature'] = analyze_pylint_output(sample.get('eval', ''))\n",
    "\n",
    "    # 3) Arrays for splitting\n",
    "    labels = np.array([sample['label'] for sample in full_train_set])\n",
    "    groups = np.array([sample['problem_id'] for sample in full_train_set])\n",
    "\n",
    "    # 4) Group-aware Train/Test split\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=seed)\n",
    "    train_full_idx, test_idx = next(\n",
    "        gss.split(\n",
    "            np.zeros(len(full_train_set)),\n",
    "            labels,\n",
    "            groups=groups\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 5) Group-aware Train/Val split (within train_full)\n",
    "    gss_val = GroupShuffleSplit(n_splits=1, test_size=val_size, random_state=seed)\n",
    "    train_idx, val_idx = next(\n",
    "        gss_val.split(\n",
    "            np.zeros(len(train_full_idx)),\n",
    "            labels[train_full_idx],\n",
    "            groups=groups[train_full_idx]\n",
    "        )\n",
    "    )\n",
    "    # 인덱스를 원본 기준으로 변환\n",
    "    train_idx = train_full_idx[train_idx]\n",
    "    val_idx   = train_full_idx[val_idx]\n",
    "\n",
    "    # 6) 누수(그룹 겹침) 점검\n",
    "    warn_group_overlap(groups, train_idx, val_idx, \"Train\", \"Val\")\n",
    "    warn_group_overlap(groups, train_idx, test_idx, \"Train\", \"Test\")\n",
    "    warn_group_overlap(groups, val_idx,   test_idx, \"Val\",   \"Test\")\n",
    "\n",
    "    # 7) 실제 세트 구성\n",
    "    train_set = [full_train_set[i] for i in train_idx]\n",
    "    val_set   = [full_train_set[i] for i in val_idx]\n",
    "    test_set  = [full_train_set[i] for i in test_idx]\n",
    "\n",
    "    # 8) 라벨 분포 확인(옵션이지만 유용)\n",
    "    def distrib(name, arr):\n",
    "        c = Counter([s['label'] for s in arr])\n",
    "        total = len(arr)\n",
    "        print(f\"{name}: {total}  | human={c.get('human',0)} ({c.get('human',0)/total:.2%}), AI={c.get('AI',0)} ({c.get('AI',0)/total:.2%})\")\n",
    "\n",
    "    print(f\"Train: {len(train_set)}, Validation: {len(val_set)}, Test: {len(test_set)}\")\n",
    "    distrib(\"Train\", train_set)\n",
    "    distrib(\"Val\",   val_set)\n",
    "    distrib(\"Test\",  test_set)\n",
    "    \n",
    "    return [train_set, val_set, test_set]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1501f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model', type=str, default='Transformer')\n",
    "    parser.add_argument('--gpu', type=str, default='0')\n",
    "    parser.add_argument('--train_mode', type=str, default='classify')\n",
    "    parser.add_argument('--batch_size', type=int, default=32)\n",
    "    parser.add_argument('--seq_len', type=int, default=1024)\n",
    "    parser.add_argument('--dataset', type=str, default=\"\")\n",
    "    parser.add_argument('--method', type=str, default=\"focalbmesbinary_embedconcat_transformer256\")\n",
    "    \n",
    "    parser.add_argument('--train_ratio', type=float, default=0.9)\n",
    "    parser.add_argument('--split_dataset', action='store_true')\n",
    "    parser.add_argument('--data_path', type=str, default='')\n",
    "    parser.add_argument('--train_path', type=str, default='')\n",
    "    parser.add_argument('--valid_path', type=str, default='')\n",
    "    parser.add_argument('--test_path', type=str, default='')\n",
    "\n",
    "    parser.add_argument('--num_train_epochs', type=int, default=20)\n",
    "    parser.add_argument('--weight_decay', type=float, default=0.1)\n",
    "    parser.add_argument('--lr', type=float, default=5e-5)\n",
    "    parser.add_argument('--warm_up_ratio', type=float, default=0.1)\n",
    "    parser.add_argument('--seed', type=int, default=42, required=True)\n",
    "    parser.add_argument('--do_test', action='store_true')\n",
    "    parser.add_argument('--test_content', action='store_true')\n",
    "    \n",
    "    parser.add_argument('--ckpt_name', type=str, default='')\n",
    "    parser.add_argument('--alpha', type=float, default=0.5)\n",
    "    parser.add_argument('--testbed', type=str, required=True)\n",
    "\n",
    "    parser.add_argument('--at_feature_path', type=str, default='')\n",
    "    \n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bba197f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log INFO: split dataset...\n",
      "[OK] No problem_id overlap between Train and Val.\n",
      "[OK] No problem_id overlap between Train and Test.\n",
      "[OK] No problem_id overlap between Val and Test.\n",
      "Train: 1992, Validation: 231, Test: 564\n",
      "Train: 1992  | human=0 (0.00%), AI=1992 (100.00%)\n",
      "Val: 231  | human=0 (0.00%), AI=231 (100.00%)\n",
      "Test: 564  | human=0 (0.00%), AI=564 (100.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [00:02<00:00, 896.12it/s] \n",
      "100%|██████████| 231/231 [00:00<00:00, 1135.30it/s]\n",
      "100%|██████████| 564/564 [00:00<00:00, 1188.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log INFO: do train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:48<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: train_loss 0.04598437675407955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:07<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.301743969321251\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 67.122\n",
      "Macro F1 Score: 40.163\n",
      "Binary F1 Score (pos): 0.000\n",
      "Precision/Recall per class:\n",
      "67.1,100.0,0.0,0.0\n",
      "CM [[TN FP],[FN TP]] = [[3148, 0], [1542, 0]]\n",
      "ROC_AUC (fpr-tpr): 0.572\n",
      "AUPRC: 0.347\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=67.1  MacroF1=40.2  BinF1(pos)=0.0\n",
      " P/R per class -> 0(H): 67.1/100.0 , 1(AI): 0.0/0.0\n",
      " CM [[TN FP],[FN TP]] = [[3148, 0], [1542, 0]]\n",
      "[thr=YoudenJ] thr=0.246 | Acc=52.1  MacroF1=52.0  BinF1(pos)=49.7\n",
      " P/R per class -> 0(H): 75.5/42.4 , 1(AI): 38.0/71.9\n",
      " CM [[TN FP],[FN TP]] = [[1335, 1813], [433, 1109]]\n",
      "[thr=bestPosF1] thr=0.222 | Acc=44.5  MacroF1=43.2  BinF1(pos)=51.7\n",
      " P/R per class -> 0(H): 82.5/22.0 , 1(AI): 36.2/90.5\n",
      " CM [[TN FP],[FN TP]] = [[692, 2456], [147, 1395]]\n",
      "67.1,40.2,0.0,67.1,100.0,0.0,0.0,0.572,0.347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:47<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: train_loss 0.03511156304369843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.117461420595646\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 67.122\n",
      "Macro F1 Score: 40.163\n",
      "Binary F1 Score (pos): 0.000\n",
      "Precision/Recall per class:\n",
      "67.1,100.0,0.0,0.0\n",
      "CM [[TN FP],[FN TP]] = [[3148, 0], [1542, 0]]\n",
      "ROC_AUC (fpr-tpr): 0.716\n",
      "AUPRC: 0.560\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=67.1  MacroF1=40.2  BinF1(pos)=0.0\n",
      " P/R per class -> 0(H): 67.1/100.0 , 1(AI): 0.0/0.0\n",
      " CM [[TN FP],[FN TP]] = [[3148, 0], [1542, 0]]\n",
      "[thr=YoudenJ] thr=0.238 | Acc=67.3  MacroF1=63.8  BinF1(pos)=52.6\n",
      " P/R per class -> 0(H): 77.0/73.2 , 1(AI): 50.3/55.3\n",
      " CM [[TN FP],[FN TP]] = [[2305, 843], [690, 852]]\n",
      "[thr=bestPosF1] thr=0.141 | Acc=51.1  MacroF1=50.6  BinF1(pos)=55.7\n",
      " P/R per class -> 0(H): 90.7/30.3 , 1(AI): 39.7/93.6\n",
      " CM [[TN FP],[FN TP]] = [[953, 2195], [98, 1444]]\n",
      "67.1,40.2,0.0,67.1,100.0,0.0,0.0,0.716,0.560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:47<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: train_loss 0.032503859361722356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.9871856719255447\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 72.580\n",
      "Macro F1 Score: 57.225\n",
      "Binary F1 Score (pos): 31.596\n",
      "Precision/Recall per class:\n",
      "71.4,98.7,87.9,19.3\n",
      "CM [[TN FP],[FN TP]] = [[3107, 41], [1245, 297]]\n",
      "ROC_AUC (fpr-tpr): 0.783\n",
      "AUPRC: 0.645\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=71.7  MacroF1=56.1  BinF1(pos)=29.8\n",
      " P/R per class -> 0(H): 71.0/97.9 , 1(AI): 81.0/18.3\n",
      " CM [[TN FP],[FN TP]] = [[3082, 66], [1260, 282]]\n",
      "[thr=YoudenJ] thr=0.226 | Acc=71.9  MacroF1=69.4  BinF1(pos)=60.8\n",
      " P/R per class -> 0(H): 81.9/74.6 , 1(AI): 56.1/66.3\n",
      " CM [[TN FP],[FN TP]] = [[2349, 799], [520, 1022]]\n",
      "[thr=bestPosF1] thr=0.202 | Acc=69.5  MacroF1=67.9  BinF1(pos)=60.9\n",
      " P/R per class -> 0(H): 83.4/68.1 , 1(AI): 52.6/72.3\n",
      " CM [[TN FP],[FN TP]] = [[2143, 1005], [427, 1115]]\n",
      "72.6,57.2,31.6,71.4,98.7,87.9,19.3,0.783,0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:46<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: train_loss 0.030884298422033826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.8839417099952698\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 75.736\n",
      "Macro F1 Score: 66.381\n",
      "Binary F1 Score (pos): 48.646\n",
      "Precision/Recall per class:\n",
      "75.0,95.7,80.0,35.0\n",
      "CM [[TN FP],[FN TP]] = [[3013, 135], [1003, 539]]\n",
      "ROC_AUC (fpr-tpr): 0.789\n",
      "AUPRC: 0.655\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=74.4  MacroF1=63.9  BinF1(pos)=44.6\n",
      " P/R per class -> 0(H): 73.9/95.5 , 1(AI): 77.2/31.3\n",
      " CM [[TN FP],[FN TP]] = [[3005, 143], [1059, 483]]\n",
      "[thr=YoudenJ] thr=0.272 | Acc=71.4  MacroF1=69.1  BinF1(pos)=60.8\n",
      " P/R per class -> 0(H): 82.1/73.4 , 1(AI): 55.4/67.3\n",
      " CM [[TN FP],[FN TP]] = [[2311, 837], [504, 1038]]\n",
      "[thr=bestPosF1] thr=0.234 | Acc=68.6  MacroF1=67.4  BinF1(pos)=61.1\n",
      " P/R per class -> 0(H): 84.2/65.5 , 1(AI): 51.5/74.9\n",
      " CM [[TN FP],[FN TP]] = [[2062, 1086], [387, 1155]]\n",
      "75.7,66.4,48.6,75.0,95.7,80.0,35.0,0.789,0.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:46<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: train_loss 0.02965918186283301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.8215121403336525\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 76.610\n",
      "Macro F1 Score: 67.662\n",
      "Binary F1 Score (pos): 50.652\n",
      "Precision/Recall per class:\n",
      "75.6,96.3,82.7,36.5\n",
      "CM [[TN FP],[FN TP]] = [[3030, 118], [979, 563]]\n",
      "ROC_AUC (fpr-tpr): 0.797\n",
      "AUPRC: 0.659\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=74.2  MacroF1=63.9  BinF1(pos)=44.7\n",
      " P/R per class -> 0(H): 73.9/94.9 , 1(AI): 75.5/31.7\n",
      " CM [[TN FP],[FN TP]] = [[2989, 159], [1053, 489]]\n",
      "[thr=YoudenJ] thr=0.239 | Acc=70.1  MacroF1=68.8  BinF1(pos)=62.2\n",
      " P/R per class -> 0(H): 84.6/67.9 , 1(AI): 53.3/74.8\n",
      " CM [[TN FP],[FN TP]] = [[2136, 1012], [388, 1154]]\n",
      "[thr=bestPosF1] thr=0.239 | Acc=70.1  MacroF1=68.8  BinF1(pos)=62.2\n",
      " P/R per class -> 0(H): 84.6/67.9 , 1(AI): 53.3/74.8\n",
      " CM [[TN FP],[FN TP]] = [[2136, 1012], [388, 1154]]\n",
      "76.6,67.7,50.7,75.6,96.3,82.7,36.5,0.797,0.659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:46<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: train_loss 0.029021569719863315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.772867277264595\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 76.610\n",
      "Macro F1 Score: 67.742\n",
      "Binary F1 Score (pos): 50.829\n",
      "Precision/Recall per class:\n",
      "75.6,96.1,82.3,36.8\n",
      "CM [[TN FP],[FN TP]] = [[3026, 122], [975, 567]]\n",
      "ROC_AUC (fpr-tpr): 0.827\n",
      "AUPRC: 0.697\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=75.0  MacroF1=65.1  BinF1(pos)=46.5\n",
      " P/R per class -> 0(H): 74.4/95.6 , 1(AI): 78.4/33.0\n",
      " CM [[TN FP],[FN TP]] = [[3008, 140], [1033, 509]]\n",
      "[thr=YoudenJ] thr=0.219 | Acc=73.8  MacroF1=72.3  BinF1(pos)=65.8\n",
      " P/R per class -> 0(H): 86.4/72.4 , 1(AI): 57.6/76.7\n",
      " CM [[TN FP],[FN TP]] = [[2279, 869], [360, 1182]]\n",
      "[thr=bestPosF1] thr=0.219 | Acc=73.8  MacroF1=72.3  BinF1(pos)=65.8\n",
      " P/R per class -> 0(H): 86.4/72.4 , 1(AI): 57.6/76.7\n",
      " CM [[TN FP],[FN TP]] = [[2279, 869], [360, 1182]]\n",
      "76.6,67.7,50.8,75.6,96.1,82.3,36.8,0.827,0.697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:46<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: train_loss 0.02839068905819976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7391883730888367\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 78.145\n",
      "Macro F1 Score: 71.871\n",
      "Binary F1 Score (pos): 58.586\n",
      "Precision/Recall per class:\n",
      "78.3,93.4,77.7,47.0\n",
      "CM [[TN FP],[FN TP]] = [[2940, 208], [817, 725]]\n",
      "ROC_AUC (fpr-tpr): 0.847\n",
      "AUPRC: 0.728\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=77.0  MacroF1=69.8  BinF1(pos)=55.1\n",
      " P/R per class -> 0(H): 77.0/93.6 , 1(AI): 76.8/42.9\n",
      " CM [[TN FP],[FN TP]] = [[2948, 200], [880, 662]]\n",
      "[thr=YoudenJ] thr=0.229 | Acc=75.0  MacroF1=73.6  BinF1(pos)=67.4\n",
      " P/R per class -> 0(H): 87.5/73.2 , 1(AI): 59.0/78.6\n",
      " CM [[TN FP],[FN TP]] = [[2305, 843], [330, 1212]]\n",
      "[thr=bestPosF1] thr=0.229 | Acc=75.0  MacroF1=73.6  BinF1(pos)=67.4\n",
      " P/R per class -> 0(H): 87.5/73.2 , 1(AI): 59.0/78.6\n",
      " CM [[TN FP],[FN TP]] = [[2305, 843], [330, 1212]]\n",
      "78.1,71.9,58.6,78.3,93.4,77.7,47.0,0.847,0.728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:47<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8: train_loss 0.027996375713320004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "Epoch:  40%|████      | 8/20 [07:15<10:48, 54.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7458174303174019\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 75.928\n",
      "Macro F1 Score: 65.881\n",
      "Binary F1 Score (pos): 47.366\n",
      "Precision/Recall per class:\n",
      "74.7,97.0,84.2,32.9\n",
      "CM [[TN FP],[FN TP]] = [[3053, 95], [1034, 508]]\n",
      "ROC_AUC (fpr-tpr): 0.850\n",
      "AUPRC: 0.726\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=74.8  MacroF1=63.9  BinF1(pos)=43.9\n",
      " P/R per class -> 0(H): 73.8/96.8 , 1(AI): 81.9/30.0\n",
      " CM [[TN FP],[FN TP]] = [[3046, 102], [1079, 463]]\n",
      "[thr=YoudenJ] thr=0.174 | Acc=75.5  MacroF1=74.1  BinF1(pos)=68.1\n",
      " P/R per class -> 0(H): 87.9/73.6 , 1(AI): 59.6/79.4\n",
      " CM [[TN FP],[FN TP]] = [[2317, 831], [318, 1224]]\n",
      "[thr=bestPosF1] thr=0.192 | Acc=76.7  MacroF1=74.9  BinF1(pos)=68.1\n",
      " P/R per class -> 0(H): 86.6/77.2 , 1(AI): 61.9/75.7\n",
      " CM [[TN FP],[FN TP]] = [[2431, 717], [375, 1167]]\n",
      "75.9,65.9,47.4,74.7,97.0,84.2,32.9,0.850,0.726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:46<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9: train_loss 0.027782511054759935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7045677527785301\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 79.083\n",
      "Macro F1 Score: 72.647\n",
      "Binary F1 Score (pos): 59.379\n",
      "Precision/Recall per class:\n",
      "78.4,95.0,82.1,46.5\n",
      "CM [[TN FP],[FN TP]] = [[2992, 156], [825, 717]]\n",
      "ROC_AUC (fpr-tpr): 0.858\n",
      "AUPRC: 0.740\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=77.1  MacroF1=69.9  BinF1(pos)=55.1\n",
      " P/R per class -> 0(H): 77.0/94.1 , 1(AI): 77.8/42.6\n",
      " CM [[TN FP],[FN TP]] = [[2961, 187], [885, 657]]\n",
      "[thr=YoudenJ] thr=0.240 | Acc=76.4  MacroF1=74.8  BinF1(pos)=68.4\n",
      " P/R per class -> 0(H): 87.4/75.8 , 1(AI): 61.1/77.7\n",
      " CM [[TN FP],[FN TP]] = [[2385, 763], [344, 1198]]\n",
      "[thr=bestPosF1] thr=0.267 | Acc=77.8  MacroF1=75.7  BinF1(pos)=68.5\n",
      " P/R per class -> 0(H): 86.0/80.0 , 1(AI): 64.2/73.4\n",
      " CM [[TN FP],[FN TP]] = [[2517, 631], [410, 1132]]\n",
      "79.1,72.6,59.4,78.4,95.0,82.1,46.5,0.858,0.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:46<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10: train_loss 0.02737483527097437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6967208907008171\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 78.465\n",
      "Macro F1 Score: 71.488\n",
      "Binary F1 Score (pos): 57.384\n",
      "Precision/Recall per class:\n",
      "77.7,95.3,82.1,44.1\n",
      "CM [[TN FP],[FN TP]] = [[3000, 148], [862, 680]]\n",
      "ROC_AUC (fpr-tpr): 0.864\n",
      "AUPRC: 0.752\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=77.9  MacroF1=70.6  BinF1(pos)=56.1\n",
      " P/R per class -> 0(H): 77.3/94.9 , 1(AI): 80.7/43.0\n",
      " CM [[TN FP],[FN TP]] = [[2989, 159], [879, 663]]\n",
      "[thr=YoudenJ] thr=0.208 | Acc=76.4  MacroF1=75.1  BinF1(pos)=69.2\n",
      " P/R per class -> 0(H): 88.6/74.5 , 1(AI): 60.7/80.4\n",
      " CM [[TN FP],[FN TP]] = [[2345, 803], [302, 1240]]\n",
      "[thr=bestPosF1] thr=0.242 | Acc=78.0  MacroF1=76.1  BinF1(pos)=69.2\n",
      " P/R per class -> 0(H): 86.8/79.3 , 1(AI): 64.1/75.4\n",
      " CM [[TN FP],[FN TP]] = [[2496, 652], [380, 1162]]\n",
      "78.5,71.5,57.4,77.7,95.3,82.1,44.1,0.864,0.752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:45<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11: train_loss 0.02713565067166374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6811652556061745\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 79.659\n",
      "Macro F1 Score: 73.758\n",
      "Binary F1 Score (pos): 61.314\n",
      "Precision/Recall per class:\n",
      "79.1,94.7,81.8,49.0\n",
      "CM [[TN FP],[FN TP]] = [[2980, 168], [786, 756]]\n",
      "ROC_AUC (fpr-tpr): 0.867\n",
      "AUPRC: 0.757\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=78.6  MacroF1=72.3  BinF1(pos)=59.2\n",
      " P/R per class -> 0(H): 78.4/93.9 , 1(AI): 79.2/47.3\n",
      " CM [[TN FP],[FN TP]] = [[2956, 192], [813, 729]]\n",
      "[thr=YoudenJ] thr=0.204 | Acc=75.2  MacroF1=74.2  BinF1(pos)=69.1\n",
      " P/R per class -> 0(H): 90.2/70.7 , 1(AI): 58.5/84.3\n",
      " CM [[TN FP],[FN TP]] = [[2227, 921], [242, 1300]]\n",
      "[thr=bestPosF1] thr=0.220 | Acc=76.2  MacroF1=74.9  BinF1(pos)=69.1\n",
      " P/R per class -> 0(H): 88.8/73.9 , 1(AI): 60.3/80.9\n",
      " CM [[TN FP],[FN TP]] = [[2327, 821], [294, 1248]]\n",
      "79.7,73.8,61.3,79.1,94.7,81.8,49.0,0.867,0.757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:46<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12: train_loss 0.02711533048441486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "Epoch:  60%|██████    | 12/20 [10:49<07:08, 53.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6880217790603638\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 79.339\n",
      "Macro F1 Score: 72.879\n",
      "Binary F1 Score (pos): 59.642\n",
      "Precision/Recall per class:\n",
      "78.4,95.5,83.4,46.4\n",
      "CM [[TN FP],[FN TP]] = [[3005, 143], [826, 716]]\n",
      "ROC_AUC (fpr-tpr): 0.868\n",
      "AUPRC: 0.755\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=77.8  MacroF1=70.6  BinF1(pos)=56.0\n",
      " P/R per class -> 0(H): 77.2/94.9 , 1(AI): 80.3/42.9\n",
      " CM [[TN FP],[FN TP]] = [[2986, 162], [880, 662]]\n",
      "[thr=YoudenJ] thr=0.194 | Acc=75.9  MacroF1=74.7  BinF1(pos)=69.3\n",
      " P/R per class -> 0(H): 89.5/72.6 , 1(AI): 59.6/82.6\n",
      " CM [[TN FP],[FN TP]] = [[2286, 862], [268, 1274]]\n",
      "[thr=bestPosF1] thr=0.205 | Acc=76.6  MacroF1=75.2  BinF1(pos)=69.3\n",
      " P/R per class -> 0(H): 88.6/74.7 , 1(AI): 60.9/80.4\n",
      " CM [[TN FP],[FN TP]] = [[2352, 796], [302, 1240]]\n",
      "79.3,72.9,59.6,78.4,95.5,83.4,46.4,0.868,0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:47<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13: train_loss 0.02691323972410626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6634411215782166\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 81.109\n",
      "Macro F1 Score: 77.353\n",
      "Binary F1 Score (pos): 68.129\n",
      "Precision/Recall per class:\n",
      "82.8,90.8,76.5,61.4\n",
      "CM [[TN FP],[FN TP]] = [[2857, 291], [595, 947]]\n",
      "ROC_AUC (fpr-tpr): 0.870\n",
      "AUPRC: 0.766\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=79.8  MacroF1=75.3  BinF1(pos)=64.9\n",
      " P/R per class -> 0(H): 81.1/91.0 , 1(AI): 75.6/56.8\n",
      " CM [[TN FP],[FN TP]] = [[2866, 282], [666, 876]]\n",
      "[thr=YoudenJ] thr=0.227 | Acc=74.5  MacroF1=73.7  BinF1(pos)=69.0\n",
      " P/R per class -> 0(H): 91.2/68.6 , 1(AI): 57.5/86.5\n",
      " CM [[TN FP],[FN TP]] = [[2160, 988], [208, 1334]]\n",
      "[thr=bestPosF1] thr=0.253 | Acc=75.5  MacroF1=74.4  BinF1(pos)=69.1\n",
      " P/R per class -> 0(H): 89.8/71.6 , 1(AI): 59.0/83.3\n",
      " CM [[TN FP],[FN TP]] = [[2254, 894], [257, 1285]]\n",
      "81.1,77.4,68.1,82.8,90.8,76.5,61.4,0.870,0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:46<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14: train_loss 0.02686885738420108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "Epoch:  70%|███████   | 14/20 [12:37<05:21, 53.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6786263212561607\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 78.849\n",
      "Macro F1 Score: 72.012\n",
      "Binary F1 Score (pos): 58.179\n",
      "Precision/Recall per class:\n",
      "77.9,95.6,83.1,44.7\n",
      "CM [[TN FP],[FN TP]] = [[3008, 140], [852, 690]]\n",
      "ROC_AUC (fpr-tpr): 0.872\n",
      "AUPRC: 0.764\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=78.0  MacroF1=70.6  BinF1(pos)=55.9\n",
      " P/R per class -> 0(H): 77.2/95.5 , 1(AI): 82.2/42.3\n",
      " CM [[TN FP],[FN TP]] = [[3007, 141], [889, 653]]\n",
      "[thr=YoudenJ] thr=0.181 | Acc=76.8  MacroF1=75.6  BinF1(pos)=70.1\n",
      " P/R per class -> 0(H): 89.6/74.0 , 1(AI): 60.9/82.6\n",
      " CM [[TN FP],[FN TP]] = [[2330, 818], [269, 1273]]\n",
      "[thr=bestPosF1] thr=0.181 | Acc=76.8  MacroF1=75.6  BinF1(pos)=70.1\n",
      " P/R per class -> 0(H): 89.6/74.1 , 1(AI): 60.9/82.5\n",
      " CM [[TN FP],[FN TP]] = [[2332, 816], [270, 1272]]\n",
      "78.8,72.0,58.2,77.9,95.6,83.1,44.7,0.872,0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:46<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15: train_loss 0.026712152219953992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n",
      "Epoch:  75%|███████▌  | 15/20 [13:30<04:27, 53.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6832278668880463\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 78.209\n",
      "Macro F1 Score: 70.770\n",
      "Binary F1 Score (pos): 56.024\n",
      "Precision/Recall per class:\n",
      "77.2,95.8,83.2,42.2\n",
      "CM [[TN FP],[FN TP]] = [[3017, 131], [891, 651]]\n",
      "ROC_AUC (fpr-tpr): 0.873\n",
      "AUPRC: 0.766\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=77.8  MacroF1=70.0  BinF1(pos)=54.8\n",
      " P/R per class -> 0(H): 76.8/95.8 , 1(AI): 82.6/41.0\n",
      " CM [[TN FP],[FN TP]] = [[3015, 133], [910, 632]]\n",
      "[thr=YoudenJ] thr=0.164 | Acc=76.2  MacroF1=75.1  BinF1(pos)=70.1\n",
      " P/R per class -> 0(H): 90.6/72.0 , 1(AI): 59.7/84.8\n",
      " CM [[TN FP],[FN TP]] = [[2266, 882], [235, 1307]]\n",
      "[thr=bestPosF1] thr=0.167 | Acc=76.3  MacroF1=75.2  BinF1(pos)=70.1\n",
      " P/R per class -> 0(H): 90.4/72.5 , 1(AI): 60.0/84.2\n",
      " CM [[TN FP],[FN TP]] = [[2281, 867], [243, 1299]]\n",
      "78.2,70.8,56.0,77.2,95.8,83.2,42.2,0.873,0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:46<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16: train_loss 0.02660562550382955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "Epoch:  80%|████████  | 16/20 [14:23<03:33, 53.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6655448600649834\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 79.488\n",
      "Macro F1 Score: 73.468\n",
      "Binary F1 Score (pos): 60.831\n",
      "Precision/Recall per class:\n",
      "78.9,94.7,81.7,48.4\n",
      "CM [[TN FP],[FN TP]] = [[2981, 167], [795, 747]]\n",
      "ROC_AUC (fpr-tpr): 0.876\n",
      "AUPRC: 0.773\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=79.2  MacroF1=72.8  BinF1(pos)=59.6\n",
      " P/R per class -> 0(H): 78.5/95.1 , 1(AI): 82.5/46.7\n",
      " CM [[TN FP],[FN TP]] = [[2995, 153], [822, 720]]\n",
      "[thr=YoudenJ] thr=0.170 | Acc=75.7  MacroF1=74.8  BinF1(pos)=70.0\n",
      " P/R per class -> 0(H): 91.3/70.6 , 1(AI): 58.9/86.3\n",
      " CM [[TN FP],[FN TP]] = [[2221, 927], [212, 1330]]\n",
      "[thr=bestPosF1] thr=0.203 | Acc=77.5  MacroF1=76.1  BinF1(pos)=70.3\n",
      " P/R per class -> 0(H): 89.0/75.9 , 1(AI): 62.2/80.9\n",
      " CM [[TN FP],[FN TP]] = [[2389, 759], [295, 1247]]\n",
      "79.5,73.5,60.8,78.9,94.7,81.7,48.4,0.876,0.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:46<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17: train_loss 0.026586061816603418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6620846316218376\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 79.659\n",
      "Macro F1 Score: 73.799\n",
      "Binary F1 Score (pos): 61.408\n",
      "Precision/Recall per class:\n",
      "79.2,94.6,81.6,49.2\n",
      "CM [[TN FP],[FN TP]] = [[2977, 171], [783, 759]]\n",
      "ROC_AUC (fpr-tpr): 0.876\n",
      "AUPRC: 0.772\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=79.0  MacroF1=72.8  BinF1(pos)=59.8\n",
      " P/R per class -> 0(H): 78.6/94.4 , 1(AI): 80.6/47.5\n",
      " CM [[TN FP],[FN TP]] = [[2972, 176], [810, 732]]\n",
      "[thr=YoudenJ] thr=0.207 | Acc=77.6  MacroF1=76.3  BinF1(pos)=70.5\n",
      " P/R per class -> 0(H): 89.3/75.8 , 1(AI): 62.2/81.5\n",
      " CM [[TN FP],[FN TP]] = [[2385, 763], [286, 1256]]\n",
      "[thr=bestPosF1] thr=0.207 | Acc=77.6  MacroF1=76.3  BinF1(pos)=70.5\n",
      " P/R per class -> 0(H): 89.3/75.8 , 1(AI): 62.2/81.5\n",
      " CM [[TN FP],[FN TP]] = [[2385, 763], [286, 1256]]\n",
      "79.7,73.8,61.4,79.2,94.6,81.6,49.2,0.876,0.772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:46<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18: train_loss 0.026370967132231547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6585622057318687\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 80.128\n",
      "Macro F1 Score: 74.509\n",
      "Binary F1 Score (pos): 62.540\n",
      "Precision/Recall per class:\n",
      "79.6,94.7,82.2,50.5\n",
      "CM [[TN FP],[FN TP]] = [[2980, 168], [764, 778]]\n",
      "ROC_AUC (fpr-tpr): 0.876\n",
      "AUPRC: 0.773\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=79.4  MacroF1=73.4  BinF1(pos)=60.9\n",
      " P/R per class -> 0(H): 79.0/94.4 , 1(AI): 81.1/48.7\n",
      " CM [[TN FP],[FN TP]] = [[2973, 175], [791, 751]]\n",
      "[thr=YoudenJ] thr=0.198 | Acc=76.8  MacroF1=75.6  BinF1(pos)=70.2\n",
      " P/R per class -> 0(H): 89.8/73.9 , 1(AI): 60.8/82.9\n",
      " CM [[TN FP],[FN TP]] = [[2325, 823], [263, 1279]]\n",
      "[thr=bestPosF1] thr=0.217 | Acc=77.7  MacroF1=76.2  BinF1(pos)=70.3\n",
      " P/R per class -> 0(H): 88.9/76.3 , 1(AI): 62.4/80.5\n",
      " CM [[TN FP],[FN TP]] = [[2401, 747], [301, 1241]]\n",
      "80.1,74.5,62.5,79.6,94.7,82.2,50.5,0.876,0.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:46<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19: train_loss 0.026411913098796966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6558604687452316\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 80.277\n",
      "Macro F1 Score: 74.911\n",
      "Binary F1 Score (pos): 63.308\n",
      "Precision/Recall per class:\n",
      "80.0,94.3,81.5,51.8\n",
      "CM [[TN FP],[FN TP]] = [[2967, 181], [744, 798]]\n",
      "ROC_AUC (fpr-tpr): 0.877\n",
      "AUPRC: 0.774\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=79.7  MacroF1=74.0  BinF1(pos)=61.8\n",
      " P/R per class -> 0(H): 79.3/94.4 , 1(AI): 81.4/49.8\n",
      " CM [[TN FP],[FN TP]] = [[2972, 176], [774, 768]]\n",
      "[thr=YoudenJ] thr=0.205 | Acc=76.9  MacroF1=75.7  BinF1(pos)=70.2\n",
      " P/R per class -> 0(H): 89.7/74.2 , 1(AI): 61.0/82.6\n",
      " CM [[TN FP],[FN TP]] = [[2335, 813], [269, 1273]]\n",
      "[thr=bestPosF1] thr=0.230 | Acc=78.0  MacroF1=76.4  BinF1(pos)=70.3\n",
      " P/R per class -> 0(H): 88.5/77.3 , 1(AI): 63.1/79.4\n",
      " CM [[TN FP],[FN TP]] = [[2432, 716], [317, 1225]]\n",
      "80.3,74.9,63.3,80.0,94.3,81.5,51.8,0.877,0.774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 63/63 [00:46<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20: train_loss 0.026360068943292375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "Epoch: 100%|██████████| 20/20 [17:58<00:00, 53.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6631856858730316\n",
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 79.531\n",
      "Macro F1 Score: 73.538\n",
      "Binary F1 Score (pos): 60.944\n",
      "Precision/Recall per class:\n",
      "79.0,94.7,81.8,48.6\n",
      "CM [[TN FP],[FN TP]] = [[2981, 167], [793, 749]]\n",
      "ROC_AUC (fpr-tpr): 0.877\n",
      "AUPRC: 0.774\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=79.3  MacroF1=72.9  BinF1(pos)=59.8\n",
      " P/R per class -> 0(H): 78.5/95.2 , 1(AI): 82.6/46.9\n",
      " CM [[TN FP],[FN TP]] = [[2996, 152], [819, 723]]\n",
      "[thr=YoudenJ] thr=0.198 | Acc=77.6  MacroF1=76.2  BinF1(pos)=70.5\n",
      " P/R per class -> 0(H): 89.4/75.6 , 1(AI): 62.1/81.6\n",
      " CM [[TN FP],[FN TP]] = [[2379, 769], [283, 1259]]\n",
      "[thr=bestPosF1] thr=0.211 | Acc=78.1  MacroF1=76.6  BinF1(pos)=70.5\n",
      " P/R per class -> 0(H): 88.6/77.3 , 1(AI): 63.2/79.8\n",
      " CM [[TN FP],[FN TP]] = [[2433, 715], [312, 1230]]\n",
      "79.5,73.5,60.9,79.0,94.7,81.8,48.6,0.877,0.774\n",
      "Reloading best model from ckpt/codenet(python)_gemini_hybrid_line_256atf_best_f1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 18/18 [00:17<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** Sentence Level Evalation ********\n",
      "=== Given labels (as-is) ===\n",
      "Accuracy: 77.039\n",
      "Macro F1 Score: 70.032\n",
      "Binary F1 Score (pos): 55.540\n",
      "Precision/Recall per class:\n",
      "75.2,96.5,86.3,40.9\n",
      "CM [[TN FP],[FN TP]] = [[7987, 289], [2636, 1827]]\n",
      "ROC_AUC (fpr-tpr): 0.859\n",
      "AUPRC: 0.774\n",
      "=== Threshold sweeps on scores ===\n",
      "[thr=0.5] thr=0.500 | Acc=76.2  MacroF1=69.2  BinF1(pos)=54.4\n",
      " P/R per class -> 0(H): 74.8/95.5 , 1(AI): 83.0/40.5\n",
      " CM [[TN FP],[FN TP]] = [[7906, 370], [2657, 1806]]\n",
      "[thr=YoudenJ] thr=0.244 | Acc=77.5  MacroF1=76.1  BinF1(pos)=70.2\n",
      " P/R per class -> 0(H): 85.7/78.5 , 1(AI): 65.5/75.7\n",
      " CM [[TN FP],[FN TP]] = [[6496, 1780], [1086, 3377]]\n",
      "[thr=bestPosF1] thr=0.244 | Acc=77.5  MacroF1=76.1  BinF1(pos)=70.2\n",
      " P/R per class -> 0(H): 85.7/78.5 , 1(AI): 65.5/75.7\n",
      " CM [[TN FP],[FN TP]] = [[6496, 1780], [1086, 3377]]\n",
      "77.0,70.0,55.5,75.2,96.5,86.3,40.9,0.859,0.774\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    sys.argv = [\n",
    "        \"train.py\",\n",
    "        \"--dataset\", \"codenet(python)_gemini_hybrid_line\",\n",
    "        \"--data_path\", \"./data\",\n",
    "        \"--seed\", \"42\",\n",
    "        \"--testbed\", \"toplevel\",\n",
    "        \"--ckpt_name\", \"codenet(python)_gemini_hybrid_line_256atf\",\n",
    "    ]\n",
    "\n",
    "    args = parse_args()\n",
    "    \n",
    "    print(\"Log INFO: split dataset...\")\n",
    "    df_ = split_dataset(data_path=args.data_path, seed=args.seed, dataset=args.dataset)  # [train, val, test]\n",
    "\n",
    "    en_labels = {\n",
    "        'human': 0,\n",
    "        'AI': 1\n",
    "    }\n",
    "    \n",
    "    id2label = construct_bmes_labels(en_labels)\n",
    "    label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "    prediction_method = 'most_common'\n",
    "\n",
    "    experiment_results = []\n",
    "\n",
    "    if 'revised' in args.dataset:\n",
    "        at_sidecar = AtcSidecar('./limo_atf/great_data_256/index.json')\n",
    "        datas = DataManagerTest(datas=df_, batch_size=args.batch_size, max_len=args.seq_len, human_label='human', id2label=id2label, at_feature_lookup=at_sidecar)\n",
    "    else:\n",
    "        at_sidecar = AtcSidecar('./limo_atf/great_data_256/index.json')\n",
    "        datas = DataManager(datas=df_, batch_size=args.batch_size, max_len=args.seq_len, human_label='human', id2label=id2label, at_feature_lookup=at_sidecar)\n",
    "\n",
    "    # classifier 선택\n",
    "    if args.method == 'focalbmesbinary_embedconcat_transformer256':\n",
    "        if args.testbed == 'toplevel':\n",
    "            if 'gemini' in args.dataset or 'gpt4' in args.dataset:\n",
    "                classifier = MultiModalConcatLineFocalBMESBinaryClassifier(id2labels=id2label, seq_len=args.seq_len, alpha=args.alpha)\n",
    "\n",
    "    ckpt_name = f'ckpt/{args.ckpt_name}_best_f1.pt'\n",
    "\n",
    "    trainer = SupervisedTrainer(datas, classifier, en_labels, id2label, args)\n",
    "    trainer.writer = SummaryWriter(log_dir=f\"runs/python_{args.ckpt_name}\")\n",
    "\n",
    "    experiment_result = {}\n",
    "\n",
    "    if args.do_test:\n",
    "        print(\"Log INFO: do test...\")\n",
    "        saved_model = torch.load(ckpt_name)\n",
    "        trainer.model.load_state_dict(saved_model.state_dict())\n",
    "        if 'hybrid' in args.dataset or 'revised' in args.dataset:\n",
    "            test_sent_result, _, test_raw_results = trainer.test(datas.test_dataloader, content_level_eval=False, prediction_method=prediction_method)\n",
    "            experiment_result['test_result'] = {'line': test_sent_result, 'raw': test_raw_results}\n",
    "        else:\n",
    "            test_sent_result, test_content_result, test_raw_results = trainer.test(datas.test_dataloader, content_level_eval=True, prediction_method=prediction_method)\n",
    "            experiment_result['test_result'] = {'line': test_sent_result, 'document': test_content_result, 'raw': test_raw_results}\n",
    "    else:\n",
    "        print(\"Log INFO: do train...\")\n",
    "        trainer.train(ckpt_name=ckpt_name, prediction_method=prediction_method)\n",
    "\n",
    "        if 'hybrid' in args.dataset or 'revised' in args.dataset:\n",
    "            test_sent_result, _, test_raw_results = trainer.test(datas.test_dataloader, content_level_eval=False, prediction_method=prediction_method)\n",
    "            experiment_result['test_result'] = {'line': test_sent_result, 'raw': test_raw_results}\n",
    "        else:\n",
    "            test_sent_result, test_content_result, test_raw_results = trainer.test(datas.test_dataloader, content_level_eval=True, prediction_method=prediction_method)\n",
    "            experiment_result['test_result'] = {'line': test_sent_result, 'document': test_content_result, 'raw': test_raw_results}\n",
    "\n",
    "    experiment_results.append(experiment_result)\n",
    "\n",
    "    with open(f'result/experiment_results_{args.ckpt_name}.json', 'w') as file:\n",
    "        json.dump(experiment_results, file, ensure_ascii=False, cls=NpEncoder)\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
